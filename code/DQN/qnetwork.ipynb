{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import math\n",
    "import copy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "      <th>vaso_input</th>\n",
       "      <th>iv_input</th>\n",
       "      <th>reward</th>\n",
       "      <th>icustayid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.029027</td>\n",
       "      <td>0.061212</td>\n",
       "      <td>0.224086</td>\n",
       "      <td>0.079448</td>\n",
       "      <td>0.052524</td>\n",
       "      <td>0.077151</td>\n",
       "      <td>0.103817</td>\n",
       "      <td>0.063714</td>\n",
       "      <td>0.032102</td>\n",
       "      <td>0.042459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083823</td>\n",
       "      <td>0.053838</td>\n",
       "      <td>0.081020</td>\n",
       "      <td>0.057297</td>\n",
       "      <td>0.030372</td>\n",
       "      <td>0.047363</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.031518</td>\n",
       "      <td>0.078677</td>\n",
       "      <td>0.120369</td>\n",
       "      <td>0.040228</td>\n",
       "      <td>0.047623</td>\n",
       "      <td>0.104624</td>\n",
       "      <td>0.093498</td>\n",
       "      <td>0.073046</td>\n",
       "      <td>0.035958</td>\n",
       "      <td>0.056553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088714</td>\n",
       "      <td>0.073047</td>\n",
       "      <td>0.083202</td>\n",
       "      <td>0.043883</td>\n",
       "      <td>0.036930</td>\n",
       "      <td>0.057726</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.030942</td>\n",
       "      <td>0.083416</td>\n",
       "      <td>0.106333</td>\n",
       "      <td>0.040481</td>\n",
       "      <td>0.039120</td>\n",
       "      <td>0.098819</td>\n",
       "      <td>0.077658</td>\n",
       "      <td>0.074696</td>\n",
       "      <td>0.041053</td>\n",
       "      <td>0.053553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092754</td>\n",
       "      <td>0.079161</td>\n",
       "      <td>0.082560</td>\n",
       "      <td>0.041910</td>\n",
       "      <td>0.036587</td>\n",
       "      <td>0.067986</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.042970</td>\n",
       "      <td>0.050963</td>\n",
       "      <td>0.090261</td>\n",
       "      <td>0.093201</td>\n",
       "      <td>0.031332</td>\n",
       "      <td>0.057674</td>\n",
       "      <td>0.032040</td>\n",
       "      <td>0.054802</td>\n",
       "      <td>0.061447</td>\n",
       "      <td>0.053960</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098049</td>\n",
       "      <td>0.074196</td>\n",
       "      <td>0.088113</td>\n",
       "      <td>0.045784</td>\n",
       "      <td>0.041096</td>\n",
       "      <td>0.129189</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.064572</td>\n",
       "      <td>0.084793</td>\n",
       "      <td>0.065976</td>\n",
       "      <td>0.070753</td>\n",
       "      <td>0.063990</td>\n",
       "      <td>0.051591</td>\n",
       "      <td>0.050112</td>\n",
       "      <td>0.049624</td>\n",
       "      <td>0.092619</td>\n",
       "      <td>0.080058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032011</td>\n",
       "      <td>0.081824</td>\n",
       "      <td>0.037519</td>\n",
       "      <td>0.061251</td>\n",
       "      <td>0.071471</td>\n",
       "      <td>0.039540</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 204 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.029027  0.061212  0.224086  0.079448  0.052524  0.077151  0.103817   \n",
       "1  0.031518  0.078677  0.120369  0.040228  0.047623  0.104624  0.093498   \n",
       "2  0.030942  0.083416  0.106333  0.040481  0.039120  0.098819  0.077658   \n",
       "3  0.042970  0.050963  0.090261  0.093201  0.031332  0.057674  0.032040   \n",
       "4  0.064572  0.084793  0.065976  0.070753  0.063990  0.051591  0.050112   \n",
       "\n",
       "          7         8         9    ...           194       195       196  \\\n",
       "0  0.063714  0.032102  0.042459    ...      0.083823  0.053838  0.081020   \n",
       "1  0.073046  0.035958  0.056553    ...      0.088714  0.073047  0.083202   \n",
       "2  0.074696  0.041053  0.053553    ...      0.092754  0.079161  0.082560   \n",
       "3  0.054802  0.061447  0.053960    ...      0.098049  0.074196  0.088113   \n",
       "4  0.049624  0.092619  0.080058    ...      0.032011  0.081824  0.037519   \n",
       "\n",
       "        197       198       199  vaso_input  iv_input  reward  icustayid  \n",
       "0  0.057297  0.030372  0.047363           0       0.0     0.0       12.0  \n",
       "1  0.043883  0.036930  0.057726           0       0.0     0.0       12.0  \n",
       "2  0.041910  0.036587  0.067986           0       0.0     0.0       12.0  \n",
       "3  0.045784  0.041096  0.129189           0       0.0    15.0       12.0  \n",
       "4  0.061251  0.071471  0.039540           0       4.0     0.0       14.0  \n",
       "\n",
       "[5 rows x 204 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../../data/train_scaled_encoded.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "      <th>vaso_input</th>\n",
       "      <th>iv_input</th>\n",
       "      <th>reward</th>\n",
       "      <th>icustayid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.044787</td>\n",
       "      <td>0.024944</td>\n",
       "      <td>0.059501</td>\n",
       "      <td>0.186372</td>\n",
       "      <td>0.099174</td>\n",
       "      <td>0.010116</td>\n",
       "      <td>0.015910</td>\n",
       "      <td>0.031792</td>\n",
       "      <td>0.063170</td>\n",
       "      <td>0.050696</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037952</td>\n",
       "      <td>0.041529</td>\n",
       "      <td>0.046699</td>\n",
       "      <td>0.054380</td>\n",
       "      <td>0.082892</td>\n",
       "      <td>0.012378</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.048257</td>\n",
       "      <td>0.029508</td>\n",
       "      <td>0.033046</td>\n",
       "      <td>0.102542</td>\n",
       "      <td>0.107019</td>\n",
       "      <td>0.015018</td>\n",
       "      <td>0.014971</td>\n",
       "      <td>0.034197</td>\n",
       "      <td>0.057205</td>\n",
       "      <td>0.072662</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037210</td>\n",
       "      <td>0.051388</td>\n",
       "      <td>0.044145</td>\n",
       "      <td>0.039312</td>\n",
       "      <td>0.096143</td>\n",
       "      <td>0.013473</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.041906</td>\n",
       "      <td>0.028968</td>\n",
       "      <td>0.028705</td>\n",
       "      <td>0.111719</td>\n",
       "      <td>0.098205</td>\n",
       "      <td>0.013579</td>\n",
       "      <td>0.012648</td>\n",
       "      <td>0.027884</td>\n",
       "      <td>0.074506</td>\n",
       "      <td>0.081935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037256</td>\n",
       "      <td>0.055131</td>\n",
       "      <td>0.042269</td>\n",
       "      <td>0.039004</td>\n",
       "      <td>0.103266</td>\n",
       "      <td>0.015244</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.040383</td>\n",
       "      <td>0.029019</td>\n",
       "      <td>0.029167</td>\n",
       "      <td>0.131740</td>\n",
       "      <td>0.099840</td>\n",
       "      <td>0.013389</td>\n",
       "      <td>0.012455</td>\n",
       "      <td>0.028260</td>\n",
       "      <td>0.072425</td>\n",
       "      <td>0.088626</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037022</td>\n",
       "      <td>0.057600</td>\n",
       "      <td>0.039294</td>\n",
       "      <td>0.038362</td>\n",
       "      <td>0.117384</td>\n",
       "      <td>0.015660</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.045685</td>\n",
       "      <td>0.029040</td>\n",
       "      <td>0.027817</td>\n",
       "      <td>0.137894</td>\n",
       "      <td>0.106901</td>\n",
       "      <td>0.013968</td>\n",
       "      <td>0.012697</td>\n",
       "      <td>0.028393</td>\n",
       "      <td>0.073113</td>\n",
       "      <td>0.088150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036816</td>\n",
       "      <td>0.058196</td>\n",
       "      <td>0.038383</td>\n",
       "      <td>0.038041</td>\n",
       "      <td>0.123431</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 204 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.044787  0.024944  0.059501  0.186372  0.099174  0.010116  0.015910   \n",
       "1  0.048257  0.029508  0.033046  0.102542  0.107019  0.015018  0.014971   \n",
       "2  0.041906  0.028968  0.028705  0.111719  0.098205  0.013579  0.012648   \n",
       "3  0.040383  0.029019  0.029167  0.131740  0.099840  0.013389  0.012455   \n",
       "4  0.045685  0.029040  0.027817  0.137894  0.106901  0.013968  0.012697   \n",
       "\n",
       "          7         8         9    ...           194       195       196  \\\n",
       "0  0.031792  0.063170  0.050696    ...      0.037952  0.041529  0.046699   \n",
       "1  0.034197  0.057205  0.072662    ...      0.037210  0.051388  0.044145   \n",
       "2  0.027884  0.074506  0.081935    ...      0.037256  0.055131  0.042269   \n",
       "3  0.028260  0.072425  0.088626    ...      0.037022  0.057600  0.039294   \n",
       "4  0.028393  0.073113  0.088150    ...      0.036816  0.058196  0.038383   \n",
       "\n",
       "        197       198       199  vaso_input  iv_input  reward  icustayid  \n",
       "0  0.054380  0.082892  0.012378           0       4.0     0.0       61.0  \n",
       "1  0.039312  0.096143  0.013473           0       4.0     0.0       61.0  \n",
       "2  0.039004  0.103266  0.015244           0       4.0     0.0       61.0  \n",
       "3  0.038362  0.117384  0.015660           0       4.0     0.0       61.0  \n",
       "4  0.038041  0.123431  0.014925           0       4.0     0.0       61.0  \n",
       "\n",
       "[5 rows x 204 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('../../data/test_scaled_encoded.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "REWARD_THRESHOLD =15\n",
    "reg_lambda = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PER important weights and params\n",
    "per_flag = True\n",
    "beta_start = 0.9\n",
    "train['prob'] = abs(train['reward'])\n",
    "temp = 1.0 / train['prob']\n",
    "temp[temp == float('Inf')] = 1.0\n",
    "train['imp_weight'] = pow((1.0 / len(train) * temp), beta_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "      <th>vaso_input</th>\n",
       "      <th>iv_input</th>\n",
       "      <th>reward</th>\n",
       "      <th>icustayid</th>\n",
       "      <th>prob</th>\n",
       "      <th>imp_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.064572</td>\n",
       "      <td>0.084793</td>\n",
       "      <td>0.065976</td>\n",
       "      <td>0.070753</td>\n",
       "      <td>0.063990</td>\n",
       "      <td>0.051591</td>\n",
       "      <td>0.050112</td>\n",
       "      <td>0.049624</td>\n",
       "      <td>0.092619</td>\n",
       "      <td>0.080058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037519</td>\n",
       "      <td>0.061251</td>\n",
       "      <td>0.071471</td>\n",
       "      <td>0.039540</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.074025</td>\n",
       "      <td>0.079019</td>\n",
       "      <td>0.069797</td>\n",
       "      <td>0.068576</td>\n",
       "      <td>0.069831</td>\n",
       "      <td>0.043737</td>\n",
       "      <td>0.056884</td>\n",
       "      <td>0.073837</td>\n",
       "      <td>0.073740</td>\n",
       "      <td>0.075134</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040486</td>\n",
       "      <td>0.053812</td>\n",
       "      <td>0.067138</td>\n",
       "      <td>0.043424</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.067640</td>\n",
       "      <td>0.073252</td>\n",
       "      <td>0.077615</td>\n",
       "      <td>0.072775</td>\n",
       "      <td>0.074835</td>\n",
       "      <td>0.040598</td>\n",
       "      <td>0.054152</td>\n",
       "      <td>0.078552</td>\n",
       "      <td>0.073434</td>\n",
       "      <td>0.086740</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043017</td>\n",
       "      <td>0.054578</td>\n",
       "      <td>0.068782</td>\n",
       "      <td>0.045069</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.084182</td>\n",
       "      <td>0.069916</td>\n",
       "      <td>0.070347</td>\n",
       "      <td>0.069123</td>\n",
       "      <td>0.072279</td>\n",
       "      <td>0.034510</td>\n",
       "      <td>0.053141</td>\n",
       "      <td>0.090075</td>\n",
       "      <td>0.061658</td>\n",
       "      <td>0.072907</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049218</td>\n",
       "      <td>0.054276</td>\n",
       "      <td>0.064720</td>\n",
       "      <td>0.051236</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.113805</td>\n",
       "      <td>0.048466</td>\n",
       "      <td>0.068828</td>\n",
       "      <td>0.080646</td>\n",
       "      <td>0.059614</td>\n",
       "      <td>0.016070</td>\n",
       "      <td>0.028201</td>\n",
       "      <td>0.081736</td>\n",
       "      <td>0.072616</td>\n",
       "      <td>0.049215</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051598</td>\n",
       "      <td>0.057034</td>\n",
       "      <td>0.067416</td>\n",
       "      <td>0.083398</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.103441</td>\n",
       "      <td>0.079006</td>\n",
       "      <td>0.073327</td>\n",
       "      <td>0.083135</td>\n",
       "      <td>0.065522</td>\n",
       "      <td>0.030426</td>\n",
       "      <td>0.026677</td>\n",
       "      <td>0.059899</td>\n",
       "      <td>0.066019</td>\n",
       "      <td>0.055480</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065361</td>\n",
       "      <td>0.069394</td>\n",
       "      <td>0.072032</td>\n",
       "      <td>0.120818</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.101310</td>\n",
       "      <td>0.064388</td>\n",
       "      <td>0.070295</td>\n",
       "      <td>0.103702</td>\n",
       "      <td>0.062022</td>\n",
       "      <td>0.026225</td>\n",
       "      <td>0.029238</td>\n",
       "      <td>0.069330</td>\n",
       "      <td>0.088385</td>\n",
       "      <td>0.064827</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063749</td>\n",
       "      <td>0.072680</td>\n",
       "      <td>0.077492</td>\n",
       "      <td>0.109648</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.089622</td>\n",
       "      <td>0.053569</td>\n",
       "      <td>0.067050</td>\n",
       "      <td>0.118848</td>\n",
       "      <td>0.064748</td>\n",
       "      <td>0.025035</td>\n",
       "      <td>0.034923</td>\n",
       "      <td>0.078645</td>\n",
       "      <td>0.086481</td>\n",
       "      <td>0.075960</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063923</td>\n",
       "      <td>0.076082</td>\n",
       "      <td>0.078420</td>\n",
       "      <td>0.104181</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.094056</td>\n",
       "      <td>0.052298</td>\n",
       "      <td>0.068664</td>\n",
       "      <td>0.119672</td>\n",
       "      <td>0.071022</td>\n",
       "      <td>0.029564</td>\n",
       "      <td>0.037301</td>\n",
       "      <td>0.062040</td>\n",
       "      <td>0.070939</td>\n",
       "      <td>0.079584</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052991</td>\n",
       "      <td>0.083214</td>\n",
       "      <td>0.070643</td>\n",
       "      <td>0.099471</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.093668</td>\n",
       "      <td>0.047470</td>\n",
       "      <td>0.073948</td>\n",
       "      <td>0.109111</td>\n",
       "      <td>0.074271</td>\n",
       "      <td>0.028844</td>\n",
       "      <td>0.038724</td>\n",
       "      <td>0.067044</td>\n",
       "      <td>0.064909</td>\n",
       "      <td>0.077116</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048472</td>\n",
       "      <td>0.077113</td>\n",
       "      <td>0.064924</td>\n",
       "      <td>0.103841</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 206 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6  \\\n",
       "4   0.064572  0.084793  0.065976  0.070753  0.063990  0.051591  0.050112   \n",
       "5   0.074025  0.079019  0.069797  0.068576  0.069831  0.043737  0.056884   \n",
       "6   0.067640  0.073252  0.077615  0.072775  0.074835  0.040598  0.054152   \n",
       "7   0.084182  0.069916  0.070347  0.069123  0.072279  0.034510  0.053141   \n",
       "8   0.113805  0.048466  0.068828  0.080646  0.059614  0.016070  0.028201   \n",
       "9   0.103441  0.079006  0.073327  0.083135  0.065522  0.030426  0.026677   \n",
       "10  0.101310  0.064388  0.070295  0.103702  0.062022  0.026225  0.029238   \n",
       "11  0.089622  0.053569  0.067050  0.118848  0.064748  0.025035  0.034923   \n",
       "12  0.094056  0.052298  0.068664  0.119672  0.071022  0.029564  0.037301   \n",
       "13  0.093668  0.047470  0.073948  0.109111  0.074271  0.028844  0.038724   \n",
       "\n",
       "           7         8         9     ...           196       197       198  \\\n",
       "4   0.049624  0.092619  0.080058     ...      0.037519  0.061251  0.071471   \n",
       "5   0.073837  0.073740  0.075134     ...      0.040486  0.053812  0.067138   \n",
       "6   0.078552  0.073434  0.086740     ...      0.043017  0.054578  0.068782   \n",
       "7   0.090075  0.061658  0.072907     ...      0.049218  0.054276  0.064720   \n",
       "8   0.081736  0.072616  0.049215     ...      0.051598  0.057034  0.067416   \n",
       "9   0.059899  0.066019  0.055480     ...      0.065361  0.069394  0.072032   \n",
       "10  0.069330  0.088385  0.064827     ...      0.063749  0.072680  0.077492   \n",
       "11  0.078645  0.086481  0.075960     ...      0.063923  0.076082  0.078420   \n",
       "12  0.062040  0.070939  0.079584     ...      0.052991  0.083214  0.070643   \n",
       "13  0.067044  0.064909  0.077116     ...      0.048472  0.077113  0.064924   \n",
       "\n",
       "         199  vaso_input  iv_input  reward  icustayid  prob  imp_weight  \n",
       "4   0.039540           0       4.0     0.0       14.0   0.0    0.000022  \n",
       "5   0.043424           0       3.0     0.0       14.0   0.0    0.000022  \n",
       "6   0.045069           0       3.0     0.0       14.0   0.0    0.000022  \n",
       "7   0.051236           0       2.0     0.0       14.0   0.0    0.000022  \n",
       "8   0.083398           0       0.0     0.0       14.0   0.0    0.000022  \n",
       "9   0.120818           0       0.0     0.0       14.0   0.0    0.000022  \n",
       "10  0.109648           0       2.0     0.0       14.0   0.0    0.000022  \n",
       "11  0.104181           0       2.0     0.0       14.0   0.0    0.000022  \n",
       "12  0.099471           0       2.0     0.0       14.0   0.0    0.000022  \n",
       "13  0.103841           0       2.0    15.0       14.0  15.0    0.000002  \n",
       "\n",
       "[10 rows x 206 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[train['icustayid'] == 14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_1_size = 128\n",
    "hidden_2_size = 128\n",
    "\n",
    "class Qnetwork():\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.phase = tf.placeholder(tf.bool)\n",
    "        self.num_actions = 25\n",
    "        self.input_size = 200\n",
    "        self.state = tf.placeholder(tf.float32, shape=[None, self.input_size],name=\"input_state\")\n",
    "        \n",
    "        self.fc_1 = tf.contrib.layers.fully_connected(self.state, hidden_1_size, activation_fn=None)\n",
    "        self.fc_1_bn = tf.contrib.layers.batch_norm(self.fc_1, center=True, scale=True, is_training=self.phase)\n",
    "        self.fc_1_ac = tf.maximum(self.fc_1_bn, self.fc_1_bn * 0.5)\n",
    "        \n",
    "        self.fc_2 = tf.contrib.layers.fully_connected(self.fc_1_ac, hidden_2_size, activation_fn=None)\n",
    "        self.fc_2_bn = tf.contrib.layers.batch_norm(self.fc_2, center=True, scale=True, is_training=self.phase)\n",
    "        self.fc_2_ac = tf.maximum(self.fc_2_bn, self.fc_2_bn * 0.5)\n",
    "        \n",
    "        # advantage and value streams\n",
    "        self.streamA, self.streamV = tf.split(self.fc_2_ac,2,axis=1)\n",
    "        self.Advantage = tf.contrib.layers.fully_connected(self.streamA, self.num_actions, activation_fn=None)\n",
    "        self.Value = tf.contrib.layers.fully_connected(self.streamV, 1, activation_fn=None)\n",
    "#         self.AW = tf.Variable(tf.random_normal([hidden_2_size//2, self.num_actions], stddev=0.3))\n",
    "#         self.VW = tf.Variable(tf.random_normal([hidden_2_size//2, 1], stddev=0.3))\n",
    "#         self.Advantage = tf.matmul(self.streamA, self.AW)\n",
    "#         self.Value = tf.matmul(self.streamV, self.VW)\n",
    "        \n",
    "        # Then combine them together to get our final Q-values.\n",
    "        self.q_output = self.Value + tf.subtract(self.Advantage, tf.reduce_mean(self.Advantage,axis=1,keep_dims=True))\n",
    "        self.predict = tf.argmax(self.q_output, 1, name='predict') # vector of length batch size\n",
    "        \n",
    "        #Below we obtain the loss by taking the sum of squares difference between the target and predicted Q values.\n",
    "        self.targetQ = tf.placeholder(shape=[None],dtype=tf.float32)\n",
    "        self.actions = tf.placeholder(shape=[None],dtype=tf.int32)\n",
    "        self.actions_onehot = tf.one_hot(self.actions, self.num_actions,dtype=tf.float32)\n",
    "        \n",
    "        # Importance sampling weights for PER, used in network update    \n",
    "        self.imp_weights = tf.placeholder(shape=[None], dtype=tf.float32)\n",
    "        # select the Q values for the actions that would be selected\n",
    "        self.Q = tf.reduce_sum(tf.multiply(self.q_output, self.actions_onehot), reduction_indices=1) # batch size x 1 vector\n",
    "        \n",
    "        # reward threshold, to ensure reasonable Q-value predictions  \n",
    "        self.reg_vector = tf.maximum(tf.abs(self.Q)-REWARD_THRESHOLD,0)\n",
    "        self.reg_term = tf.reduce_sum(self.reg_vector)\n",
    "        \n",
    "        self.abs_error = tf.abs(self.targetQ - self.Q)\n",
    "        \n",
    "        self.td_error = tf.square(self.targetQ - self.Q)\n",
    "        \n",
    "        # below is the loss when we are not using PER\n",
    "        self.old_loss = tf.reduce_mean(self.td_error)\n",
    "        \n",
    "        # as in the paper, to get PER loss we weight the squared error by the importance weights\n",
    "        self.per_error = tf.multiply(self.td_error, self.imp_weights)\n",
    "\n",
    "        # total loss is a sum of PER loss and the regularisation term\n",
    "        if per_flag:\n",
    "            self.loss = tf.reduce_mean(self.per_error) + reg_lambda * self.reg_term\n",
    "        else:\n",
    "            self.loss = self.old_loss + reg_lambda * self.reg_term\n",
    "\n",
    "        self.trainer = tf.train.AdamOptimizer(learning_rate=0.00005)\n",
    "        self.update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(self.update_ops):\n",
    "        # Ensures that we execute the update_ops before performing the model update, so batchnorm works\n",
    "            self.update_model = self.trainer.minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function is needed to update parameters between main and target network\n",
    "# tf_vars are the trainable variables to update, and tau is the rate at which to update\n",
    "# returns tf ops corresponding to the updates\n",
    "def update_target_graph(tf_vars,tau):\n",
    "    total_vars = len(tf_vars)\n",
    "    op_holder = []\n",
    "    for idx,var in enumerate(tf_vars[0:int(total_vars/2)]):\n",
    "        op_holder.append(tf_vars[idx+int(total_vars/2)].assign((var.value()*tau) + ((1-tau)*tf_vars[idx+int(total_vars/2)].value())))\n",
    "    return op_holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_target(op_holder,sess):\n",
    "    for op in op_holder:\n",
    "        sess.run(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define an action mapping - how to get an id representing the action from the (iv,vaso) tuple\n",
    "action_map = {}\n",
    "count = 0\n",
    "for iv in range(5):\n",
    "    for vaso in range(5):\n",
    "        action_map[(iv, vaso)] = count\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generates batches for the Q network - depending on train and eval_type, can select data from train/val/test sets.\n",
    "def process_batch(size, train_phase=True, eval_type = None):\n",
    "    \n",
    "    if not train_phase:\n",
    "        \n",
    "        if eval_type is None:\n",
    "            raise Exception('Provide eval_type to process_batch')\n",
    "        elif eval_type == 'train':\n",
    "            a = train.copy()\n",
    "        elif eval_type == 'val':\n",
    "            a = val_df.copy()\n",
    "        elif eval_type == 'test':\n",
    "            a = test.copy()\n",
    "        else:\n",
    "            raise Exception('Unknown eval_type')\n",
    "    else:\n",
    "        if per_flag:\n",
    "            # uses prioritised exp replay\n",
    "            a = train.sample(n=size, weights=train['prob'])\n",
    "        else:\n",
    "            a = train.sample(n=size)\n",
    "            \n",
    "    if size == None:\n",
    "        size = len(a)\n",
    "    \n",
    "    states = np.zeros((size, 200))\n",
    "    actions = np.zeros((size, 1), dtype=int)\n",
    "    rewards = np.zeros((size, 1))\n",
    "    next_states = np.zeros((size, 200))\n",
    "    done_flags = np.zeros((size, 1))\n",
    "    \n",
    "    counter = 0\n",
    "    for idx, obser in a.iterrows():\n",
    "        cur_state = obser[:200]\n",
    "        iv = int(obser.loc['iv_input'])\n",
    "        vaso = int(obser.loc['vaso_input'])\n",
    "        action = action_map[iv, vaso]\n",
    "        reward = obser.loc['reward']\n",
    "        \n",
    "        if idx != train.index[-1]:\n",
    "            # if not terminal step in trajectory             \n",
    "            if train.loc[idx, 'icustayid'] == train.loc[idx + 1, 'icustayid']:\n",
    "                next_state = train.iloc[idx + 1, :200]\n",
    "                done = 0\n",
    "            else:\n",
    "                # trajectory is finished\n",
    "                next_state = np.zeros(len(cur_state))\n",
    "                done = 1\n",
    "        else:\n",
    "            # last entry in df is the final state of that trajectory\n",
    "            next_state = np.zeros(len(cur_state))\n",
    "            done = 1\n",
    "        \n",
    "        states[counter] = cur_state\n",
    "        actions[counter] = action\n",
    "        rewards[counter] = reward\n",
    "        next_states[counter] = next_state\n",
    "        done_flags[counter] = done\n",
    "        counter += 1\n",
    "        \n",
    "    return (states, np.squeeze(actions), np.squeeze(rewards), next_states, np.squeeze(done_flags), a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  Used to run diagnostics on the train set\n",
    "phys_q_train = []\n",
    "agent_q_train = []\n",
    "phys_actions_tr = []\n",
    "agent_actions_tr = []\n",
    "\n",
    "def train_set_performance():\n",
    "    count = 0\n",
    "    global phys_q_train\n",
    "    global agent_q_train\n",
    "    global phys_actions\n",
    "    global agent_actions\n",
    "    phys_q_train = []\n",
    "    agent_q_train = []\n",
    "    phys_actions_tr = []\n",
    "    agent_actions_tr = []\n",
    "    for r in train.index:\n",
    "        cur_state = [train.iloc[r, :200]]\n",
    "        iv = int(train.loc[r, 'iv_input'])\n",
    "        vaso = int(train.loc[r, 'vaso_input'])\n",
    "        action = action_map[iv, vaso]\n",
    "        output_q = np.squeeze(sess.run(mainQN.q_output, feed_dict = {mainQN.state : cur_state, mainQN.phase : False}))\n",
    "        phys_q_train.append(output_q[action])\n",
    "        agent_q_train.append(max(output_q))\n",
    "        agent_actions_tr.append(np.argmax(output_q))\n",
    "        phys_actions_tr.append(action)\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_eval(eval_type):\n",
    "    states,actions,rewards,next_states,done_flags, _ = process_batch(size=None,train_phase=False,eval_type=eval_type)\n",
    "    # firstly get the chosen actions at the next timestep\n",
    "    actions_from_q1 = sess.run(mainQN.predict,feed_dict={mainQN.state: next_states, mainQN.phase : 0})\n",
    "\n",
    "    # Q values for the next timestep from target network, as part of the Double DQN update\n",
    "    Q2 = sess.run(targetQN.q_output,feed_dict={targetQN.state:next_states, targetQN.phase : 0})\n",
    "    # handles the case when a trajectory is finished\n",
    "    end_multiplier = 1 - done_flags\n",
    "\n",
    "    # target Q value using Q values from target, and actions from main\n",
    "    double_q_value = Q2[range(len(actions_from_q1)), actions_from_q1]\n",
    "\n",
    "    # definition of target Q\n",
    "    targetQ = rewards + ( gamma * double_q_value * end_multiplier )\n",
    "\n",
    "    # get the output q's, actions, and loss\n",
    "    q_output, actions_taken, abs_err = sess.run([mainQN.q_output, mainQN.predict, mainQN.abs_error], \\\n",
    "        feed_dict={mainQN.state:states,\n",
    "                   mainQN.targetQ:targetQ, \n",
    "                   mainQN.actions:actions,\n",
    "                   mainQN.phase:False})\n",
    "    # return the relevant q values and actions\n",
    "    phys_q = q_output[range(len(q_output)), actions]\n",
    "    agent_q = q_output[range(len(q_output)), actions_taken]\n",
    "    error = np.mean(abs_err)\n",
    "    \n",
    "    return phys_q, actions, agent_q, actions_taken, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_save_results():\n",
    "    \n",
    "    # get the chosen actions for the train, val, and test set when training is complete.\n",
    "    phys_q_train, actions_train, agent_q_train, agent_actions_train, _ = do_eval(eval_type = 'train')        \n",
    "    # phys_q_val, actions_val, agent_q_val, agent_actions_val, _ = do_eval(eval_type = 'val')        \n",
    "    phys_q_test, actions_test, agent_q_test, agent_actions_test, _ = do_eval(eval_type = 'test')  \n",
    "    \n",
    "    # save everything for later - they're used in policy evaluation and when generating plots\n",
    "    \n",
    "    ## Physician q\n",
    "    with open(save_dir + 'dqn_autoencode_phy_q_train.p', 'wb') as f:\n",
    "        pickle.dump(phys_q_train, f)\n",
    "#     with open(save_dir + 'dqn_autoencode_phy_q_val.p', 'wb') as f:\n",
    "#         pickle.dump(phys_q_val, f)\n",
    "    with open(save_dir + 'dqn_autoencode_phy_q_test.p', 'wb') as f:\n",
    "        pickle.dump(phys_q_test, f)\n",
    "    \n",
    "    ## Physician action\n",
    "    with open(save_dir + 'dqn_autoencode_phy_actions_train.p', 'wb') as f:\n",
    "        pickle.dump(actions_train, f)\n",
    "#     with open(save_dir + 'dqn_autoencode_phy_actions_val.p', 'wb') as f:\n",
    "#         pickle.dump(actions_val, f)\n",
    "    with open(save_dir + 'dqn_autoencode_phy_actions_test.p', 'wb') as f:\n",
    "        pickle.dump(actions_test, f)\n",
    "    \n",
    "    ## Agent actions\n",
    "    with open(save_dir + 'dqn_autoencode_agent_actions_train.p', 'wb') as f:\n",
    "        pickle.dump(agent_actions_train, f)\n",
    "#     with open(save_dir + 'dqn_autoencode_actions_val.p', 'wb') as f:\n",
    "#         pickle.dump(agent_actions_val, f)\n",
    "    with open(save_dir + 'dqn_autoencode_agent_actions_test.p', 'wb') as f:\n",
    "        pickle.dump(agent_actions_test, f)\n",
    "    \n",
    "    ## Agent Q\n",
    "    with open(save_dir + 'dqn_autoencode_agent_q_train.p', 'wb') as f:\n",
    "        pickle.dump(agent_q_train, f)\n",
    "#     with open(save_dir + 'dqn_autoencode_q_val.p', 'wb') as f:\n",
    "#         pickle.dump(agent_q_val, f)\n",
    "    with open(save_dir + 'dqn_autoencode_agent_q_test.p', 'wb') as f:\n",
    "        pickle.dump(agent_q_test, f)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running default init\n",
      "Init done\n",
      "Saved Model, step is 1000\n",
      "Average loss is  0.383027761936\n",
      "Saving PER and importance weights\n",
      "step: 1000\n",
      "phys actions  [ 0  0  0  0  0 10  0  5 12 10 15 15  5  5 20  0  5  0 10 10  0  3 22  0  0\n",
      "  5  0  5  0  0]\n",
      "chosen actions  [24 10  0  0 15 20  0 21 11 15 20 20  0  0  0  0  8  0 21  0  0  0 11 21  0\n",
      " 21  5  5  5  0]\n",
      "mean abs err: 1.40667\n",
      "mean phys Q: 0.396197\n",
      "mean agent Q: 0.557635\n",
      "------------------------\n",
      "Saved Model, step is 2000\n",
      "Average loss is  0.371833103657\n",
      "Saving PER and importance weights\n",
      "step: 2000\n",
      "phys actions  [ 0 10 15 15  4  0 10  0 10 10  0 20 16  5  0  0  5  5 24 10  5  0  0 16  0\n",
      " 10  0  0 15  0]\n",
      "chosen actions  [10 21 20 10 10 20  0  0  0 20  0  0 10 21  0 21  0 10 10 15  0  0  0 10  0\n",
      "  0  0  0 20  0]\n",
      "mean abs err: 1.749\n",
      "mean phys Q: 0.938686\n",
      "mean agent Q: 1.29719\n",
      "------------------------\n",
      "Saved Model, step is 3000\n",
      "Average loss is  0.301234333992\n",
      "Saving PER and importance weights\n",
      "step: 3000\n",
      "phys actions  [10 11  0  0  0  0  0 10  0  0 15  0 15  0  0  0  0 19 10  5  0 19 18 15  0\n",
      " 15  5  0 13 10]\n",
      "chosen actions  [10 17  0  0  0  0  0 10  5  0 10  0  0 10  0  0  0 10 10 10  0  3 17 10  0\n",
      "  5 10  0 10 10]\n",
      "mean abs err: 2.21645\n",
      "mean phys Q: 1.6549\n",
      "mean agent Q: 2.25133\n",
      "------------------------\n",
      "Saved Model, step is 4000\n",
      "Average loss is  0.29603443861\n",
      "Saving PER and importance weights\n",
      "step: 4000\n",
      "phys actions  [ 0 10 10  5 10 24 23 23  0 15  5  0 10  5  0 10  0  0 10  0  0  0 15 10 10\n",
      "  0 15  5  0  0]\n",
      "chosen actions  [ 5 10 10 15 10  0 10 15  0 10 20  0  0  0 15 20  5  0 10  0  0 15 10 20 20\n",
      "  0  0 10  0  0]\n",
      "mean abs err: 2.83485\n",
      "mean phys Q: 2.50582\n",
      "mean agent Q: 3.42861\n",
      "------------------------\n",
      "Saved Model, step is 5000\n",
      "Average loss is  0.309569881439\n",
      "Saving PER and importance weights\n",
      "step: 5000\n",
      "phys actions  [10 15  0  0  5  0  5  0  0  0  0 10  0  0  7  0  0  0  8 20  0  0 10  0  0\n",
      "  0  6  0  0  0]\n",
      "chosen actions  [10 11  0 20 10  0  0  0 21 10  5 20  0  0 20  0 10  5 15 10  0  0 10  0  0\n",
      "  0 10  0  0  0]\n",
      "mean abs err: 3.65827\n",
      "mean phys Q: 3.6807\n",
      "mean agent Q: 5.01986\n",
      "------------------------\n",
      "Saved Model, step is 6000\n",
      "Average loss is  0.318050937653\n",
      "Saving PER and importance weights\n",
      "step: 6000\n",
      "phys actions  [20  0 15  0 10 15  5  0 20 10  5 14  0 15 10 10  5 15 15 10 16 15  0  5 15\n",
      "  0  0  0  0 10]\n",
      "chosen actions  [ 0  0 10  0 10 15  5  0 10 10 10  0  5 10 10 20  0  5  0 10 10  0  0  5  5\n",
      "  0  5  0  0  0]\n",
      "mean abs err: 4.94459\n",
      "mean phys Q: 5.53314\n",
      "mean agent Q: 7.35338\n",
      "------------------------\n",
      "Saved Model, step is 7000\n",
      "Average loss is  0.273575680256\n",
      "Saving PER and importance weights\n",
      "step: 7000\n",
      "phys actions  [15 20  0  0  0 24 10  5  0 15  5  5  0 15  5  0 12  0 10  0  0  5 10  0  0\n",
      "  0  5 10  5  5]\n",
      "chosen actions  [ 5  5  0  0  0  3  5 10  0  0 10 10  0 10  0  0 10  0 10  5 20  0 15  0  5\n",
      " 10  0  0  5 10]\n",
      "mean abs err: 5.38784\n",
      "mean phys Q: 6.10813\n",
      "mean agent Q: 8.32903\n",
      "------------------------\n",
      "Saved Model, step is 8000\n",
      "Average loss is  0.30017545414\n",
      "Saving PER and importance weights\n",
      "step: 8000\n",
      "phys actions  [ 0  0  0 15  0 20  0 15  0 15  5 10  5  5  0  0 15  0 10 15 23  5 15 21 16\n",
      " 10  0  0  0 10]\n",
      "chosen actions  [ 0  0  0 15  0 10 10  5  0 10  5  5  0  0  0  0  5  5 10  0  0 10  5  0  0\n",
      " 10  0  0  0  5]\n",
      "mean abs err: 4.92137\n",
      "mean phys Q: 4.91357\n",
      "mean agent Q: 7.43484\n",
      "------------------------\n",
      "Saved Model, step is 9000\n",
      "Average loss is  0.269806869984\n",
      "Saving PER and importance weights\n",
      "step: 9000\n",
      "phys actions  [10  0  0  0  0 24 15 11 22  0  0  5  5 15 15  5  0  0  5 15  0  0  0  5 10\n",
      "  5  0  0 10  0]\n",
      "chosen actions  [10  0  5  0  0 10 10  6 15  0  0  0 10 10 10  0  0 20  5  5  0  0  5  0 15\n",
      "  5  0  0 10  0]\n",
      "mean abs err: 5.81117\n",
      "mean phys Q: 6.55598\n",
      "mean agent Q: 9.1952\n",
      "------------------------\n",
      "Saved Model, step is 10000\n",
      "Average loss is  0.280343234539\n",
      "Saving PER and importance weights\n",
      "step: 10000\n",
      "phys actions  [11 15  0  0 10 10 10  0 15  0 19  0 11  0  7 15  0 15  0 15  6 15 15  0  0\n",
      "  0  5 10  0  0]\n",
      "chosen actions  [ 5  0  0  0 10  0  5  0  0 10  0  0 17  0 10 10  0  5 11 10  5 10  0  0  0\n",
      "  0 10 20  5 20]\n",
      "mean abs err: 5.92902\n",
      "mean phys Q: 7.34357\n",
      "mean agent Q: 10.0947\n",
      "------------------------\n",
      "Saved Model, step is 11000\n",
      "Average loss is  0.254252396584\n",
      "Saving PER and importance weights\n",
      "step: 11000\n",
      "phys actions  [ 0 20  0  0 10  5  5  0 10  0  0  0 15  0 23  0 15 12  5  5 14  5  5 15  0\n",
      " 10 16  0  0  5]\n",
      "chosen actions  [ 0  5  0  0 10 10 10  0  0  0  0  0 10  0 10  0 11  5 17  5 10  0  5 10  0\n",
      "  0 10  0  0  5]\n",
      "mean abs err: 5.62352\n",
      "mean phys Q: 7.22464\n",
      "mean agent Q: 10.0644\n",
      "------------------------\n",
      "Saved Model, step is 12000\n",
      "Average loss is  0.234470238686\n",
      "Saving PER and importance weights\n",
      "step: 12000\n",
      "phys actions  [ 7  0 20 10 10  5  0 10  5  0 15  5 16  0  0  0  5  0  0 10 20  5 10  0  5\n",
      "  0 14  0  0 10]\n",
      "chosen actions  [ 0  5 10  5 10 10  5 10 10  0  0  0 17  0  0  0  0  0  0 10 15  0 10  0  0\n",
      "  0  5  0  0 20]\n",
      "mean abs err: 5.79555\n",
      "mean phys Q: 7.57764\n",
      "mean agent Q: 10.1814\n",
      "------------------------\n",
      "Saved Model, step is 13000\n",
      "Average loss is  0.268302616119\n",
      "Saving PER and importance weights\n",
      "step: 13000\n",
      "phys actions  [ 0  0  0 20  0  0  0  2  0  5  0  5  0 10  0  5 15  0  5 22 12  5 20  0 15\n",
      "  5  5 20  0 20]\n",
      "chosen actions  [ 0  0  0 15  0 20  0 11 15 17  0  5  0 17  5  0 10 20  5  0  0 20  0  5  0\n",
      "  5 10  0  0  0]\n",
      "mean abs err: 5.75729\n",
      "mean phys Q: 7.66667\n",
      "mean agent Q: 10.2284\n",
      "------------------------\n",
      "Saved Model, step is 14000\n",
      "Average loss is  0.247838110924\n",
      "Saving PER and importance weights\n",
      "step: 14000\n",
      "phys actions  [ 0  0  5  0  0  0  0 23  0 22 10 15  0  0  0 15 19  0  5  0 15 20  0  0  0\n",
      "  0 24 15  0  0]\n",
      "chosen actions  [ 0  0  5  0  0  0 20 15  0  0  0 10  0 10  0 10 17  0  5  0 17  5  0  0  0\n",
      "  0 10  0  0 23]\n",
      "mean abs err: 5.27296\n",
      "mean phys Q: 7.19331\n",
      "mean agent Q: 10.0952\n",
      "------------------------\n",
      "Saved Model, step is 15000\n",
      "Average loss is  0.308837848186\n",
      "Saving PER and importance weights\n",
      "step: 15000\n",
      "phys actions  [ 0  0 16 10 20  0  5  0  0 15 16  0 16  5 21 12  5 10  0 24 20 20  0  0 10\n",
      " 15  4 15 20 15]\n",
      "chosen actions  [ 0  0  5 20 15  0  6  0  0  0  5  0  5  0 15  5  0  0 20 10  0 11 10  0 10\n",
      "  0  0 10 10  0]\n",
      "mean abs err: 5.3453\n",
      "mean phys Q: 7.71542\n",
      "mean agent Q: 10.4352\n",
      "------------------------\n",
      "Saved Model, step is 16000\n",
      "Average loss is  0.257824433327\n",
      "Saving PER and importance weights\n",
      "step: 16000\n",
      "phys actions  [ 0  0  5  5  0  0  0 10 10  0  0 10 21 10  0  0 24 20  5 15  0 10 19  0  0\n",
      " 20  0  5  0  5]\n",
      "chosen actions  [ 0  0  0  5  0  0  0 11 17  0  0 20  0  0  0  0  5  5 10  6  5  0 17  0  5\n",
      "  5  0  0  0  0]\n",
      "mean abs err: 5.16397\n",
      "mean phys Q: 7.41744\n",
      "mean agent Q: 9.98859\n",
      "------------------------\n",
      "Saved Model, step is 17000\n",
      "Average loss is  0.280550981522\n",
      "Saving PER and importance weights\n",
      "step: 17000\n",
      "phys actions  [14  5 10  5 13 19 20  0 20 14  0 17 20  0  0 15 10  0  5  0  0  0  0 10  0\n",
      "  5  5  0 15  7]\n",
      "chosen actions  [11  0 10  5  5  5 15 20 20  0  5  5 15 15  0  5  0  5  0  0  0  0  0  0  0\n",
      "  0  5  0  0  5]\n",
      "mean abs err: 5.41487\n",
      "mean phys Q: 8.05549\n",
      "mean agent Q: 10.4788\n",
      "------------------------\n",
      "Saved Model, step is 18000\n",
      "Average loss is  0.271107307434\n",
      "Saving PER and importance weights\n",
      "step: 18000\n",
      "phys actions  [21 10  6  0  0  0  5  0  5  0 19  0 20  0  6 22  0 12  5  0  5  0 24  5 15\n",
      "  0  0 10 17  0]\n",
      "chosen actions  [ 0  0  5  0  5  0 17  5  0  0 11  5  5  5  0  5  0 11  0  5  0  0  0  5  5\n",
      "  0  5 20 11  5]\n",
      "mean abs err: 5.11828\n",
      "mean phys Q: 7.5649\n",
      "mean agent Q: 10.0649\n",
      "------------------------\n",
      "Saved Model, step is 19000\n",
      "Average loss is  0.247789679527\n",
      "Saving PER and importance weights\n",
      "step: 19000\n",
      "phys actions  [ 0 13  0 21  0 15  0 15  0  5  0 15  0 15  0  0  5 10 15  0 20  5 20  0  5\n",
      " 18 10  0  0  0]\n",
      "chosen actions  [ 5  5  0  0  0 20  0  0  0 10  5  0  0  0  0  5  0 20  5  0  5 11  7  0  0\n",
      " 15  5 24  0 17]\n",
      "mean abs err: 5.38736\n",
      "mean phys Q: 8.48868\n",
      "mean agent Q: 10.8528\n",
      "------------------------\n",
      "Saved Model, step is 20000\n",
      "Average loss is  0.228731746197\n",
      "Saving PER and importance weights\n",
      "step: 20000\n",
      "phys actions  [ 0  0 10  0  0  0  5  5 11  7 10  0  5 21  6  0  0  0  5 10  0  0  0  5  0\n",
      "  0  0 16  0 10]\n",
      "chosen actions  [ 0  0  6  0  0  0 20  5  0  0 15  5  6 17 11  0  0  5 23 21  0  5  5  0 20\n",
      "  0  0  5  0  5]\n",
      "mean abs err: 5.83823\n",
      "mean phys Q: 9.26723\n",
      "mean agent Q: 11.5892\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Model, step is 21000\n",
      "Average loss is  0.166966172695\n",
      "Saving PER and importance weights\n",
      "step: 21000\n",
      "phys actions  [ 0  0  0 20 20 10  0 18  5  6  0 22  0 15  0  5 13  0  5 18  0  0  0  0 20\n",
      "  0 23 16  0  0]\n",
      "chosen actions  [15  0  5  0  5  0  0  5  5  0  5  5  0 11  0 10  5  0  0  6  0  5  0  0  6\n",
      "  5 15  5  0 15]\n",
      "mean abs err: 5.83582\n",
      "mean phys Q: 9.33849\n",
      "mean agent Q: 11.6623\n",
      "------------------------\n",
      "Saved Model, step is 22000\n",
      "Average loss is  0.208119170189\n",
      "Saving PER and importance weights\n",
      "step: 22000\n",
      "phys actions  [ 0  8 10 15  0  0  5  0  0 12  0  0 15  5  0  0 15 15 20 18  5  0 15  0  0\n",
      " 10  0 10  0  0]\n",
      "chosen actions  [ 0 20  0 15  0  5  0  5  0  0  0  5  5  5  0 15  5 20 15 17  5  5 17  0 15\n",
      " 15  0  0  0  0]\n",
      "mean abs err: 5.33354\n",
      "mean phys Q: 8.70892\n",
      "mean agent Q: 11.0427\n",
      "------------------------\n",
      "Saved Model, step is 23000\n",
      "Average loss is  0.212064511299\n",
      "Saving PER and importance weights\n",
      "step: 23000\n",
      "phys actions  [ 5  0  0 20  5  0  0  0  0  0 10 20  6 23  0 20 20  0 10 10  5 15  5  0 15\n",
      "  0  5  0 10 12]\n",
      "chosen actions  [ 5  0  0  5  5  0 10  0  0  0  5 17  5  0  0  0 20  0  6 20  5  5  6  0  0\n",
      " 10  0  0  5  0]\n",
      "mean abs err: 6.16902\n",
      "mean phys Q: 10.211\n",
      "mean agent Q: 12.3879\n",
      "------------------------\n",
      "Saved Model, step is 24000\n",
      "Average loss is  0.1972964468\n",
      "Saving PER and importance weights\n",
      "step: 24000\n",
      "phys actions  [15  0  5 10 10  0  5  5  0  0  0  5 15 18  0  0 15 20  0  0 19  0  4  0  5\n",
      "  5  5  0  0 13]\n",
      "chosen actions  [ 0  0  5  0  0  5  5  5  5  0  5 10  5  5  0 15 15  0  0  0  5  0 15 15  5\n",
      "  5  0  5 22 17]\n",
      "mean abs err: 5.26252\n",
      "mean phys Q: 8.87944\n",
      "mean agent Q: 11.0485\n",
      "------------------------\n",
      "Saved Model, step is 25000\n",
      "Average loss is  0.210739531994\n",
      "Saving PER and importance weights\n",
      "step: 25000\n",
      "phys actions  [ 0  0  5  5  0  0  5 15  8  0  0  0  0  5  0 10  0  0 11  5 15  5 15  0  0\n",
      "  0  0  5  5 20]\n",
      "chosen actions  [ 5 10  5  5  0 20  5  5  5  0  0  0  0  0  0  5 24 15 17  5 20  5 17 20 15\n",
      "  5  5  0  5 20]\n",
      "mean abs err: 6.18774\n",
      "mean phys Q: 10.5177\n",
      "mean agent Q: 12.5885\n",
      "------------------------\n",
      "Saved Model, step is 26000\n",
      "Average loss is  0.205973089218\n",
      "Saving PER and importance weights\n",
      "step: 26000\n",
      "phys actions  [22  0 20 20  5  0  5  0  0 15 22  0  0 24  0 10  0  5 20  0 21  0  0  0 20\n",
      "  0  0  0 10  5]\n",
      "chosen actions  [ 5  0  5  5  0  0  5  0  0  5  5 15  0  5 20  6  0 11  0  0 17  0  0  0  5\n",
      "  5 24  0  5  5]\n",
      "mean abs err: 5.65826\n",
      "mean phys Q: 9.90506\n",
      "mean agent Q: 12.0594\n",
      "------------------------\n",
      "Saved Model, step is 27000\n",
      "Average loss is  0.173785638809\n",
      "Saving PER and importance weights\n",
      "step: 27000\n",
      "phys actions  [10  5 20 15 10  0 10 15  0 20  5  0 18  0  0  5 10 10  0  0  0  0  0  5  0\n",
      "  5  0 24  0  0]\n",
      "chosen actions  [ 0  0 20  5  5  0 10  5  0  5  5 15 11 15  5  5  5  5 10  5  0  0  5  5  0\n",
      "  0  0  5 20 10]\n",
      "mean abs err: 5.82034\n",
      "mean phys Q: 10.0919\n",
      "mean agent Q: 12.1909\n",
      "------------------------\n",
      "Saved Model, step is 28000\n",
      "Average loss is  0.232567957878\n",
      "Saving PER and importance weights\n",
      "step: 28000\n",
      "phys actions  [23 15  0  0 14  0  0  0  0 22 10  8  0 20  5 15 10 20  0  5 10 20  0  5  0\n",
      " 10 24  0  0  0]\n",
      "chosen actions  [17  5  5  0  5 20  0  5  0  5  0  5  5  0  0 20 20 15  0  5 20  5  0  5  5\n",
      "  5  5 15  5  0]\n",
      "mean abs err: 5.60581\n",
      "mean phys Q: 9.76375\n",
      "mean agent Q: 11.8633\n",
      "------------------------\n",
      "Saved Model, step is 29000\n",
      "Average loss is  0.2626419034\n",
      "Saving PER and importance weights\n",
      "step: 29000\n",
      "phys actions  [ 0  0 20  6  0 10  0  0  5  5  0 15 15  0  5  9 15 10 10 18  0  0  0  0  5\n",
      "  5 16  0 10 20]\n",
      "chosen actions  [ 0  0 17  6  0  5  0  5 20  0  0 20  5 15  5  5 10  0  0 10  0  0  5 15  0\n",
      "  5  5  0  6 15]\n",
      "mean abs err: 6.41112\n",
      "mean phys Q: 11.2951\n",
      "mean agent Q: 13.3073\n",
      "------------------------\n",
      "Saved Model, step is 30000\n",
      "Average loss is  0.173281766891\n",
      "Saving PER and importance weights\n",
      "step: 30000\n",
      "phys actions  [10  5  0  5  0 15 16 11  0  0  0  0  0  5  0 20  0  0  0  0  6  0 10 13  0\n",
      " 10 20  0  0  0]\n",
      "chosen actions  [ 5  0 20  5  5 22 17  5  0  0  5 20  0  5  0  5  0 15  5  5  5  0 22 17  0\n",
      "  0  5 15  0  5]\n",
      "mean abs err: 6.34677\n",
      "mean phys Q: 11.0159\n",
      "mean agent Q: 13.1132\n",
      "------------------------\n",
      "Saved Model, step is 31000\n",
      "Average loss is  0.188650093555\n",
      "Saving PER and importance weights\n",
      "step: 31000\n",
      "phys actions  [ 0 20 10  2  0 15  0 13  0 15 15  0 13 10  0  0 10 20  0  0  5  0  0  0  0\n",
      "  0  0  0 15  0]\n",
      "chosen actions  [ 0 22 23  0 15 15  0 17  0  5 24  0 20 17 22 20  5 20  5 10  0  0  5  0 20\n",
      "  0  0  0  5  5]\n",
      "mean abs err: 5.62616\n",
      "mean phys Q: 10.0323\n",
      "mean agent Q: 12.0849\n",
      "------------------------\n",
      "Saved Model, step is 32000\n",
      "Average loss is  0.167225791931\n",
      "Saving PER and importance weights\n",
      "step: 32000\n",
      "phys actions  [ 0 10  0 10  0 20  0  0 24 10  0  0 15 10 10  0 22 24 22  0 15  5 10  5 15\n",
      "  7 10 20 24  5]\n",
      "chosen actions  [ 0  5  0  5 20  0  5  0 20  5  5  0 15  5  0  0  5  5 11 15 20 15  5 20  0\n",
      "  0  5 17  0 20]\n",
      "mean abs err: 6.16615\n",
      "mean phys Q: 10.8802\n",
      "mean agent Q: 12.8715\n",
      "------------------------\n",
      "Saved Model, step is 33000\n",
      "Average loss is  0.193300648689\n",
      "Saving PER and importance weights\n",
      "step: 33000\n",
      "phys actions  [ 0  0 10  5  5  0  9  0 10  5  0  5 10 10 10 15  0 10 10 10  0 12 20  0 16\n",
      " 20 15  0  0 10]\n",
      "chosen actions  [ 5  0 20  5  0  5 22 15 17 10  0  5  5  5  0 15  0  0  0  6 20 10  5 15 17\n",
      " 24  0  0 10 10]\n",
      "mean abs err: 5.80792\n",
      "mean phys Q: 10.3278\n",
      "mean agent Q: 12.332\n",
      "------------------------\n",
      "Saved Model, step is 34000\n",
      "Average loss is  0.180326934338\n",
      "Saving PER and importance weights\n",
      "step: 34000\n",
      "phys actions  [ 6  0 15 15  5  0  0  0  0 13  5  0  0 20  0 10 20 15  5 10 10  0 15  5  0\n",
      " 20 15  0  0 15]\n",
      "chosen actions  [ 0 20  0  0  5  0 20 10  5  5  0  5  0  0 20 23  5 20  5 20 15  0  0  0 20\n",
      " 17 17 24 20  5]\n",
      "mean abs err: 5.85634\n",
      "mean phys Q: 10.5766\n",
      "mean agent Q: 12.5537\n",
      "------------------------\n",
      "Saved Model, step is 35000\n",
      "Average loss is  0.145182888031\n",
      "Saving PER and importance weights\n",
      "step: 35000\n",
      "phys actions  [ 5 15  0 16  0 13  0  0  0  0  0 23  0  0  0  5  0  0  5  0  0  5  0 12  4\n",
      "  0  5  0  0  5]\n",
      "chosen actions  [ 5 20  5  6 15  5  5  6  5  5  5  5  0  0  0  0  5  0  0 20  5 24 15 15  5\n",
      " 20 15 20 24  5]\n",
      "mean abs err: 5.89324\n",
      "mean phys Q: 10.5483\n",
      "mean agent Q: 12.5473\n",
      "------------------------\n",
      "Saved Model, step is 36000\n",
      "Average loss is  0.159242776871\n",
      "Saving PER and importance weights\n",
      "step: 36000\n",
      "phys actions  [10 12  0  0  5 10  0 24  0 10  0  0 10  0  5  0 15  0  0  0 10  0  0 15  0\n",
      "  0 10 20 24 20]\n",
      "chosen actions  [ 0  5  5  5 20  6  0  0 15 20  0  0 23  0 15  0  5  5  0  5 24  0 10 20  0\n",
      "  5  5  6  0 10]\n",
      "mean abs err: 6.24234\n",
      "mean phys Q: 11.21\n",
      "mean agent Q: 13.0248\n",
      "------------------------\n",
      "Saved Model, step is 37000\n",
      "Average loss is  0.270222590446\n",
      "Saving PER and importance weights\n",
      "step: 37000\n",
      "phys actions  [ 3  0  1  0 10 12  0 20  0  5  0 10 10  6  0  0  5 10  5 17 10 10  0 15 10\n",
      " 15  0 10 23  0]\n",
      "chosen actions  [19  0 20  0 15  0 15  5  5 20  0 21  0  6  0 20  0 15 15  5 20  5  5 17  5\n",
      " 20  5  0  0 20]\n",
      "mean abs err: 5.64651\n",
      "mean phys Q: 10.3452\n",
      "mean agent Q: 12.2341\n",
      "------------------------\n",
      "Saved Model, step is 38000\n",
      "Average loss is  0.200218403816\n",
      "Saving PER and importance weights\n",
      "step: 38000\n",
      "phys actions  [ 0 10  0 20 15  5  0  0  5  0  0  0  5  0 16 10  5  0  5  0  0 10  0  5  0\n",
      " 15  0  0 10  0]\n",
      "chosen actions  [ 5  5  0 15 24  0 20 15  0  5 15 15 22  0 20  5  0  0  5 20  5  5 20 20  5\n",
      "  5  5  0 15  0]\n",
      "mean abs err: 5.99914\n",
      "mean phys Q: 10.7923\n",
      "mean agent Q: 12.672\n",
      "------------------------\n",
      "Saved Model, step is 39000\n",
      "Average loss is  0.196401801109\n",
      "Saving PER and importance weights\n",
      "step: 39000\n",
      "phys actions  [15  5 14  0 15 10  0  0  0  0 20  5  0  8  0 22  5  0  5  0  5  0  0  5  0\n",
      "  0 10  0 20  5]\n",
      "chosen actions  [ 0  0  0  0 17  5 15  0 20 15 17  0 20  0  0  5  0  5 10 20  5  0 20  0 15\n",
      " 10  5 20  5  0]\n",
      "mean abs err: 5.74224\n",
      "mean phys Q: 10.4401\n",
      "mean agent Q: 12.3716\n",
      "------------------------\n",
      "Saved Model, step is 40000\n",
      "Average loss is  0.17449643898\n",
      "Saving PER and importance weights\n",
      "step: 40000\n",
      "phys actions  [10  0  0  0  5  0 15 10 20  0  0  0  0  0  0 21 15 15 10  0 15 13 13  0  0\n",
      "  5 10  5  0  0]\n",
      "chosen actions  [ 6  5  5  5  5 17 20 15  5  0 20  5 12  6 20 17  0  0  5  0 10  0 15  0  0\n",
      "  5 20 20  5  5]\n",
      "mean abs err: 5.60082\n",
      "mean phys Q: 10.3763\n",
      "mean agent Q: 12.2796\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Model, step is 41000\n",
      "Average loss is  0.241033299923\n",
      "Saving PER and importance weights\n",
      "step: 41000\n",
      "phys actions  [20  0  0 18  0  0  0  5  0 10  0  5  5  5 18  0 15  0 15 23  0 10  0 10  0\n",
      " 18  0  0 10  5]\n",
      "chosen actions  [24  0  0 15  5  0  5  0  5  5  0 17 10  6  5 10  0  5 17  0  0 20  5 20 20\n",
      "  0  0 20 15  7]\n",
      "mean abs err: 6.11148\n",
      "mean phys Q: 11.1415\n",
      "mean agent Q: 13.0594\n",
      "------------------------\n",
      "Saved Model, step is 42000\n",
      "Average loss is  0.19483852005\n",
      "Saving PER and importance weights\n",
      "step: 42000\n",
      "phys actions  [15 15  0 10 21 15 10  5 11 20  0 15  0  0  0  0  0  5  0  5 10  0  0  0  0\n",
      "  0 12  0  5  0]\n",
      "chosen actions  [17  5 22 15 17 10  0  0  5 17  0 23 10 20  5  0 15  0  5  0 24  5  0 20 15\n",
      "  0 24 15  5  0]\n",
      "mean abs err: 5.41902\n",
      "mean phys Q: 10.2101\n",
      "mean agent Q: 12.1203\n",
      "------------------------\n",
      "Saved Model, step is 43000\n",
      "Average loss is  0.198598357201\n",
      "Saving PER and importance weights\n",
      "step: 43000\n",
      "phys actions  [ 7  0  0 13 20  0  0  5  0  5  0  5 10 10  0 15 10  0  0 10 15  0  0 15 15\n",
      "  8 13 15 15  5]\n",
      "chosen actions  [ 5  5 20  0 20  5  5  0  0  0 20  5 15 20 20  0  0 15  5  6  6 15  0 15 20\n",
      "  0 20  0 15 22]\n",
      "mean abs err: 5.85474\n",
      "mean phys Q: 10.7498\n",
      "mean agent Q: 12.6732\n",
      "------------------------\n",
      "Saved Model, step is 44000\n",
      "Average loss is  0.157502429008\n",
      "Saving PER and importance weights\n",
      "step: 44000\n",
      "phys actions  [ 0 15 20  0  0  0  6  0  0  0 15 15 10  0  0  5  0  0 23  5  0  0 15  0  0\n",
      "  0 24 10  0  0]\n",
      "chosen actions  [12 15  5  0  0  5 17  0  0 10 20  0 17 22 20  0 15 15  0  0 20  0  0  0 15\n",
      "  0  6 17  0  0]\n",
      "mean abs err: 5.58243\n",
      "mean phys Q: 10.3804\n",
      "mean agent Q: 12.3093\n",
      "------------------------\n",
      "Saved Model, step is 45000\n",
      "Average loss is  0.227029946327\n",
      "Saving PER and importance weights\n",
      "step: 45000\n",
      "phys actions  [10 14 15 23  5  0  0  0  0  0  5  0  5  0 10  0  0  0 10  0  5  0 10 10 15\n",
      "  0  0  5  0  0]\n",
      "chosen actions  [ 0 20 20  0 20  5  0  0 20  5 15  5  0  5 24  5  0  0 17  5 17 10  0 10  5\n",
      " 15 20  0  5  0]\n",
      "mean abs err: 4.898\n",
      "mean phys Q: 9.21894\n",
      "mean agent Q: 11.1591\n",
      "------------------------\n",
      "Saved Model, step is 46000\n",
      "Average loss is  0.240510702133\n",
      "Saving PER and importance weights\n",
      "step: 46000\n",
      "phys actions  [10 17  0  5 10 10  5  0 20 16  0  5  0 22 15 10  0  0 23 16  0 15 11 16  0\n",
      "  0  0  0  0  5]\n",
      "chosen actions  [ 0 15  0 15  0  0  6 20  5 20 15  0 20  0  5 15  5  5  5 10 20 15  6  0 15\n",
      " 10  0  0 15 15]\n",
      "mean abs err: 5.49157\n",
      "mean phys Q: 10.3493\n",
      "mean agent Q: 12.2722\n",
      "------------------------\n",
      "Saved Model, step is 47000\n",
      "Average loss is  0.163772458076\n",
      "Saving PER and importance weights\n",
      "step: 47000\n",
      "phys actions  [19  5  0 10  5  0 20 10  0  0  0 10 10  0 15 15 24  0 15  0  0  5  5  5  0\n",
      "  0 10  5  0  0]\n",
      "chosen actions  [ 0  0  5  0 15 20 17 15  5  0  0  0  5  5  0  0  5 20 21 24 20  5 20 19  0\n",
      "  5 20  0 15 20]\n",
      "mean abs err: 5.93856\n",
      "mean phys Q: 11.013\n",
      "mean agent Q: 12.8826\n",
      "------------------------\n",
      "Saved Model, step is 48000\n",
      "Average loss is  0.134400252342\n",
      "Saving PER and importance weights\n",
      "step: 48000\n",
      "phys actions  [ 0  5 10  0 13 22  0  5 20 10 15  5 15  5  0  5  0  0 15 15 15  0  0 10  5\n",
      " 20  0  0  0  0]\n",
      "chosen actions  [ 5  6  7 15  0 17 10 20  0  0  6  5 20  5 15 20 15  5 15 20 15  5 15 20  5\n",
      " 20  0  0 20  0]\n",
      "mean abs err: 4.9909\n",
      "mean phys Q: 9.56304\n",
      "mean agent Q: 11.5688\n",
      "------------------------\n",
      "Saved Model, step is 49000\n",
      "Average loss is  0.148740531921\n",
      "Saving PER and importance weights\n",
      "step: 49000\n",
      "phys actions  [10  0  7 10 15  5 20  0 10  5  5  0  8 20  5 10 13 15 23 10  5  0  5  8  0\n",
      "  0 10  0  0  0]\n",
      "chosen actions  [ 5 20 20 24 10  6  5 10  7  0 15 20  0  0  5  0 15 15  0 22  0 20  0  0 15\n",
      "  0  0  0 20 10]\n",
      "mean abs err: 5.42828\n",
      "mean phys Q: 10.1368\n",
      "mean agent Q: 12.144\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(3)\n",
    "np.random.seed(3)\n",
    "# The main training loop is here\n",
    "per_alpha = 0.6 # PER hyperparameter\n",
    "per_epsilon = 0.01 # PER hyperparameter\n",
    "batch_size = 30 #How many experiences to use for each training step.\n",
    "gamma = 0.99 #Discount factor on the target Q-values\n",
    "num_steps = 50000\n",
    "load_model = False #Whether to load a saved model.\n",
    "save_dir = '../../data/dqn/'\n",
    "save_path = \"./model/\"#The path to save our model to.\n",
    "tau = 0.001 #Rate to update target network toward primary network\n",
    "tf.reset_default_graph()\n",
    "mainQN = Qnetwork()\n",
    "targetQN = Qnetwork()\n",
    "av_q_list = []\n",
    "save_results = False\n",
    "\n",
    "saver = tf.train.Saver(tf.global_variables())\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "trainables = tf.trainable_variables()\n",
    "target_ops = update_target_graph(trainables, tau)\n",
    "\n",
    "#Make a path for our model to be saved in.\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "loss_hist = []\n",
    "mean_q_hist = [] # (step, phy_q, agent_q)\n",
    "with tf.Session() as sess:\n",
    "    if load_model == True:\n",
    "        print('Trying to load model...')\n",
    "        try:\n",
    "            restorer = tf.train.import_meta_graph(save_path + 'ckpt.meta')\n",
    "            restorer.restore(sess, tf.train.latest_checkpoint(save_dir))\n",
    "            print (\"Model restored\")\n",
    "        except IOError:\n",
    "            print (\"No previous model found, running default init\")\n",
    "            sess.run(init)\n",
    "        try:\n",
    "            per_weights = pickle.load(open( save_dir + \"per_weights.p\", \"rb\" ))\n",
    "            imp_weights = pickle.load(open( save_dir + \"imp_weights.p\", \"rb\" ))\n",
    "            \n",
    "            # the PER weights, governing probability of sampling, and importance sampling\n",
    "            # weights for use in the gradient descent updates\n",
    "            train['prob'] = per_weights\n",
    "            train['imp_weight'] = imp_weights\n",
    "            print (\"PER and Importance weights restored\")\n",
    "        except IOError:\n",
    "            print(\"No PER weights found - default being used for PER and importance sampling\")\n",
    "    else:\n",
    "        print(\"Running default init\")\n",
    "        sess.run(init)\n",
    "    print(\"Init done\")\n",
    "    \n",
    "    for i in range(num_steps):\n",
    "        \n",
    "        if save_results:\n",
    "            do_save_results()\n",
    "            break\n",
    "            \n",
    "        net_loss = 0.0\n",
    "        net_q = 0.0\n",
    "        states, actions, rewards, next_states, done_flags, sampled_df = process_batch(batch_size)\n",
    "        # firstly get the chosen actions at the next timestep\n",
    "        actions_from_q1 = sess.run(mainQN.predict, feed_dict={mainQN.state:next_states, mainQN.phase : 1})\n",
    "        # actions chosen now, as a check\n",
    "        cur_act = sess.run(mainQN.predict, feed_dict={mainQN.state:states, mainQN.phase : 1})\n",
    "        \n",
    "        # Q values for the next timestep from target network, as part of the Double DQN update\n",
    "        Q2 = sess.run(targetQN.q_output, feed_dict={targetQN.state:next_states, targetQN.phase : 1})\n",
    "        # handles the case when a trajectory is finished\n",
    "        end_multiplier = 1 - done_flags\n",
    "        \n",
    "        # target Q value using Q values from target, and actions from main\n",
    "        double_q_value = Q2[range(batch_size), actions_from_q1]\n",
    "        \n",
    "        # empirical hack to make the Q values never exceed the threshold - helps learning\n",
    "        double_q_value[double_q_value > REWARD_THRESHOLD] = REWARD_THRESHOLD\n",
    "        double_q_value[double_q_value < -REWARD_THRESHOLD] = -REWARD_THRESHOLD\n",
    "        \n",
    "        # definition of target Q\n",
    "        targetQ = rewards + (gamma * double_q_value * end_multiplier)\n",
    "        \n",
    "        # Calculate the importance sampling weights for PER\n",
    "        imp_sampling_weights = np.array(sampled_df['imp_weight'] / float(max(train['imp_weight'])))\n",
    "        imp_sampling_weights[np.isnan(imp_sampling_weights)] = 1\n",
    "        imp_sampling_weights[imp_sampling_weights <= 0.001] = 0.001\n",
    "        \n",
    "        # Train with the batch\n",
    "        _, loss, error, q_output = sess.run([mainQN.update_model, mainQN.loss, mainQN.abs_error, mainQN.q_output], \\\n",
    "            feed_dict={mainQN.state: states,\n",
    "                       mainQN.targetQ: targetQ, \n",
    "                       mainQN.actions: actions,\n",
    "                       mainQN.phase: True,\n",
    "                       mainQN.imp_weights: imp_sampling_weights})\n",
    "        \n",
    "        update_target(target_ops, sess)\n",
    "        \n",
    "        net_loss += sum(error)\n",
    "        net_q += np.mean(targetQ)\n",
    "        \n",
    "        # Set the selection weight/prob to the abs prediction error and update the importance sampling weight\n",
    "        new_weights = pow((error + per_epsilon), per_alpha)\n",
    "        train.loc[train.index.isin(sampled_df.index), 'prob'] = new_weights\n",
    "        temp = 1.0 / new_weights\n",
    "        train.loc[train.index.isin(sampled_df.index), 'imp_weight'] = pow(((1.0/len(train)) * temp), beta_start)\n",
    "        \n",
    "        if i % 1000 == 0 and i > 0:\n",
    "            saver.save(sess, save_path)\n",
    "            print(\"Saved Model, step is \" + str(i))\n",
    "            \n",
    "            av_loss = net_loss / 1000.0\n",
    "            loss_hist += [ (i, av_loss) ]\n",
    "            print(\"Average loss is \", av_loss)\n",
    "            net_loss = 0.0\n",
    "             \n",
    "            print (\"Saving PER and importance weights\")\n",
    "            with open(save_dir + 'per_weights.p', 'wb') as f:\n",
    "                pickle.dump(train['prob'], f)\n",
    "            with open(save_dir + 'imp_weights.p', 'wb') as f:\n",
    "                pickle.dump(train['imp_weight'], f)\n",
    "        \n",
    "        if (i % 1000 == 0) and i > 0:\n",
    "            print ('step:', i)\n",
    "            print (\"phys actions \", actions)\n",
    "            print (\"chosen actions \", cur_act)\n",
    "            if i >= 1000:\n",
    "                # run an evaluation on the validation set\n",
    "                phys_q, phys_actions, agent_q, agent_actions, mean_abs_error = do_eval(eval_type = 'test')\n",
    "                mean_q_hist += [ ( i, np.mean(phys_q),  np.mean(agent_q)) ]\n",
    "                print ('mean abs err:', mean_abs_error)\n",
    "                print ('mean phys Q:', np.mean(phys_q))\n",
    "                print ('mean agent Q:', np.mean(agent_q))\n",
    "            print ('------------------------')\n",
    "        \n",
    "        if i == num_steps - 1:\n",
    "            phys_q_train, phys_actions_train, agent_q_train, agent_actions_train, _ = do_eval(eval_type = 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     55812\n",
       "5     22690\n",
       "15    21083\n",
       "20    19297\n",
       "17     7550\n",
       "24     6426\n",
       "6      5280\n",
       "10     5204\n",
       "22     1717\n",
       "23     1572\n",
       "21     1189\n",
       "16      734\n",
       "7       705\n",
       "13      573\n",
       "12      329\n",
       "19      200\n",
       "8        96\n",
       "2        92\n",
       "4        65\n",
       "18       64\n",
       "14       54\n",
       "11        7\n",
       "1         1\n",
       "9         1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(agent_actions_train).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x12457a9e8>"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\naNB3RDz+5BIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x120c13f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "% matplotlib inline\n",
    "pd.Series(agent_actions_train).hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1230c3a20>"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npIbhIElqGA6SpIbhIElq/D9HqsqFqubg5QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1208b8400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "% matplotlib inline\n",
    "pd.Series(agent_actions).hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x121b46a20>"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x120b3c978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "% matplotlib inline\n",
    "pd.Series(phys_actions).hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps, losses = zip(*loss_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps, losses = list(steps), list(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x124cc2a58>]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD8CAYAAACYebj1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12188b6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(steps, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_, phy_qs, agent_qs = zip(*mean_q_hist)\n",
    "phy_qs, agent_qs = list(phy_qs),list(agent_qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.lines.Line2D at 0x1259c9390>],\n",
       " [<matplotlib.lines.Line2D at 0x1259c9550>])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIYSoIP4f5lMxrHQVVfcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x121c9b588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(steps, phy_qs), plt.plot(steps, agent_qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(agent_actions_train, open('r4/agent_actions_train.pkl', 'wb'))\n",
    "pickle.dump(agent_q_train, open('r4/agent_mean_q_train.pkl', 'wb'))\n",
    "pickle.dump(phys_actions_train, open('r4/phy_actions_train.pkl', 'wb'))\n",
    "pickle.dump(phys_q_train, open('r4/phy_mean_q_train.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(agent_actions, open('r4/agent_actions_test.pkl', 'wb'))\n",
    "pickle.dump(agent_q, open('r4/agent_mean_q_test.pkl', 'wb'))\n",
    "pickle.dump(phys_actions, open('r4/phy_actions_test.pkl', 'wb'))\n",
    "pickle.dump(phys_q, open('r4/phy_mean_q_test.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
