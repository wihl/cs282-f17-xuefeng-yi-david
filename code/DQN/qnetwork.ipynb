{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import math\n",
    "import copy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "      <th>vaso_input</th>\n",
       "      <th>iv_input</th>\n",
       "      <th>reward</th>\n",
       "      <th>icustayid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.029027</td>\n",
       "      <td>0.061212</td>\n",
       "      <td>0.224086</td>\n",
       "      <td>0.079448</td>\n",
       "      <td>0.052524</td>\n",
       "      <td>0.077151</td>\n",
       "      <td>0.103817</td>\n",
       "      <td>0.063714</td>\n",
       "      <td>0.032102</td>\n",
       "      <td>0.042459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083823</td>\n",
       "      <td>0.053838</td>\n",
       "      <td>0.081020</td>\n",
       "      <td>0.057297</td>\n",
       "      <td>0.030372</td>\n",
       "      <td>0.047363</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.031518</td>\n",
       "      <td>0.078677</td>\n",
       "      <td>0.120369</td>\n",
       "      <td>0.040228</td>\n",
       "      <td>0.047623</td>\n",
       "      <td>0.104624</td>\n",
       "      <td>0.093498</td>\n",
       "      <td>0.073046</td>\n",
       "      <td>0.035958</td>\n",
       "      <td>0.056553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088714</td>\n",
       "      <td>0.073047</td>\n",
       "      <td>0.083202</td>\n",
       "      <td>0.043883</td>\n",
       "      <td>0.036930</td>\n",
       "      <td>0.057726</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.030942</td>\n",
       "      <td>0.083416</td>\n",
       "      <td>0.106333</td>\n",
       "      <td>0.040481</td>\n",
       "      <td>0.039120</td>\n",
       "      <td>0.098819</td>\n",
       "      <td>0.077658</td>\n",
       "      <td>0.074696</td>\n",
       "      <td>0.041053</td>\n",
       "      <td>0.053553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092754</td>\n",
       "      <td>0.079161</td>\n",
       "      <td>0.082560</td>\n",
       "      <td>0.041910</td>\n",
       "      <td>0.036587</td>\n",
       "      <td>0.067986</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.042970</td>\n",
       "      <td>0.050963</td>\n",
       "      <td>0.090261</td>\n",
       "      <td>0.093201</td>\n",
       "      <td>0.031332</td>\n",
       "      <td>0.057674</td>\n",
       "      <td>0.032040</td>\n",
       "      <td>0.054802</td>\n",
       "      <td>0.061447</td>\n",
       "      <td>0.053960</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098049</td>\n",
       "      <td>0.074196</td>\n",
       "      <td>0.088113</td>\n",
       "      <td>0.045784</td>\n",
       "      <td>0.041096</td>\n",
       "      <td>0.129189</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.064572</td>\n",
       "      <td>0.084793</td>\n",
       "      <td>0.065976</td>\n",
       "      <td>0.070753</td>\n",
       "      <td>0.063990</td>\n",
       "      <td>0.051591</td>\n",
       "      <td>0.050112</td>\n",
       "      <td>0.049624</td>\n",
       "      <td>0.092619</td>\n",
       "      <td>0.080058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032011</td>\n",
       "      <td>0.081824</td>\n",
       "      <td>0.037519</td>\n",
       "      <td>0.061251</td>\n",
       "      <td>0.071471</td>\n",
       "      <td>0.039540</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 204 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.029027  0.061212  0.224086  0.079448  0.052524  0.077151  0.103817   \n",
       "1  0.031518  0.078677  0.120369  0.040228  0.047623  0.104624  0.093498   \n",
       "2  0.030942  0.083416  0.106333  0.040481  0.039120  0.098819  0.077658   \n",
       "3  0.042970  0.050963  0.090261  0.093201  0.031332  0.057674  0.032040   \n",
       "4  0.064572  0.084793  0.065976  0.070753  0.063990  0.051591  0.050112   \n",
       "\n",
       "          7         8         9    ...           194       195       196  \\\n",
       "0  0.063714  0.032102  0.042459    ...      0.083823  0.053838  0.081020   \n",
       "1  0.073046  0.035958  0.056553    ...      0.088714  0.073047  0.083202   \n",
       "2  0.074696  0.041053  0.053553    ...      0.092754  0.079161  0.082560   \n",
       "3  0.054802  0.061447  0.053960    ...      0.098049  0.074196  0.088113   \n",
       "4  0.049624  0.092619  0.080058    ...      0.032011  0.081824  0.037519   \n",
       "\n",
       "        197       198       199  vaso_input  iv_input  reward  icustayid  \n",
       "0  0.057297  0.030372  0.047363           0       0.0     0.0       12.0  \n",
       "1  0.043883  0.036930  0.057726           0       0.0     0.0       12.0  \n",
       "2  0.041910  0.036587  0.067986           0       0.0     0.0       12.0  \n",
       "3  0.045784  0.041096  0.129189           0       0.0    15.0       12.0  \n",
       "4  0.061251  0.071471  0.039540           0       4.0     0.0       14.0  \n",
       "\n",
       "[5 rows x 204 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../../data/train_scaled_encoded.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "      <th>vaso_input</th>\n",
       "      <th>iv_input</th>\n",
       "      <th>reward</th>\n",
       "      <th>icustayid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.044787</td>\n",
       "      <td>0.024944</td>\n",
       "      <td>0.059501</td>\n",
       "      <td>0.186372</td>\n",
       "      <td>0.099174</td>\n",
       "      <td>0.010116</td>\n",
       "      <td>0.015910</td>\n",
       "      <td>0.031792</td>\n",
       "      <td>0.063170</td>\n",
       "      <td>0.050696</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037952</td>\n",
       "      <td>0.041529</td>\n",
       "      <td>0.046699</td>\n",
       "      <td>0.054380</td>\n",
       "      <td>0.082892</td>\n",
       "      <td>0.012378</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.048257</td>\n",
       "      <td>0.029508</td>\n",
       "      <td>0.033046</td>\n",
       "      <td>0.102542</td>\n",
       "      <td>0.107019</td>\n",
       "      <td>0.015018</td>\n",
       "      <td>0.014971</td>\n",
       "      <td>0.034197</td>\n",
       "      <td>0.057205</td>\n",
       "      <td>0.072662</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037210</td>\n",
       "      <td>0.051388</td>\n",
       "      <td>0.044145</td>\n",
       "      <td>0.039312</td>\n",
       "      <td>0.096143</td>\n",
       "      <td>0.013473</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.041906</td>\n",
       "      <td>0.028968</td>\n",
       "      <td>0.028705</td>\n",
       "      <td>0.111719</td>\n",
       "      <td>0.098205</td>\n",
       "      <td>0.013579</td>\n",
       "      <td>0.012648</td>\n",
       "      <td>0.027884</td>\n",
       "      <td>0.074506</td>\n",
       "      <td>0.081935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037256</td>\n",
       "      <td>0.055131</td>\n",
       "      <td>0.042269</td>\n",
       "      <td>0.039004</td>\n",
       "      <td>0.103266</td>\n",
       "      <td>0.015244</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.040383</td>\n",
       "      <td>0.029019</td>\n",
       "      <td>0.029167</td>\n",
       "      <td>0.131740</td>\n",
       "      <td>0.099840</td>\n",
       "      <td>0.013389</td>\n",
       "      <td>0.012455</td>\n",
       "      <td>0.028260</td>\n",
       "      <td>0.072425</td>\n",
       "      <td>0.088626</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037022</td>\n",
       "      <td>0.057600</td>\n",
       "      <td>0.039294</td>\n",
       "      <td>0.038362</td>\n",
       "      <td>0.117384</td>\n",
       "      <td>0.015660</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.045685</td>\n",
       "      <td>0.029040</td>\n",
       "      <td>0.027817</td>\n",
       "      <td>0.137894</td>\n",
       "      <td>0.106901</td>\n",
       "      <td>0.013968</td>\n",
       "      <td>0.012697</td>\n",
       "      <td>0.028393</td>\n",
       "      <td>0.073113</td>\n",
       "      <td>0.088150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036816</td>\n",
       "      <td>0.058196</td>\n",
       "      <td>0.038383</td>\n",
       "      <td>0.038041</td>\n",
       "      <td>0.123431</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 204 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.044787  0.024944  0.059501  0.186372  0.099174  0.010116  0.015910   \n",
       "1  0.048257  0.029508  0.033046  0.102542  0.107019  0.015018  0.014971   \n",
       "2  0.041906  0.028968  0.028705  0.111719  0.098205  0.013579  0.012648   \n",
       "3  0.040383  0.029019  0.029167  0.131740  0.099840  0.013389  0.012455   \n",
       "4  0.045685  0.029040  0.027817  0.137894  0.106901  0.013968  0.012697   \n",
       "\n",
       "          7         8         9    ...           194       195       196  \\\n",
       "0  0.031792  0.063170  0.050696    ...      0.037952  0.041529  0.046699   \n",
       "1  0.034197  0.057205  0.072662    ...      0.037210  0.051388  0.044145   \n",
       "2  0.027884  0.074506  0.081935    ...      0.037256  0.055131  0.042269   \n",
       "3  0.028260  0.072425  0.088626    ...      0.037022  0.057600  0.039294   \n",
       "4  0.028393  0.073113  0.088150    ...      0.036816  0.058196  0.038383   \n",
       "\n",
       "        197       198       199  vaso_input  iv_input  reward  icustayid  \n",
       "0  0.054380  0.082892  0.012378           0       4.0     0.0       61.0  \n",
       "1  0.039312  0.096143  0.013473           0       4.0     0.0       61.0  \n",
       "2  0.039004  0.103266  0.015244           0       4.0     0.0       61.0  \n",
       "3  0.038362  0.117384  0.015660           0       4.0     0.0       61.0  \n",
       "4  0.038041  0.123431  0.014925           0       4.0     0.0       61.0  \n",
       "\n",
       "[5 rows x 204 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('../../data/test_scaled_encoded.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "REWARD_THRESHOLD =15\n",
    "reg_lambda = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PER important weights and params\n",
    "per_flag = True\n",
    "beta_start = 0.9\n",
    "train['prob'] = abs(train['reward'])\n",
    "temp = 1.0 / train['prob']\n",
    "temp[temp == float('Inf')] = 1.0\n",
    "train['imp_weight'] = pow((1.0 / len(train) * temp), beta_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "      <th>vaso_input</th>\n",
       "      <th>iv_input</th>\n",
       "      <th>reward</th>\n",
       "      <th>icustayid</th>\n",
       "      <th>prob</th>\n",
       "      <th>imp_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.029027</td>\n",
       "      <td>0.061212</td>\n",
       "      <td>0.224086</td>\n",
       "      <td>0.079448</td>\n",
       "      <td>0.052524</td>\n",
       "      <td>0.077151</td>\n",
       "      <td>0.103817</td>\n",
       "      <td>0.063714</td>\n",
       "      <td>0.032102</td>\n",
       "      <td>0.042459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081020</td>\n",
       "      <td>0.057297</td>\n",
       "      <td>0.030372</td>\n",
       "      <td>0.047363</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.031518</td>\n",
       "      <td>0.078677</td>\n",
       "      <td>0.120369</td>\n",
       "      <td>0.040228</td>\n",
       "      <td>0.047623</td>\n",
       "      <td>0.104624</td>\n",
       "      <td>0.093498</td>\n",
       "      <td>0.073046</td>\n",
       "      <td>0.035958</td>\n",
       "      <td>0.056553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083202</td>\n",
       "      <td>0.043883</td>\n",
       "      <td>0.036930</td>\n",
       "      <td>0.057726</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.030942</td>\n",
       "      <td>0.083416</td>\n",
       "      <td>0.106333</td>\n",
       "      <td>0.040481</td>\n",
       "      <td>0.039120</td>\n",
       "      <td>0.098819</td>\n",
       "      <td>0.077658</td>\n",
       "      <td>0.074696</td>\n",
       "      <td>0.041053</td>\n",
       "      <td>0.053553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082560</td>\n",
       "      <td>0.041910</td>\n",
       "      <td>0.036587</td>\n",
       "      <td>0.067986</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.042970</td>\n",
       "      <td>0.050963</td>\n",
       "      <td>0.090261</td>\n",
       "      <td>0.093201</td>\n",
       "      <td>0.031332</td>\n",
       "      <td>0.057674</td>\n",
       "      <td>0.032040</td>\n",
       "      <td>0.054802</td>\n",
       "      <td>0.061447</td>\n",
       "      <td>0.053960</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088113</td>\n",
       "      <td>0.045784</td>\n",
       "      <td>0.041096</td>\n",
       "      <td>0.129189</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.064572</td>\n",
       "      <td>0.084793</td>\n",
       "      <td>0.065976</td>\n",
       "      <td>0.070753</td>\n",
       "      <td>0.063990</td>\n",
       "      <td>0.051591</td>\n",
       "      <td>0.050112</td>\n",
       "      <td>0.049624</td>\n",
       "      <td>0.092619</td>\n",
       "      <td>0.080058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037519</td>\n",
       "      <td>0.061251</td>\n",
       "      <td>0.071471</td>\n",
       "      <td>0.039540</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 206 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.029027  0.061212  0.224086  0.079448  0.052524  0.077151  0.103817   \n",
       "1  0.031518  0.078677  0.120369  0.040228  0.047623  0.104624  0.093498   \n",
       "2  0.030942  0.083416  0.106333  0.040481  0.039120  0.098819  0.077658   \n",
       "3  0.042970  0.050963  0.090261  0.093201  0.031332  0.057674  0.032040   \n",
       "4  0.064572  0.084793  0.065976  0.070753  0.063990  0.051591  0.050112   \n",
       "\n",
       "          7         8         9     ...           196       197       198  \\\n",
       "0  0.063714  0.032102  0.042459     ...      0.081020  0.057297  0.030372   \n",
       "1  0.073046  0.035958  0.056553     ...      0.083202  0.043883  0.036930   \n",
       "2  0.074696  0.041053  0.053553     ...      0.082560  0.041910  0.036587   \n",
       "3  0.054802  0.061447  0.053960     ...      0.088113  0.045784  0.041096   \n",
       "4  0.049624  0.092619  0.080058     ...      0.037519  0.061251  0.071471   \n",
       "\n",
       "        199  vaso_input  iv_input  reward  icustayid  prob  imp_weight  \n",
       "0  0.047363           0       0.0     0.0       12.0   0.0    0.000022  \n",
       "1  0.057726           0       0.0     0.0       12.0   0.0    0.000022  \n",
       "2  0.067986           0       0.0     0.0       12.0   0.0    0.000022  \n",
       "3  0.129189           0       0.0    15.0       12.0  15.0    0.000002  \n",
       "4  0.039540           0       4.0     0.0       14.0   0.0    0.000022  \n",
       "\n",
       "[5 rows x 206 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "      <th>vaso_input</th>\n",
       "      <th>iv_input</th>\n",
       "      <th>reward</th>\n",
       "      <th>icustayid</th>\n",
       "      <th>prob</th>\n",
       "      <th>imp_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.064572</td>\n",
       "      <td>0.084793</td>\n",
       "      <td>0.065976</td>\n",
       "      <td>0.070753</td>\n",
       "      <td>0.063990</td>\n",
       "      <td>0.051591</td>\n",
       "      <td>0.050112</td>\n",
       "      <td>0.049624</td>\n",
       "      <td>0.092619</td>\n",
       "      <td>0.080058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037519</td>\n",
       "      <td>0.061251</td>\n",
       "      <td>0.071471</td>\n",
       "      <td>0.039540</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.074025</td>\n",
       "      <td>0.079019</td>\n",
       "      <td>0.069797</td>\n",
       "      <td>0.068576</td>\n",
       "      <td>0.069831</td>\n",
       "      <td>0.043737</td>\n",
       "      <td>0.056884</td>\n",
       "      <td>0.073837</td>\n",
       "      <td>0.073740</td>\n",
       "      <td>0.075134</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040486</td>\n",
       "      <td>0.053812</td>\n",
       "      <td>0.067138</td>\n",
       "      <td>0.043424</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.067640</td>\n",
       "      <td>0.073252</td>\n",
       "      <td>0.077615</td>\n",
       "      <td>0.072775</td>\n",
       "      <td>0.074835</td>\n",
       "      <td>0.040598</td>\n",
       "      <td>0.054152</td>\n",
       "      <td>0.078552</td>\n",
       "      <td>0.073434</td>\n",
       "      <td>0.086740</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043017</td>\n",
       "      <td>0.054578</td>\n",
       "      <td>0.068782</td>\n",
       "      <td>0.045069</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.084182</td>\n",
       "      <td>0.069916</td>\n",
       "      <td>0.070347</td>\n",
       "      <td>0.069123</td>\n",
       "      <td>0.072279</td>\n",
       "      <td>0.034510</td>\n",
       "      <td>0.053141</td>\n",
       "      <td>0.090075</td>\n",
       "      <td>0.061658</td>\n",
       "      <td>0.072907</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049218</td>\n",
       "      <td>0.054276</td>\n",
       "      <td>0.064720</td>\n",
       "      <td>0.051236</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.113805</td>\n",
       "      <td>0.048466</td>\n",
       "      <td>0.068828</td>\n",
       "      <td>0.080646</td>\n",
       "      <td>0.059614</td>\n",
       "      <td>0.016070</td>\n",
       "      <td>0.028201</td>\n",
       "      <td>0.081736</td>\n",
       "      <td>0.072616</td>\n",
       "      <td>0.049215</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051598</td>\n",
       "      <td>0.057034</td>\n",
       "      <td>0.067416</td>\n",
       "      <td>0.083398</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.103441</td>\n",
       "      <td>0.079006</td>\n",
       "      <td>0.073327</td>\n",
       "      <td>0.083135</td>\n",
       "      <td>0.065522</td>\n",
       "      <td>0.030426</td>\n",
       "      <td>0.026677</td>\n",
       "      <td>0.059899</td>\n",
       "      <td>0.066019</td>\n",
       "      <td>0.055480</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065361</td>\n",
       "      <td>0.069394</td>\n",
       "      <td>0.072032</td>\n",
       "      <td>0.120818</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.101310</td>\n",
       "      <td>0.064388</td>\n",
       "      <td>0.070295</td>\n",
       "      <td>0.103702</td>\n",
       "      <td>0.062022</td>\n",
       "      <td>0.026225</td>\n",
       "      <td>0.029238</td>\n",
       "      <td>0.069330</td>\n",
       "      <td>0.088385</td>\n",
       "      <td>0.064827</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063749</td>\n",
       "      <td>0.072680</td>\n",
       "      <td>0.077492</td>\n",
       "      <td>0.109648</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.089622</td>\n",
       "      <td>0.053569</td>\n",
       "      <td>0.067050</td>\n",
       "      <td>0.118848</td>\n",
       "      <td>0.064748</td>\n",
       "      <td>0.025035</td>\n",
       "      <td>0.034923</td>\n",
       "      <td>0.078645</td>\n",
       "      <td>0.086481</td>\n",
       "      <td>0.075960</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063923</td>\n",
       "      <td>0.076082</td>\n",
       "      <td>0.078420</td>\n",
       "      <td>0.104181</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.094056</td>\n",
       "      <td>0.052298</td>\n",
       "      <td>0.068664</td>\n",
       "      <td>0.119672</td>\n",
       "      <td>0.071022</td>\n",
       "      <td>0.029564</td>\n",
       "      <td>0.037301</td>\n",
       "      <td>0.062040</td>\n",
       "      <td>0.070939</td>\n",
       "      <td>0.079584</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052991</td>\n",
       "      <td>0.083214</td>\n",
       "      <td>0.070643</td>\n",
       "      <td>0.099471</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.093668</td>\n",
       "      <td>0.047470</td>\n",
       "      <td>0.073948</td>\n",
       "      <td>0.109111</td>\n",
       "      <td>0.074271</td>\n",
       "      <td>0.028844</td>\n",
       "      <td>0.038724</td>\n",
       "      <td>0.067044</td>\n",
       "      <td>0.064909</td>\n",
       "      <td>0.077116</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048472</td>\n",
       "      <td>0.077113</td>\n",
       "      <td>0.064924</td>\n",
       "      <td>0.103841</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 206 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6  \\\n",
       "4   0.064572  0.084793  0.065976  0.070753  0.063990  0.051591  0.050112   \n",
       "5   0.074025  0.079019  0.069797  0.068576  0.069831  0.043737  0.056884   \n",
       "6   0.067640  0.073252  0.077615  0.072775  0.074835  0.040598  0.054152   \n",
       "7   0.084182  0.069916  0.070347  0.069123  0.072279  0.034510  0.053141   \n",
       "8   0.113805  0.048466  0.068828  0.080646  0.059614  0.016070  0.028201   \n",
       "9   0.103441  0.079006  0.073327  0.083135  0.065522  0.030426  0.026677   \n",
       "10  0.101310  0.064388  0.070295  0.103702  0.062022  0.026225  0.029238   \n",
       "11  0.089622  0.053569  0.067050  0.118848  0.064748  0.025035  0.034923   \n",
       "12  0.094056  0.052298  0.068664  0.119672  0.071022  0.029564  0.037301   \n",
       "13  0.093668  0.047470  0.073948  0.109111  0.074271  0.028844  0.038724   \n",
       "\n",
       "           7         8         9     ...           196       197       198  \\\n",
       "4   0.049624  0.092619  0.080058     ...      0.037519  0.061251  0.071471   \n",
       "5   0.073837  0.073740  0.075134     ...      0.040486  0.053812  0.067138   \n",
       "6   0.078552  0.073434  0.086740     ...      0.043017  0.054578  0.068782   \n",
       "7   0.090075  0.061658  0.072907     ...      0.049218  0.054276  0.064720   \n",
       "8   0.081736  0.072616  0.049215     ...      0.051598  0.057034  0.067416   \n",
       "9   0.059899  0.066019  0.055480     ...      0.065361  0.069394  0.072032   \n",
       "10  0.069330  0.088385  0.064827     ...      0.063749  0.072680  0.077492   \n",
       "11  0.078645  0.086481  0.075960     ...      0.063923  0.076082  0.078420   \n",
       "12  0.062040  0.070939  0.079584     ...      0.052991  0.083214  0.070643   \n",
       "13  0.067044  0.064909  0.077116     ...      0.048472  0.077113  0.064924   \n",
       "\n",
       "         199  vaso_input  iv_input  reward  icustayid  prob  imp_weight  \n",
       "4   0.039540           0       4.0     0.0       14.0   0.0    0.000022  \n",
       "5   0.043424           0       3.0     0.0       14.0   0.0    0.000022  \n",
       "6   0.045069           0       3.0     0.0       14.0   0.0    0.000022  \n",
       "7   0.051236           0       2.0     0.0       14.0   0.0    0.000022  \n",
       "8   0.083398           0       0.0     0.0       14.0   0.0    0.000022  \n",
       "9   0.120818           0       0.0     0.0       14.0   0.0    0.000022  \n",
       "10  0.109648           0       2.0     0.0       14.0   0.0    0.000022  \n",
       "11  0.104181           0       2.0     0.0       14.0   0.0    0.000022  \n",
       "12  0.099471           0       2.0     0.0       14.0   0.0    0.000022  \n",
       "13  0.103841           0       2.0    15.0       14.0  15.0    0.000002  \n",
       "\n",
       "[10 rows x 206 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[train['icustayid'] == 14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_1_size = 400\n",
    "hidden_2_size = 400\n",
    "\n",
    "class Qnetwork():\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.phase = tf.placeholder(tf.bool)\n",
    "        self.num_actions = 25\n",
    "        self.input_size = 200\n",
    "        self.state = tf.placeholder(tf.float32, shape=[None, self.input_size],name=\"input_state\")\n",
    "        \n",
    "        self.fc_1 = tf.contrib.layers.fully_connected(self.state, hidden_1_size, activation_fn=None)\n",
    "        self.fc_1_bn = tf.contrib.layers.batch_norm(self.fc_1, center=True, scale=True, is_training=self.phase)\n",
    "        self.fc_1_ac = tf.maximum(self.fc_1_bn, self.fc_1_bn * 0.5)\n",
    "        \n",
    "        self.fc_2 = tf.contrib.layers.fully_connected(self.fc_1_ac, hidden_2_size, activation_fn=None)\n",
    "        self.fc_2_bn = tf.contrib.layers.batch_norm(self.fc_2, center=True, scale=True, is_training=self.phase)\n",
    "        self.fc_2_ac = tf.maximum(self.fc_2_bn, self.fc_2_bn * 0.5)\n",
    "        \n",
    "        # advantage and value streams\n",
    "        self.streamA, self.streamV = tf.split(self.fc_2_ac,2,axis=1)\n",
    "        self.AW = tf.Variable(tf.random_normal([hidden_2_size//2, self.num_actions]))\n",
    "        self.VW = tf.Variable(tf.random_normal([hidden_2_size//2, 1]))\n",
    "        self.Advantage = tf.matmul(self.streamA, self.AW)\n",
    "        self.Value = tf.matmul(self.streamV,self.VW)\n",
    "        \n",
    "        # Then combine them together to get our final Q-values.\n",
    "        self.q_output = self.Value + tf.subtract(self.Advantage, tf.reduce_mean(self.Advantage,axis=1,keep_dims=True))\n",
    "        self.predict = tf.argmax(self.q_output, 1, name='predict') # vector of length batch size\n",
    "        \n",
    "        #Below we obtain the loss by taking the sum of squares difference between the target and predicted Q values.\n",
    "        self.targetQ = tf.placeholder(shape=[None],dtype=tf.float32)\n",
    "        self.actions = tf.placeholder(shape=[None],dtype=tf.int32)\n",
    "        self.actions_onehot = tf.one_hot(self.actions, self.num_actions,dtype=tf.float32)\n",
    "        \n",
    "        # Importance sampling weights for PER, used in network update    \n",
    "        self.imp_weights = tf.placeholder(shape=[None], dtype=tf.float32)\n",
    "        # select the Q values for the actions that would be selected\n",
    "        self.Q = tf.reduce_sum(tf.multiply(self.q_output, self.actions_onehot), reduction_indices=1) # batch size x 1 vector\n",
    "        \n",
    "        # reward threshold, to ensure reasonable Q-value predictions  \n",
    "        self.reg_vector = tf.maximum(tf.abs(self.Q)-REWARD_THRESHOLD,0)\n",
    "        self.reg_term = tf.reduce_sum(self.reg_vector)\n",
    "        \n",
    "        self.abs_error = tf.abs(self.targetQ - self.Q)\n",
    "        \n",
    "        self.td_error = tf.square(self.targetQ - self.Q)\n",
    "        \n",
    "        # below is the loss when we are not using PER\n",
    "        self.old_loss = tf.reduce_mean(self.td_error)\n",
    "        \n",
    "        # as in the paper, to get PER loss we weight the squared error by the importance weights\n",
    "        self.per_error = tf.multiply(self.td_error, self.imp_weights)\n",
    "\n",
    "        # total loss is a sum of PER loss and the regularisation term\n",
    "        if per_flag:\n",
    "            self.loss = tf.reduce_mean(self.per_error) + reg_lambda*self.reg_term\n",
    "        else:\n",
    "            self.loss = self.old_loss + reg_lambda * self.reg_term\n",
    "\n",
    "        self.trainer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "        self.update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(self.update_ops):\n",
    "        # Ensures that we execute the update_ops before performing the model update, so batchnorm works\n",
    "            self.update_model = self.trainer.minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function is needed to update parameters between main and target network\n",
    "# tf_vars are the trainable variables to update, and tau is the rate at which to update\n",
    "# returns tf ops corresponding to the updates\n",
    "def update_target_graph(tf_vars,tau):\n",
    "    total_vars = len(tf_vars)\n",
    "    op_holder = []\n",
    "    for idx,var in enumerate(tf_vars[0:int(total_vars/2)]):\n",
    "        op_holder.append(tf_vars[idx+int(total_vars/2)].assign((var.value()*tau) + ((1-tau)*tf_vars[idx+int(total_vars/2)].value())))\n",
    "    return op_holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_target(op_holder,sess):\n",
    "    for op in op_holder:\n",
    "        sess.run(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define an action mapping - how to get an id representing the action from the (iv,vaso) tuple\n",
    "action_map = {}\n",
    "count = 0\n",
    "for iv in range(5):\n",
    "    for vaso in range(5):\n",
    "        action_map[(iv, vaso)] = count\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generates batches for the Q network - depending on train and eval_type, can select data from train/val/test sets.\n",
    "def process_batch(size, train_phase=True, eval_type = None):\n",
    "    \n",
    "    if not train_phase:\n",
    "        \n",
    "        if eval_type is None:\n",
    "            raise Exception('Provide eval_type to process_batch')\n",
    "        elif eval_type == 'train':\n",
    "            a = train.copy()\n",
    "        elif eval_type == 'val':\n",
    "            a = val_df.copy()\n",
    "        elif eval_type == 'test':\n",
    "            a = test.copy()\n",
    "        else:\n",
    "            raise Exception('Unknown eval_type')\n",
    "    else:\n",
    "        if per_flag:\n",
    "            # uses prioritised exp replay\n",
    "            a = train.sample(n=size, weights=train['prob'])\n",
    "        else:\n",
    "            a = train.sample(n=size)\n",
    "            \n",
    "    if size == None:\n",
    "        size = len(a)\n",
    "    \n",
    "    states = np.zeros((size, 200))\n",
    "    actions = np.zeros((size, 1), dtype=int)\n",
    "    rewards = np.zeros((size, 1))\n",
    "    next_states = np.zeros((size, 200))\n",
    "    done_flags = np.zeros((size, 1))\n",
    "    \n",
    "    counter = 0\n",
    "    for idx, obser in a.iterrows():\n",
    "        cur_state = obser[:200]\n",
    "        iv = int(obser.loc['iv_input'])\n",
    "        vaso = int(obser.loc['vaso_input'])\n",
    "        action = action_map[iv, vaso]\n",
    "        reward = obser.loc['reward']\n",
    "        \n",
    "        if idx != train.index[-1]:\n",
    "            # if not terminal step in trajectory             \n",
    "            if train.loc[idx, 'icustayid'] == train.loc[idx + 1, 'icustayid']:\n",
    "                next_state = train.iloc[idx + 1, :200]\n",
    "                done = 0\n",
    "            else:\n",
    "                # trajectory is finished\n",
    "                next_state = np.zeros(len(cur_state))\n",
    "                done = 1\n",
    "        else:\n",
    "            # last entry in df is the final state of that trajectory\n",
    "            next_state = np.zeros(len(cur_state))\n",
    "            done = 1\n",
    "        \n",
    "        states[counter] = cur_state\n",
    "        actions[counter] = action\n",
    "        rewards[counter] = reward\n",
    "        next_states[counter] = next_state\n",
    "        done_flags[counter] = done\n",
    "        counter += 1\n",
    "    return (states, np.squeeze(actions), np.squeeze(rewards), next_states, np.squeeze(done_flags), a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  Used to run diagnostics on the train set\n",
    "phys_q_train = []\n",
    "agent_q_train = []\n",
    "phys_actions_tr = []\n",
    "agent_actions_tr = []\n",
    "\n",
    "def train_set_performance():\n",
    "    count = 0\n",
    "    global phys_q_train\n",
    "    global agent_q_train\n",
    "    global phys_actions\n",
    "    global agent_actions\n",
    "    phys_q_train = []\n",
    "    agent_q_train = []\n",
    "    phys_actions_tr = []\n",
    "    agent_actions_tr = []\n",
    "    for r in train.index:\n",
    "        cur_state = [train.iloc[r, :200]]\n",
    "        iv = int(train.loc[r, 'iv_input'])\n",
    "        vaso = int(train.loc[r, 'vaso_input'])\n",
    "        action = action_map[iv, vaso]\n",
    "        output_q = np.squeeze(sess.run(mainQN.q_output, feed_dict = {mainQN.state : cur_state, mainQN.phase : False}))\n",
    "        phys_q_train.append(output_q[action])\n",
    "        agent_q_train.append(max(output_q))\n",
    "        agent_actions_tr.append(np.argmax(output_q))\n",
    "        phys_actions_tr.append(action)\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_eval(eval_type):\n",
    "    states,actions,rewards,next_states,done_flags, _ = process_batch(size=None,train_phase=False,eval_type=eval_type)\n",
    "    # firstly get the chosen actions at the next timestep\n",
    "    actions_from_q1 = sess.run(mainQN.predict,feed_dict={mainQN.state: next_states, mainQN.phase : 0})\n",
    "\n",
    "    # Q values for the next timestep from target network, as part of the Double DQN update\n",
    "    Q2 = sess.run(targetQN.q_output,feed_dict={targetQN.state:next_states, targetQN.phase : 0})\n",
    "    # handles the case when a trajectory is finished\n",
    "    end_multiplier = 1 - done_flags\n",
    "\n",
    "    # target Q value using Q values from target, and actions from main\n",
    "    double_q_value = Q2[range(len(actions_from_q1)), actions_from_q1]\n",
    "\n",
    "    # definition of target Q\n",
    "    targetQ = rewards + ( gamma * double_q_value * end_multiplier )\n",
    "\n",
    "    # get the output q's, actions, and loss\n",
    "    q_output, actions_taken, abs_err = sess.run([mainQN.q_output, mainQN.predict, mainQN.abs_error], \\\n",
    "        feed_dict={mainQN.state:states,\n",
    "                   mainQN.targetQ:targetQ, \n",
    "                   mainQN.actions:actions,\n",
    "                   mainQN.phase:False})\n",
    "    # return the relevant q values and actions\n",
    "    phys_q = q_output[range(len(q_output)), actions]\n",
    "    agent_q = q_output[range(len(q_output)), actions_taken]\n",
    "    error = np.mean(abs_err)\n",
    "    \n",
    "    return phys_q, actions, agent_q, actions_taken, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_save_results():\n",
    "    \n",
    "    # get the chosen actions for the train, val, and test set when training is complete.\n",
    "    phys_q_train, actions_train, agent_q_train, agent_actions_train, _ = do_eval(eval_type = 'train')        \n",
    "    # phys_q_val, actions_val, agent_q_val, agent_actions_val, _ = do_eval(eval_type = 'val')        \n",
    "    phys_q_test, actions_test, agent_q_test, agent_actions_test, _ = do_eval(eval_type = 'test')  \n",
    "    \n",
    "    # save everything for later - they're used in policy evaluation and when generating plots\n",
    "    \n",
    "    ## Physician q\n",
    "    with open(save_dir + 'dqn_autoencode_phy_q_train.p', 'wb') as f:\n",
    "        pickle.dump(phys_q_train, f)\n",
    "#     with open(save_dir + 'dqn_autoencode_phy_q_val.p', 'wb') as f:\n",
    "#         pickle.dump(phys_q_val, f)\n",
    "    with open(save_dir + 'dqn_autoencode_phy_q_test.p', 'wb') as f:\n",
    "        pickle.dump(phys_q_test, f)\n",
    "    \n",
    "    ## Physician action\n",
    "    with open(save_dir + 'dqn_autoencode_phy_actions_train.p', 'wb') as f:\n",
    "        pickle.dump(actions_train, f)\n",
    "#     with open(save_dir + 'dqn_autoencode_phy_actions_val.p', 'wb') as f:\n",
    "#         pickle.dump(actions_val, f)\n",
    "    with open(save_dir + 'dqn_autoencode_phy_actions_test.p', 'wb') as f:\n",
    "        pickle.dump(actions_test, f)\n",
    "    \n",
    "    ## Agent actions\n",
    "    with open(save_dir + 'dqn_autoencode_agent_actions_train.p', 'wb') as f:\n",
    "        pickle.dump(agent_actions_train, f)\n",
    "#     with open(save_dir + 'dqn_autoencode_actions_val.p', 'wb') as f:\n",
    "#         pickle.dump(agent_actions_val, f)\n",
    "    with open(save_dir + 'dqn_autoencode_agent_actions_test.p', 'wb') as f:\n",
    "        pickle.dump(agent_actions_test, f)\n",
    "    \n",
    "    ## Agent Q\n",
    "    with open(save_dir + 'dqn_autoencode_agent_q_train.p', 'wb') as f:\n",
    "        pickle.dump(agent_q_train, f)\n",
    "#     with open(save_dir + 'dqn_autoencode_q_val.p', 'wb') as f:\n",
    "#         pickle.dump(agent_q_val, f)\n",
    "    with open(save_dir + 'dqn_autoencode_agent_q_test.p', 'wb') as f:\n",
    "        pickle.dump(agent_q_test, f)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running default init\n",
      "Init done\n",
      "Saved Model, step is 1000\n",
      "Average loss is  0.4033934021\n",
      "Saving PER and importance weights\n",
      "step: 1000\n",
      "physactions  [10  0 21  0 15 14  5  0  0 15  5  5  5  0 24 12 15 24  3 15  0 23 23  0 10\n",
      "  0 15  0  5  0]\n",
      " chosen actions  [ 4  4  6  8 16  2  7  2 22 24  4  6 12  5  1 22 22 24  2  4  3 13  2  1  3\n",
      "  4  6 18 21  4]\n",
      "mean abs err: 2.60468\n",
      "mean phys Q: 1.78443\n",
      "mean agent Q: 3.19857\n",
      "------------------------\n",
      "Saved Model, step is 2000\n",
      "Average loss is  0.509499105453\n",
      "Saving PER and importance weights\n",
      "step: 2000\n",
      "physactions  [ 5 10  5  0  0  0  0  0  0  5  0  0  0 20 15 12 20 16  0 10 10  5  0 10  5\n",
      " 10  5  0 20 11]\n",
      " chosen actions  [12  2 24 11  4 22 15 19  7  1  4 17  4  1  2  8  4  4  1  1 12  4 22  2 22\n",
      "  6 24 23  0 22]\n",
      "mean abs err: 2.71939\n",
      "mean phys Q: 2.22827\n",
      "mean agent Q: 4.45919\n",
      "------------------------\n",
      "Saved Model, step is 3000\n",
      "Average loss is  0.476675319672\n",
      "Saving PER and importance weights\n",
      "step: 3000\n",
      "physactions  [ 5  0  5  1  0  5 20 15 15 15  0  5  0 18  0 11  0  0  0 11  0  5 10  5 10\n",
      "  0 15  0  0  0]\n",
      " chosen actions  [19  2  6  2 22 23 12  7  5  1  1  7 22  2  4  3  8 12 22  2  6 21 22  2  7\n",
      " 22 16  3  4 11]\n",
      "mean abs err: 3.12518\n",
      "mean phys Q: 2.93382\n",
      "mean agent Q: 5.71785\n",
      "------------------------\n",
      "Saved Model, step is 4000\n",
      "Average loss is  0.438266167641\n",
      "Saving PER and importance weights\n",
      "step: 4000\n",
      "physactions  [10  0  5 21 20 10  0  5 10  0  0  0 15  0 15  6 24  0 15  0 10  5  0  5  0\n",
      "  5 15 19 15  0]\n",
      " chosen actions  [14 22  4  6  4 16 22 24 14  2  6 22 11  2 14 19  1  1 16  6 14 14  4 19  8\n",
      "  8  8  3  3  2]\n",
      "mean abs err: 4.24486\n",
      "mean phys Q: 4.58962\n",
      "mean agent Q: 8.55117\n",
      "------------------------\n",
      "Saved Model, step is 5000\n",
      "Average loss is  0.473536189079\n",
      "Saving PER and importance weights\n",
      "step: 5000\n",
      "physactions  [ 0  0  5  0 10  0  5  0  0  0 15 15  0  5 10  0  5 10  0 20  0 21  0  0  0\n",
      " 10  0  0  0  0]\n",
      " chosen actions  [22  4 12  4 23 14 12 12 17  4  4 12  6 23 20  4  4  2 22 23 21  5  1  2 22\n",
      "  4 24  8  9  3]\n",
      "mean abs err: 4.6923\n",
      "mean phys Q: 5.84827\n",
      "mean agent Q: 12.1546\n",
      "------------------------\n",
      "Saved Model, step is 6000\n",
      "Average loss is  0.389917686462\n",
      "Saving PER and importance weights\n",
      "step: 6000\n",
      "physactions  [ 5 10  5  0  0 17 10  0  0  0  5 15  0 20  0  0 15  5 14  0  0  0  0 11  0\n",
      "  0  0 10  0  0]\n",
      " chosen actions  [ 5  2  7  3 20  7  1 22 17  4  7 11 16 11  4  4  1  1 19 23  4 11  4 12  4\n",
      " 22 11  3 24  4]\n",
      "mean abs err: 7.55402\n",
      "mean phys Q: 9.66703\n",
      "mean agent Q: 18.2676\n",
      "------------------------\n",
      "Saved Model, step is 7000\n",
      "Average loss is  0.379332395315\n",
      "Saving PER and importance weights\n",
      "step: 7000\n",
      "physactions  [ 5 24  0 10 20 10 15 15 10 15 10 15  0 15  0 10  0  0  7 15  0 15 10  0  6\n",
      " 10 20 23  5  0]\n",
      " chosen actions  [ 8  4  5 24  2 11  2 20 16 22  2  4  2  4 22 16  4  9  6 12  7 11 17  7 15\n",
      "  7 15  9 17  4]\n",
      "mean abs err: 5.54357\n",
      "mean phys Q: 4.77206\n",
      "mean agent Q: 16.2449\n",
      "------------------------\n",
      "Saved Model, step is 8000\n",
      "Average loss is  0.361929031849\n",
      "Saving PER and importance weights\n",
      "step: 8000\n",
      "physactions  [ 0  0  0 13  0  0 10 20  4  0 15  5 10 23 18 22  0  0 15  0  5 20 15  0  0\n",
      " 15  5  5  5 14]\n",
      " chosen actions  [ 4  4  3 12 22  2  3 12 17  4  8  2  7  7  3 20 22  4  3  6  1 14  1  1 22\n",
      " 17 22 14 22  3]\n",
      "mean abs err: 5.34303\n",
      "mean phys Q: 3.03966\n",
      "mean agent Q: 14.3909\n",
      "------------------------\n",
      "Saved Model, step is 9000\n",
      "Average loss is  0.397740501881\n",
      "Saving PER and importance weights\n",
      "step: 9000\n",
      "physactions  [ 0  0  0  0  0 15 22  0 22 10  0 12 20 23  0  0  0  0 15 10 20  5 20  5  0\n",
      " 15  0  5  0  0]\n",
      " chosen actions  [ 4  4 22  3 15 11 17 11 13  6  4  2  0 14  6  3 14 22  4  5  6 11 12  3  4\n",
      "  0  2  4 22  8]\n",
      "mean abs err: 5.93335\n",
      "mean phys Q: 6.73162\n",
      "mean agent Q: 18.8541\n",
      "------------------------\n",
      "Saved Model, step is 10000\n",
      "Average loss is  0.407301608086\n",
      "Saving PER and importance weights\n",
      "step: 10000\n",
      "physactions  [ 0  0  0  0  5  0  5  0  5 10  0  0 10  0 16 14  0  5  0 10  0 15  0 10  0\n",
      " 15 20  0  5 10]\n",
      " chosen actions  [21 22 14 17  8 16  0  4  3 18  3  2  2  4 23  2  4  5 16 11 12  4  8  7  4\n",
      "  1 15  4 15  8]\n",
      "mean abs err: 7.67156\n",
      "mean phys Q: 8.7271\n",
      "mean agent Q: 23.5822\n",
      "------------------------\n",
      "Saved Model, step is 11000\n",
      "Average loss is  0.319983417511\n",
      "Saving PER and importance weights\n",
      "step: 11000\n",
      "physactions  [ 0  0  0 20  0 15  5  5  0  5 20  0  5  5  0 20  0  5  0 15  0  0  5  0  0\n",
      "  0 15 20 20 15]\n",
      " chosen actions  [22  4  2  3  5 24  4 12 20  2  8  4 16  0  4  5  0 20  0  7 14 22  4 22  3\n",
      "  2 21 16 20  4]\n",
      "mean abs err: 5.69413\n",
      "mean phys Q: 7.46497\n",
      "mean agent Q: 16.4543\n",
      "------------------------\n",
      "Saved Model, step is 12000\n",
      "Average loss is  0.350906013012\n",
      "Saving PER and importance weights\n",
      "step: 12000\n",
      "physactions  [ 5  5  0 20  0  0 10  0  0  5  0  0 12  0 20  0  0  0  0 10  0  5  5 23  0\n",
      "  0  0  5 10 10]\n",
      " chosen actions  [ 0  7  3 11  3 22  8  4 22 22  4  4 24  4  1  4 15  4  3 14 16 14  4  3 17\n",
      " 11  4  3 22  3]\n",
      "mean abs err: 4.74729\n",
      "mean phys Q: 5.11307\n",
      "mean agent Q: 13.7766\n",
      "------------------------\n",
      "Saved Model, step is 13000\n",
      "Average loss is  0.322714754581\n",
      "Saving PER and importance weights\n",
      "step: 13000\n",
      "physactions  [13  5  0  0  0  0  0  0 10  5  0 10 10 10 16 15  0 10  5  0  0  5 15  0 24\n",
      " 10  5 20  5 10]\n",
      " chosen actions  [ 2  3  4 15  5 20  4 23  6  6 22  7  5  2  8 22  4  8  3  4 15  3  0  4  4\n",
      "  8  0 15  5  9]\n",
      "mean abs err: 5.351\n",
      "mean phys Q: 4.39283\n",
      "mean agent Q: 14.6741\n",
      "------------------------\n",
      "Saved Model, step is 14000\n",
      "Average loss is  0.295771554947\n",
      "Saving PER and importance weights\n",
      "step: 14000\n",
      "physactions  [15  5 15  0  0  5 10  0  5 10 20  5  0  5 10 16  5 15  0  0  0 15  0 19 20\n",
      " 23  0  0  5 10]\n",
      " chosen actions  [22 16  5  4  4  3 10 17  3  3 14 22 22 24 22  1 22  6  4  2  0 14 15 12 16\n",
      " 24 15  3 10 21]\n",
      "mean abs err: 5.24215\n",
      "mean phys Q: 5.21772\n",
      "mean agent Q: 16.3576\n",
      "------------------------\n",
      "Saved Model, step is 15000\n",
      "Average loss is  0.375208015442\n",
      "Saving PER and importance weights\n",
      "step: 15000\n",
      "physactions  [20  0  0 10  5  0  0 23  0  0 18 10 13 10  5  0  0  5  0 10 15  0 23  0  5\n",
      "  0 20  0 23  0]\n",
      " chosen actions  [17  4 20  5 11 22 22 10  4  6  2 22  4 16  2  4 22 22 22  1  3  0 23  0  6\n",
      " 22 19  4 15 12]\n",
      "mean abs err: 4.71765\n",
      "mean phys Q: 3.63252\n",
      "mean agent Q: 13.0353\n",
      "------------------------\n",
      "Saved Model, step is 16000\n",
      "Average loss is  0.343021211147\n",
      "Saving PER and importance weights\n",
      "step: 16000\n",
      "physactions  [ 0  5  6  5  0 13 10  0  0  0  5  0  5  6  0 20  0  0  5 10 18  5  0  5  0\n",
      " 15  7 20  0  0]\n",
      " chosen actions  [11 21  0  0  4 15  4 11 22  5  4  2  3  9  3  4  4 22 16  3 17  1  4 22 22\n",
      " 23 15 20 22  4]\n",
      "mean abs err: 4.67245\n",
      "mean phys Q: 7.75034\n",
      "mean agent Q: 14.8554\n",
      "------------------------\n",
      "Saved Model, step is 17000\n",
      "Average loss is  0.301560153008\n",
      "Saving PER and importance weights\n",
      "step: 17000\n",
      "physactions  [ 0  0  5 15 10  0 20  0  5  0 15 10 10  0 10  0  0 10  0  0 10 17 24  0 10\n",
      " 24  0  0  0  5]\n",
      " chosen actions  [ 4 10 12 16  7  4 12  3 11 12  0 12  1  4  0  4  6 22 22 22  3  0  1  4 22\n",
      "  1  7  4  4  3]\n",
      "mean abs err: 4.37234\n",
      "mean phys Q: 7.64372\n",
      "mean agent Q: 14.467\n",
      "------------------------\n",
      "Saved Model, step is 18000\n",
      "Average loss is  0.274462685585\n",
      "Saving PER and importance weights\n",
      "step: 18000\n",
      "physactions  [10 15  0  0 19 10  0  0  0  0 10 15  0 10  0 12 15 16  0  0 10 10 15  6  0\n",
      " 24 15  0  5  0]\n",
      " chosen actions  [ 3  3 15 17 11  4 22 17 22 12  1 22 17  3 17 24  3  0 22  4  4 14  4 11 15\n",
      "  0 12 12 23  6]\n",
      "mean abs err: 5.72829\n",
      "mean phys Q: 10.1683\n",
      "mean agent Q: 18.6796\n",
      "------------------------\n",
      "Saved Model, step is 19000\n",
      "Average loss is  0.263287961006\n",
      "Saving PER and importance weights\n",
      "step: 19000\n",
      "physactions  [15 10  0 20  0 12  0  0 10  5 20 15 10  0 15  0  0 24 15 20  0  0 15  0  1\n",
      "  5 15  0  0  0]\n",
      " chosen actions  [11  4  4 20  4 24 22  4 20  4  5 12 15 22  5  0 20 12 12  4  4 22 10  4  7\n",
      " 15 20  4 17 15]\n",
      "mean abs err: 6.49158\n",
      "mean phys Q: 11.8078\n",
      "mean agent Q: 17.5484\n",
      "------------------------\n",
      "Saved Model, step is 20000\n",
      "Average loss is  0.36431141758\n",
      "Saving PER and importance weights\n",
      "step: 20000\n",
      "physactions  [18  5  5  5 11 20  0  1  0  0  0  0 15 15  5  0 15  0  0  5 10 10 20  0  0\n",
      "  0 24  0  0  0]\n",
      " chosen actions  [15  5 11  2 10 14  4  0 15  2 20  4  5  4 13  0 11  4  1  4 11 15 10  4  4\n",
      " 11 15 22 17 11]\n",
      "mean abs err: 5.07004\n",
      "mean phys Q: 10.0027\n",
      "mean agent Q: 16.516\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Model, step is 21000\n",
      "Average loss is  0.318089565277\n",
      "Saving PER and importance weights\n",
      "step: 21000\n",
      "physactions  [ 0 18  5  0  0 10  5 10 21  7 24  0  5  0  0  0  0 20 15  5 14 10 10 20 20\n",
      " 15 10  0  0  0]\n",
      " chosen actions  [ 4 22  5  7  4 15  3  0  7 10 12 12 12 14 15  4 22 15 22 18  0  4 15  3 17\n",
      "  5  8 15  4  4]\n",
      "mean abs err: 4.48753\n",
      "mean phys Q: 9.23444\n",
      "mean agent Q: 14.7213\n",
      "------------------------\n",
      "Saved Model, step is 22000\n",
      "Average loss is  0.246401059628\n",
      "Saving PER and importance weights\n",
      "step: 22000\n",
      "physactions  [ 5 20  5  0  0  0  0 24  0  0 23 20  0  0 15  5  0  0  0 15  0  0  0  5  0\n",
      " 10 15  5 10 21]\n",
      " chosen actions  [15 17 22  4  0 11  2 12  4  4  6 11  2 24 23  5 22 17  0  2  4  4 22  4 17\n",
      " 11 11 12  6 15]\n",
      "mean abs err: 5.6546\n",
      "mean phys Q: 11.3184\n",
      "mean agent Q: 15.981\n",
      "------------------------\n",
      "Saved Model, step is 23000\n",
      "Average loss is  0.334937782764\n",
      "Saving PER and importance weights\n",
      "step: 23000\n",
      "physactions  [20  2 24  0  5 24 10 20  8  0  0  0 20  5  0  0  0  0 20  4  5  5 23  0 20\n",
      " 10  8 20 10 10]\n",
      " chosen actions  [ 6 15  5 11 17  2  6  4 15 23 22  5  5 17 22 17 17  3  4 20 22  4  4  4 10\n",
      " 11 14  4  1  8]\n",
      "mean abs err: 4.41827\n",
      "mean phys Q: 9.10606\n",
      "mean agent Q: 15.0033\n",
      "------------------------\n",
      "Saved Model, step is 24000\n",
      "Average loss is  0.236754119396\n",
      "Saving PER and importance weights\n",
      "step: 24000\n",
      "physactions  [ 0  0 16  5 15  0  5  0 20  0  8 15 20  0  0  0  5  0  6 10  0 23  0 12  0\n",
      "  5  0 10  6  0]\n",
      " chosen actions  [ 4  0 10 14  1  4  3  4 18  8  0  0  8  4  4 17 24  4  4  1  2 10 22  0  6\n",
      "  6 22  3 22  5]\n",
      "mean abs err: 4.64305\n",
      "mean phys Q: 10.3244\n",
      "mean agent Q: 15.9501\n",
      "------------------------\n",
      "Saved Model, step is 25000\n",
      "Average loss is  0.379717332363\n",
      "Saving PER and importance weights\n",
      "step: 25000\n",
      "physactions  [15 19  5  0 15  5  3  5  5  0  0 15  5 10  1  0  0  5  0 10 10 15  0 10  4\n",
      "  0  5 21  5 10]\n",
      " chosen actions  [ 8 11  4  5  0 20  0  8  0  4  2 14  4  4 18 18  0  0  4  0 20 16 22  0  0\n",
      " 17  6  4  6 20]\n",
      "mean abs err: 5.05142\n",
      "mean phys Q: 10.4028\n",
      "mean agent Q: 15.1111\n",
      "------------------------\n",
      "Saved Model, step is 26000\n",
      "Average loss is  0.34582750988\n",
      "Saving PER and importance weights\n",
      "step: 26000\n",
      "physactions  [ 5 15  0  0  0  5  0 10  0  6  0  0 13  0 15  0  5  0  5 15 24  0 15 10  0\n",
      " 20  0  5 15 15]\n",
      " chosen actions  [ 8 11  6  2  4  4  2  4 11 15  4 22  4 22  5  8 11  4  0  8  5  2  0 12 24\n",
      "  8 16  6  2  0]\n",
      "mean abs err: 4.22687\n",
      "mean phys Q: 9.7422\n",
      "mean agent Q: 13.4908\n",
      "------------------------\n",
      "Saved Model, step is 27000\n",
      "Average loss is  0.250342373371\n",
      "Saving PER and importance weights\n",
      "step: 27000\n",
      "physactions  [ 0  0  0 20  0  0 18  0 15  0 10  8  5  0  0  0 10  0  0 10  0 10 23  0  0\n",
      "  0  5  5  2 10]\n",
      " chosen actions  [ 5 17 15  4  6  0  0  2 15 20 23  0  4  4  4 20 15  4 22  4  4  2  0 14  4\n",
      "  4 11  4  0 11]\n",
      "mean abs err: 4.62256\n",
      "mean phys Q: 11.0217\n",
      "mean agent Q: 14.7561\n",
      "------------------------\n",
      "Saved Model, step is 28000\n",
      "Average loss is  0.246443368912\n",
      "Saving PER and importance weights\n",
      "step: 28000\n",
      "physactions  [20  0 16 15 13 24  0 20  0  0 15  0  0  5  5 15 10 15 20  0  0  0  5 10  5\n",
      " 20 15 15  0  0]\n",
      " chosen actions  [15  6 10  0  0 11  4  8  2  4 22  2  4  2 22  0 15  0 17  4 15 17  2 21 24\n",
      "  4 11  0 13 22]\n",
      "mean abs err: 4.21014\n",
      "mean phys Q: 9.26342\n",
      "mean agent Q: 13.6009\n",
      "------------------------\n",
      "Saved Model, step is 29000\n",
      "Average loss is  0.247583683491\n",
      "Saving PER and importance weights\n",
      "step: 29000\n",
      "physactions  [ 5  0  0  0 20  0  5  5  0  5  0 10  0  0 20  5 16 12 10  0  5 15  0  0  0\n",
      " 20  0  5 10  5]\n",
      " chosen actions  [ 4  5 12 20 14 23  4  4  4 10 20  4  4  2 24  2  5 23  0 14 10  7 20  2 20\n",
      "  6 10  2  5  0]\n",
      "mean abs err: 5.27844\n",
      "mean phys Q: 12.1879\n",
      "mean agent Q: 16.9394\n",
      "------------------------\n",
      "Saved Model, step is 30000\n",
      "Average loss is  0.358417283058\n",
      "Saving PER and importance weights\n",
      "step: 30000\n",
      "physactions  [ 0  0 16 17  5  0  5 20  0  5 15 19  5  0  1 10  0  0 24  0  5 20  0 15  0\n",
      " 13  5  5  0  0]\n",
      " chosen actions  [ 4 22  8  0  4 22 11  1 14  5  5 16  0  0  0  5  4  5  0  0  7  4 11  2 20\n",
      "  0 14  0  4  4]\n",
      "mean abs err: 4.39381\n",
      "mean phys Q: 10.5443\n",
      "mean agent Q: 14.3582\n",
      "------------------------\n",
      "Saved Model, step is 31000\n",
      "Average loss is  0.263049408913\n",
      "Saving PER and importance weights\n",
      "step: 31000\n",
      "physactions  [10  0  0  0  0  0  5  0 10  0  2  5 15 18  5  5  0  5  5  0  0 10 20 20  0\n",
      "  0  5  0  0 11]\n",
      " chosen actions  [ 5  2  7 11 12 20  0  0 21  6 15 10  2  0  2  4  4  4  0  4  4 11  4 15  0\n",
      "  4  4 14  4  0]\n",
      "mean abs err: 4.25508\n",
      "mean phys Q: 10.3317\n",
      "mean agent Q: 14.0682\n",
      "------------------------\n",
      "Saved Model, step is 32000\n",
      "Average loss is  0.236908241272\n",
      "Saving PER and importance weights\n",
      "step: 32000\n",
      "physactions  [10  0  5 10  0 24 15  0  0 20  0  0 18 24 10 10 10  5  0  8 20 15  5  0 15\n",
      " 15  0  9 23 10]\n",
      " chosen actions  [24  4  0  5  4 11  0  0  6  0  8  4 21  4  4 11  0  0  4  4  6  4  6  0 22\n",
      "  6  2  0  0 17]\n",
      "mean abs err: 4.28133\n",
      "mean phys Q: 10.7236\n",
      "mean agent Q: 14.6979\n",
      "------------------------\n",
      "Saved Model, step is 33000\n",
      "Average loss is  0.175169885159\n",
      "Saving PER and importance weights\n",
      "step: 33000\n",
      "physactions  [ 0 10  0  5  0  0  5  0 15 15  0 22  0 20 10 10  0  0  5  0  0 12  0  4  0\n",
      " 10  0 15 15  0]\n",
      " chosen actions  [17 21  6 17  4  4 11  4 22 20  4  0  4 15  6 22 24  4 10  4  0  8 10  0  5\n",
      "  8 11  4 11  0]\n",
      "mean abs err: 4.12275\n",
      "mean phys Q: 9.76604\n",
      "mean agent Q: 13.9428\n",
      "------------------------\n",
      "Saved Model, step is 34000\n",
      "Average loss is  0.260237606049\n",
      "Saving PER and importance weights\n",
      "step: 34000\n",
      "physactions  [ 5  0  0  0  0  0  0  0  0  6 10  0  0  0 10 10  7  0  0 19  0  5 10 10  0\n",
      " 10 20  0  0 15]\n",
      " chosen actions  [ 0  4 17  4  0  4  0  8 20  0  4 23  0  0 14  5  0  0 22  0  2 22  4 24  4\n",
      "  0 24  4  0  0]\n",
      "mean abs err: 4.28215\n",
      "mean phys Q: 10.3864\n",
      "mean agent Q: 14.6266\n",
      "------------------------\n",
      "Saved Model, step is 35000\n",
      "Average loss is  0.211448152542\n",
      "Saving PER and importance weights\n",
      "step: 35000\n",
      "physactions  [ 5 10  0  0  0  0  5  0  8  0 17  0  2  6  0  0  5  5  5 20  0  0 10  0  0\n",
      "  0  5  0  0 24]\n",
      " chosen actions  [ 4  4  0  8 17 15 16  5 11  5  8  2  0  4  4 12  5 11  0  4  2  0  4 15  4\n",
      "  6 21  4  0  0]\n",
      "mean abs err: 3.98264\n",
      "mean phys Q: 10.2439\n",
      "mean agent Q: 14.2864\n",
      "------------------------\n",
      "Saved Model, step is 36000\n",
      "Average loss is  0.213038285255\n",
      "Saving PER and importance weights\n",
      "step: 36000\n",
      "physactions  [ 0  0  0 18  0 10  0  0 20  0  0  5  0  0  5 15  5  5  0  0  5  0  5 10 15\n",
      "  0 11  0  0  0]\n",
      " chosen actions  [15 16 16  4  4  2  0  0 11 15  2  6 20 10  4 20  5  6  2  4  0  4  0  8  2\n",
      " 15 10 10 20  4]\n",
      "mean abs err: 4.18225\n",
      "mean phys Q: 9.47062\n",
      "mean agent Q: 12.8017\n",
      "------------------------\n",
      "Saved Model, step is 37000\n",
      "Average loss is  0.198044804573\n",
      "Saving PER and importance weights\n",
      "step: 37000\n",
      "physactions  [10  5  0  0 20  8  0  0  0 10 20  0  5 17 10 10 20  5  5  0  5  0  5  0  0\n",
      "  5  0  5  5  5]\n",
      " chosen actions  [15 23 23 10  8  0 16  4  0 15  4  2 16  0  0 11  1 10  4  4 15  0  4 10  4\n",
      " 18  2 10 18  4]\n",
      "mean abs err: 4.27822\n",
      "mean phys Q: 10.1935\n",
      "mean agent Q: 12.9223\n",
      "------------------------\n",
      "Saved Model, step is 38000\n",
      "Average loss is  0.27250887394\n",
      "Saving PER and importance weights\n",
      "step: 38000\n",
      "physactions  [15 15  0 15  0  5  0  0  5  0  0  0 12  0 11  0  0  5 10  0  7 15  5 20  5\n",
      " 18 10  5  0  0]\n",
      " chosen actions  [16 22  4 10  4  4  2 23 10  4 14  5  0 15  0  5  0 15  0  4 20  4 12  8 11\n",
      "  5 16 20 16 16]\n",
      "mean abs err: 4.57521\n",
      "mean phys Q: 10.4382\n",
      "mean agent Q: 13.1571\n",
      "------------------------\n",
      "Saved Model, step is 39000\n",
      "Average loss is  0.2721789217\n",
      "Saving PER and importance weights\n",
      "step: 39000\n",
      "physactions  [13  5 19  5  6  5 10 20  5 15  0  0  0  0  0  0  0 20  0  0 15 15 10 10  0\n",
      "  0  0 21 22 20]\n",
      " chosen actions  [ 0  4  0 10  0 18  4  4  4  0 10 20  0  5 20 14  4  0 10 20  5 15  4 22  8\n",
      "  0 11  4  0 19]\n",
      "mean abs err: 4.40898\n",
      "mean phys Q: 10.53\n",
      "mean agent Q: 13.4092\n",
      "------------------------\n",
      "Saved Model, step is 40000\n",
      "Average loss is  0.132556690216\n",
      "Saving PER and importance weights\n",
      "step: 40000\n",
      "physactions  [ 5  0  0  0 24  0  0  0 15  5  0  5  5  0  5 20 15 20  0  5 15  0  5  0 10\n",
      "  0  5  5  5 10]\n",
      " chosen actions  [11  0 20 10 15 16  4 20  0  0  2 20 22 15 15  0 16 11  2  4  0 20  4  7  6\n",
      " 23 15  4 22  2]\n",
      "mean abs err: 4.2107\n",
      "mean phys Q: 10.7944\n",
      "mean agent Q: 14.205\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Model, step is 41000\n",
      "Average loss is  0.219026841164\n",
      "Saving PER and importance weights\n",
      "step: 41000\n",
      "physactions  [ 0  0 20  0  0  0  0 21  0  5  0 10  0  0 11  5  5 16 15  0  3 10  5  5  0\n",
      "  5  0 10  5  0]\n",
      " chosen actions  [22  4 11 17  2  4 20 14  5  5 15 10  4  4  4  8  0 20  0  0  0 10 17  0  0\n",
      " 15 16  8 15  2]\n",
      "mean abs err: 4.4734\n",
      "mean phys Q: 11.228\n",
      "mean agent Q: 14.2961\n",
      "------------------------\n",
      "Saved Model, step is 42000\n",
      "Average loss is  0.200200876236\n",
      "Saving PER and importance weights\n",
      "step: 42000\n",
      "physactions  [ 0  0  0  5 11 15 20 15  0  0 15  5  0 10  2  0  0  2  0  5  0  0  0 15 20\n",
      "  0  5  0 13  0]\n",
      " chosen actions  [ 4  0  8 15 15  0  4  4  4 16  4  0  5  4 10 24  5 15 10 16  0 16  5 15  5\n",
      " 20  4 16 15 15]\n",
      "mean abs err: 4.24901\n",
      "mean phys Q: 11.3127\n",
      "mean agent Q: 14.4507\n",
      "------------------------\n",
      "Saved Model, step is 43000\n",
      "Average loss is  0.300801960945\n",
      "Saving PER and importance weights\n",
      "step: 43000\n",
      "physactions  [ 0 15 10 24 23 15 15 13  0  5  0  0  0 10  0  0  0 10 15 15  0  0 15 20 10\n",
      " 15  0 15  5  0]\n",
      " chosen actions  [15  0  0 17  4  4 20  0  8 20 22  0  2  7 15  4  4  4 21 24 16  0 17 20  0\n",
      " 18  2 18  3  4]\n",
      "mean abs err: 4.24273\n",
      "mean phys Q: 11.4438\n",
      "mean agent Q: 14.9575\n",
      "------------------------\n",
      "Saved Model, step is 44000\n",
      "Average loss is  0.221969755173\n",
      "Saving PER and importance weights\n",
      "step: 44000\n",
      "physactions  [15 15  0  0 23  1  0  0 20 20  0 21 14 19 11  4  5 20  5  5 10 24 12  5  4\n",
      "  5  0  5 15  0]\n",
      " chosen actions  [23 16  4  2  4  4 22  4 20 20  5  4  0  0  0 23 22  0  0  4  5 15 11  5 16\n",
      " 17  2 11  4 24]\n",
      "mean abs err: 4.39567\n",
      "mean phys Q: 9.40533\n",
      "mean agent Q: 12.0442\n",
      "------------------------\n",
      "Saved Model, step is 45000\n",
      "Average loss is  0.158230347633\n",
      "Saving PER and importance weights\n",
      "step: 45000\n",
      "physactions  [ 1  5 15 15  6  0 22  5  0  0  4  0 15  5 20  0  0 10  0  0 10 15 15  0  0\n",
      "  0 14  0  0  5]\n",
      " chosen actions  [23 15 17 20 17 22  0 11  4 22 20 10  0 10 17  4  7  0  1  4 16  4  4  0  2\n",
      "  2  0  0  0 24]\n",
      "mean abs err: 4.35992\n",
      "mean phys Q: 11.2047\n",
      "mean agent Q: 14.0759\n",
      "------------------------\n",
      "Saved Model, step is 46000\n",
      "Average loss is  0.256205481529\n",
      "Saving PER and importance weights\n",
      "step: 46000\n",
      "physactions  [ 5 17  6  5  0  0  5  5  8  0 20 15  0  0  5  5 12 12  5 10 20 15 22 10 10\n",
      "  5  0 10  5 20]\n",
      " chosen actions  [ 2 17 15 16 16 20 20  6 15 15  4 12  0  2 18 15 23  0 22  7  3 20  6 20  0\n",
      "  0  2 18 17 17]\n",
      "mean abs err: 4.38878\n",
      "mean phys Q: 10.883\n",
      "mean agent Q: 14.1983\n",
      "------------------------\n",
      "Saved Model, step is 47000\n",
      "Average loss is  0.228536927223\n",
      "Saving PER and importance weights\n",
      "step: 47000\n",
      "physactions  [ 0 10 20 15 10  0  0  5  0 10 15  5 15  5  0  0 10 19  0  0 15  0  5 10  5\n",
      " 15  0 15  0 20]\n",
      " chosen actions  [ 0 16 16  2 17 20 22 16 22  0 20  4  6  0 20  4 23 15 17 23  0 10 15  4 20\n",
      " 17 20  7  7 20]\n",
      "mean abs err: 4.22265\n",
      "mean phys Q: 10.7634\n",
      "mean agent Q: 13.6606\n",
      "------------------------\n",
      "Saved Model, step is 48000\n",
      "Average loss is  0.240618288994\n",
      "Saving PER and importance weights\n",
      "step: 48000\n",
      "physactions  [11  0  5 10 15  0  0  0  5  4  0  5  0 13 20  5  5  5  5 20 20  0  0  0  0\n",
      "  0  0  0  5 10]\n",
      " chosen actions  [17  2  5  4  4 24 10  4  0 20  0 19  0  4  4 15 17  7  4  0  0  5  0 16  0\n",
      "  5 14  0 15  0]\n",
      "mean abs err: 4.65292\n",
      "mean phys Q: 10.9667\n",
      "mean agent Q: 13.6135\n",
      "------------------------\n",
      "Saved Model, step is 49000\n",
      "Average loss is  0.212015860081\n",
      "Saving PER and importance weights\n",
      "step: 49000\n",
      "physactions  [15  5  0  5  0  0  0 16  0 11  0  5  0  8  5  0  0  5  0 15 10  0  0  0  0\n",
      "  0  0  0  5  5]\n",
      " chosen actions  [ 4 11 15 15  4 24  0  8  0  8 20 15 16 24  5 12 16  7  0 17  0 20  0  0  8\n",
      "  0  2  4  4  4]\n",
      "mean abs err: 4.32564\n",
      "mean phys Q: 10.6989\n",
      "mean agent Q: 13.4688\n",
      "------------------------\n",
      "Saved Model, step is 50000\n",
      "Average loss is  0.182243905544\n",
      "Saving PER and importance weights\n",
      "step: 50000\n",
      "physactions  [15  0  0 10  0 10 10 18 10  0 23  0  1  5  0  0  0 10 15 15  0  0  0  0  0\n",
      " 20  5  0  0 15]\n",
      " chosen actions  [ 4 20 15  4 20  0  0 15 23  0  0  4 15 10 15  0 16 10 16  4 16  4  4 10  4\n",
      "  4 23 19 20  0]\n",
      "mean abs err: 4.37554\n",
      "mean phys Q: 11.1582\n",
      "mean agent Q: 13.803\n",
      "------------------------\n",
      "Saved Model, step is 51000\n",
      "Average loss is  0.211355151176\n",
      "Saving PER and importance weights\n",
      "step: 51000\n",
      "physactions  [ 0  0  0 11  0 10 23  0  0 15 10  7 15  5  0 11  0  5  0  5  0 10  5 15  5\n",
      " 10 16 15  0 10]\n",
      " chosen actions  [ 2 20 11 15 16  5 15  4 23  0  0  0 10  0  0 10 23  4  7 22 15 11  0 10 15\n",
      "  1  4  6  0 18]\n",
      "mean abs err: 4.45532\n",
      "mean phys Q: 11.437\n",
      "mean agent Q: 14.6672\n",
      "------------------------\n",
      "Saved Model, step is 52000\n",
      "Average loss is  0.208148052216\n",
      "Saving PER and importance weights\n",
      "step: 52000\n",
      "physactions  [ 5 10  0  5  0 10  5  0  5 19  5  5  0  0  0  0  0  0 10  0  8 15  5 19  5\n",
      "  0  5 20 10  0]\n",
      " chosen actions  [ 0  4 10  4  4  4  0  2 11 10 15 15  4  0 20  0 17 15 17  0 10 19  4 14  4\n",
      "  0 11  8  0  2]\n",
      "mean abs err: 4.3956\n",
      "mean phys Q: 10.1026\n",
      "mean agent Q: 12.6533\n",
      "------------------------\n",
      "Saved Model, step is 53000\n",
      "Average loss is  0.196269295692\n",
      "Saving PER and importance weights\n",
      "step: 53000\n",
      "physactions  [10  0 22  0  5  0  0  0 17 21  0  0  0 21 10  5 10 15  0  0  5  5  0  5  0\n",
      "  5  6  5  0 10]\n",
      " chosen actions  [20  6  0  5 20 11  0  4  8  4  0  4  0  4 11 11  0 15  0 17  5 20 12  0 11\n",
      "  0  0 22  5  7]\n",
      "mean abs err: 4.70819\n",
      "mean phys Q: 9.65287\n",
      "mean agent Q: 12.1365\n",
      "------------------------\n",
      "Saved Model, step is 54000\n",
      "Average loss is  0.235369416237\n",
      "Saving PER and importance weights\n",
      "step: 54000\n",
      "physactions  [ 0  0 10  0  5  0 23  0 24 17  0  5 11  8  0 24 20  0  0  0 15 15  0  0  0\n",
      " 20  5 13  0 10]\n",
      " chosen actions  [19  2 20 20  7  7  0  0  0 15 20 18  6  0 15 20  0  1 20  7 18  0 17  4  0\n",
      " 23  8  4 20  7]\n",
      "mean abs err: 4.69897\n",
      "mean phys Q: 11.0382\n",
      "mean agent Q: 13.9667\n",
      "------------------------\n",
      "Saved Model, step is 55000\n",
      "Average loss is  0.19715499258\n",
      "Saving PER and importance weights\n",
      "step: 55000\n",
      "physactions  [24  0 15  5 20  0 23  0  0  5 19  0 13 10  0  5 10  0  0 10  5  0  5  0  0\n",
      "  0  0 15 10  0]\n",
      " chosen actions  [15  5 17 12 17  0  4  0 20 12  1  2 20  4  5  5 17  1  0  8 17  0  0 22  5\n",
      "  4 22 11  4  1]\n",
      "mean abs err: 4.63233\n",
      "mean phys Q: 11.2398\n",
      "mean agent Q: 14.3459\n",
      "------------------------\n",
      "Saved Model, step is 56000\n",
      "Average loss is  0.204159986496\n",
      "Saving PER and importance weights\n",
      "step: 56000\n",
      "physactions  [ 5  0 17  0  0  0  0  0  0  0 17  0 10 20 10 15 10  0 18  0  0 15  0 15  3\n",
      "  0  0  0 15 15]\n",
      " chosen actions  [ 4 11 16 17  7 22 10  0 23  0  6 11  0  6  8 18  2 15 10 20 23  4  6 14 20\n",
      "  0 16  4  4  4]\n",
      "mean abs err: 4.84775\n",
      "mean phys Q: 9.75412\n",
      "mean agent Q: 12.7842\n",
      "------------------------\n",
      "Saved Model, step is 57000\n",
      "Average loss is  0.181160014629\n",
      "Saving PER and importance weights\n",
      "step: 57000\n",
      "physactions  [ 0  5  8  0  0  5  5  0 12  5  0 15  0 10  5 10 10 20  0  5  0  0  0  0 10\n",
      "  0  0 11  0  5]\n",
      " chosen actions  [10  4 17 20 10 11 16  2  0  4 11 15 15 20 14 21 16 11 10  4  7 10 16 15 11\n",
      "  4 20  5 22 11]\n",
      "mean abs err: 4.81998\n",
      "mean phys Q: 10.9784\n",
      "mean agent Q: 14.0581\n",
      "------------------------\n",
      "Saved Model, step is 58000\n",
      "Average loss is  0.251109876633\n",
      "Saving PER and importance weights\n",
      "step: 58000\n",
      "physactions  [10  0  5  5  5 10  5  0  5  5  0  0  5  0  0 20  0 24  5  5  0  0 15  5  5\n",
      "  0  0  0 10  5]\n",
      " chosen actions  [ 4 15 16 17  6 13 13  2 15 18  6 23  0  7 20  7 17  4  0  0  6  6  8 17 23\n",
      "  1 15 11 15 15]\n",
      "mean abs err: 5.00576\n",
      "mean phys Q: 9.3462\n",
      "mean agent Q: 12.37\n",
      "------------------------\n",
      "Saved Model, step is 59000\n",
      "Average loss is  0.205741977692\n",
      "Saving PER and importance weights\n",
      "step: 59000\n",
      "physactions  [14 24  0  5  5  5  0 10 10 18 15 20 22  5  0  0  0 15  6  8  5  5 20  0 20\n",
      "  5 15  0  0  5]\n",
      " chosen actions  [ 2  0  4  0 20 16  0  1  6 14 19 18 20 20  6 21  1 17 10  0 11 20  6  6 17\n",
      " 15 17  4  2  8]\n",
      "mean abs err: 4.73801\n",
      "mean phys Q: 10.6314\n",
      "mean agent Q: 13.228\n",
      "------------------------\n",
      "Saved Model, step is 60000\n",
      "Average loss is  0.24847719574\n",
      "Saving PER and importance weights\n",
      "step: 60000\n",
      "physactions  [10  0  0  0 10 20 15 20  0  0  5  0 15 10  0 13 24 20  5 15  0  0  0  0  0\n",
      "  0 10  5  0 15]\n",
      " chosen actions  [ 4 17 13 20  0  5  8 23 20 12  2 20 11 17 11 10 24 17 15  4  4 11 20  2 20\n",
      "  4  4  0  0  8]\n",
      "mean abs err: 4.82432\n",
      "mean phys Q: 10.9223\n",
      "mean agent Q: 13.8725\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Model, step is 61000\n",
      "Average loss is  0.205744282722\n",
      "Saving PER and importance weights\n",
      "step: 61000\n",
      "physactions  [ 0  0 15  5 19  0 11  0 15  5 15  5 15  0 15  0 20  5 10  5  5 10  0  0 15\n",
      "  0 20 10 14  5]\n",
      " chosen actions  [20  6 12  0  1 23 15  1 11 24 15  5  4  2 17  6  5 15  0  0 17  1 23  6 24\n",
      "  0 23 15 15  6]\n",
      "mean abs err: 5.09588\n",
      "mean phys Q: 9.97701\n",
      "mean agent Q: 12.4297\n",
      "------------------------\n",
      "Saved Model, step is 62000\n",
      "Average loss is  0.254281147003\n",
      "Saving PER and importance weights\n",
      "step: 62000\n",
      "physactions  [ 0 10 15  0 16  0 20  0  0 10 10  0 24  0 22  0 10  4  0  5  0  0  0  0 15\n",
      " 15  5 10  0  0]\n",
      " chosen actions  [24  0 18  1 15  6  0 22 23  0  0  6  0 17  0  0 13  0 13 18  6 12  2  0 15\n",
      "  0  0 15  1  1]\n",
      "mean abs err: 4.63317\n",
      "mean phys Q: 11.2066\n",
      "mean agent Q: 13.5892\n",
      "------------------------\n",
      "Saved Model, step is 63000\n",
      "Average loss is  0.174262926102\n",
      "Saving PER and importance weights\n",
      "step: 63000\n",
      "physactions  [15  5  0  5  0  5  0  5  0  5  5 23  5  0  0  0  0  5  0 15  0  0 15  0 21\n",
      "  0  5  0  5  4]\n",
      " chosen actions  [24 17  0 11 20  1  1 18  1 15  0 20 18  1 23 20 20 17  0 13  5  1  6  0  0\n",
      "  6 18 14  0 20]\n",
      "mean abs err: 4.8948\n",
      "mean phys Q: 11.3119\n",
      "mean agent Q: 13.9571\n",
      "------------------------\n",
      "Saved Model, step is 64000\n",
      "Average loss is  0.199568487167\n",
      "Saving PER and importance weights\n",
      "step: 64000\n",
      "physactions  [ 0  5  0  5  8 10  0  8  5 10 10  5  5  0  0  0  3  0 10 20  0  5 15  5  0\n",
      "  0  0  5 20  6]\n",
      " chosen actions  [ 1  6 11  6 18  0 20 15 20  6 17 20  6  5 15 16 20  1  2 18  1 11  0  4  1\n",
      "  1 23  8 20  0]\n",
      "mean abs err: 5.33444\n",
      "mean phys Q: 9.85343\n",
      "mean agent Q: 12.4741\n",
      "------------------------\n",
      "Saved Model, step is 65000\n",
      "Average loss is  0.208645144939\n",
      "Saving PER and importance weights\n",
      "step: 65000\n",
      "physactions  [ 0  0  5 15  0  5 23  0  5  0  0  0  0  0  0 15  5  5  0 10 20  0 20  0 15\n",
      " 21  0 24 15  6]\n",
      " chosen actions  [20 15  4  8 23  8  0 21  0  0  1 11 16 10 17  8 17  6  0 15 23  0  4 22 11\n",
      "  6  0 20 20 16]\n",
      "mean abs err: 4.95034\n",
      "mean phys Q: 10.4808\n",
      "mean agent Q: 13.168\n",
      "------------------------\n",
      "Saved Model, step is 66000\n",
      "Average loss is  0.172224252701\n",
      "Saving PER and importance weights\n",
      "step: 66000\n",
      "physactions  [ 0  0 23  5 20 22  0  0  0 24  0 15 11  5  0  5 20 17  5  0  0  0 20  0  0\n",
      "  0  0  0 18 10]\n",
      " chosen actions  [ 1  0  0 11  0 18  6 15 15 11  6 20  4 21 21  0  1 15  0  0 16 17  1 12  6\n",
      " 17  1  2 15  4]\n",
      "mean abs err: 5.09183\n",
      "mean phys Q: 11.0711\n",
      "mean agent Q: 13.6427\n",
      "------------------------\n",
      "Saved Model, step is 67000\n",
      "Average loss is  0.236816843987\n",
      "Saving PER and importance weights\n",
      "step: 67000\n",
      "physactions  [ 5  0 10  0 16  0 24  5  0  0  0  0 13 15  0  0  0 20  5  0 10  0 10  0 10\n",
      " 15 15 10  0  5]\n",
      " chosen actions  [14  0  8 21  0 14 11 11 22  1  0 13  0 16  0  1 15 13 17  1  0 23  8 20 16\n",
      "  0 11 17 20  0]\n",
      "mean abs err: 4.90868\n",
      "mean phys Q: 10.2093\n",
      "mean agent Q: 13.0026\n",
      "------------------------\n",
      "Saved Model, step is 68000\n",
      "Average loss is  0.171359104156\n",
      "Saving PER and importance weights\n",
      "step: 68000\n",
      "physactions  [ 5  0 20  0 15 20  0  5  0  0  0  0  0  0 20 10  0  0 15 17  0  5  0 17  0\n",
      "  8 10 24 19  0]\n",
      " chosen actions  [17  5  0  2 15  4 20 11  0 10  0  5 13  6 23 24  2  0 11 20  2  0 15 10 20\n",
      " 15 15 10  0  2]\n",
      "mean abs err: 4.96224\n",
      "mean phys Q: 11.8026\n",
      "mean agent Q: 15.1288\n",
      "------------------------\n",
      "Saved Model, step is 69000\n",
      "Average loss is  0.197712449551\n",
      "Saving PER and importance weights\n",
      "step: 69000\n",
      "physactions  [ 3 24  5 20 15  0  0  0  0 15  0  0  5  5 20  0 22 15 10  0  0  0  0 15  0\n",
      "  5  0  0  0  5]\n",
      " chosen actions  [ 0  0 18  0  0  0  5  0 12  6 15 15  0  0  7 16  4  0 18 20 15 15  0  0 22\n",
      " 11  4 15  2  0]\n",
      "mean abs err: 4.7892\n",
      "mean phys Q: 11.1254\n",
      "mean agent Q: 13.539\n",
      "------------------------\n",
      "Saved Model, step is 70000\n",
      "Average loss is  0.148954706669\n",
      "Saving PER and importance weights\n",
      "step: 70000\n",
      "physactions  [ 5  0  8  0  5  0 15  0 15 20  0 10 11  0  5  0 15  0 20 10  5  7  5  5 10\n",
      "  0 23 20  0  5]\n",
      " chosen actions  [11  0  0  0 24 23  0 15  0  8  5 15 17 15  0  2 15 18  4  0 11 15  4  0 21\n",
      "  3  0  0  2 15]\n",
      "mean abs err: 5.40758\n",
      "mean phys Q: 10.6278\n",
      "mean agent Q: 13.4006\n",
      "------------------------\n",
      "Saved Model, step is 71000\n",
      "Average loss is  0.236454109192\n",
      "Saving PER and importance weights\n",
      "step: 71000\n",
      "physactions  [ 4 24  5  0 18 10  0  0  0  0  0  5  5 10  5  0  5 20  0  5  5 10 15  5 20\n",
      "  5  0  0  0 15]\n",
      " chosen actions  [15  8 15  2 15  0 13 16 16 10  6 21 10  4 24  2  0 11  7 12 11  0 15 16 14\n",
      " 10  0  6  2  0]\n",
      "mean abs err: 4.76761\n",
      "mean phys Q: 12.3999\n",
      "mean agent Q: 14.6378\n",
      "------------------------\n",
      "Saved Model, step is 72000\n",
      "Average loss is  0.213997165203\n",
      "Saving PER and importance weights\n",
      "step: 72000\n",
      "physactions  [ 0  0  0  0 11  5  0 23  6 19 10 20 20 15  5 15  5  5  0 10  5 15 15  0 20\n",
      "  0  5  0 10  0]\n",
      " chosen actions  [ 0  8  0  0  8 21  5  0 11  2 18  4  4  6 22  0 24  0  0 15 21  4  4 13 14\n",
      "  0 11 22 24 16]\n",
      "mean abs err: 4.88092\n",
      "mean phys Q: 13.0304\n",
      "mean agent Q: 15.5776\n",
      "------------------------\n",
      "Saved Model, step is 73000\n",
      "Average loss is  0.232018388748\n",
      "Saving PER and importance weights\n",
      "step: 73000\n",
      "physactions  [ 0  0  0 10  0 15 11  0  0 15  0 10 15 15  5  0 20  5 16  0  0  5 10 20 21\n",
      "  5 20 10 20  0]\n",
      " chosen actions  [ 0 15 16  0 16  4 15  5 16 21  0 15 20 14 14 15 17  6 20 10 13 16 12  4  4\n",
      " 24 11 15 17  2]\n",
      "mean abs err: 5.3847\n",
      "mean phys Q: 10.5464\n",
      "mean agent Q: 13.0665\n",
      "------------------------\n",
      "Saved Model, step is 74000\n",
      "Average loss is  0.200686126709\n",
      "Saving PER and importance weights\n",
      "step: 74000\n",
      "physactions  [20 10  0 20  5  5 10  0 15  5  5  0  5 20  0  0 10  0 10  5 15  5 24 10  5\n",
      "  0  0  5 10  0]\n",
      " chosen actions  [17  0  0 16  0  0 18 22  0 18  0  2 15 17 11 15 11  0  4 15 15  8  5 11 18\n",
      " 11 22 10  4 15]\n",
      "mean abs err: 5.04162\n",
      "mean phys Q: 10.8417\n",
      "mean agent Q: 13.5049\n",
      "------------------------\n",
      "Saved Model, step is 75000\n",
      "Average loss is  0.340981897354\n",
      "Saving PER and importance weights\n",
      "step: 75000\n",
      "physactions  [ 0  0 24  0  5  0  0 20 13 13  0 10  5  0 10  5  5  3  5  0 20 15 10 15  5\n",
      "  6 18  5  0  0]\n",
      " chosen actions  [ 2  0 15 14  8 10 11 17 20  7  6  8 17  0 14 17  0 17 11 12 18 11 13  7 17\n",
      " 10 21 11  0  0]\n",
      "mean abs err: 4.89926\n",
      "mean phys Q: 10.8047\n",
      "mean agent Q: 13.4711\n",
      "------------------------\n",
      "Saved Model, step is 76000\n",
      "Average loss is  0.158956047058\n",
      "Saving PER and importance weights\n",
      "step: 76000\n",
      "physactions  [15  0 10 19 20  0  5  0  0 18  5 15  5  0 24  5  0  0  0  0 10  5  0  0 15\n",
      " 15  0 10  0  5]\n",
      " chosen actions  [22 20  1  6 16  0 11 14 21 17 18  8  0  0 17 15 15  8  7 11 11 16 13  0  7\n",
      " 18 16 11  8  4]\n",
      "mean abs err: 4.83455\n",
      "mean phys Q: 11.1313\n",
      "mean agent Q: 14.813\n",
      "------------------------\n",
      "Saved Model, step is 77000\n",
      "Average loss is  0.17633066082\n",
      "Saving PER and importance weights\n",
      "step: 77000\n",
      "physactions  [20 15 10 17 24  5  0  0  5 10 10  0 10  0 10  0 15 16 24 10 15 10  0 10 20\n",
      " 24 10 10  0  0]\n",
      " chosen actions  [11 21 20  8 20  8 20 13 24 20 11  6 17  5 17 24 17 15  0 23 15 17 14  4 20\n",
      "  0  7 17 21  1]\n",
      "mean abs err: 5.51926\n",
      "mean phys Q: 11.3247\n",
      "mean agent Q: 14.6827\n",
      "------------------------\n",
      "Saved Model, step is 78000\n",
      "Average loss is  0.210993855\n",
      "Saving PER and importance weights\n",
      "step: 78000\n",
      "physactions  [10  3  0  0 13  0  5 10  0  0 15  0 10 10 10  0 15 20  0  5 24  0 10  5  0\n",
      "  5 20  5  5  5]\n",
      " chosen actions  [13 20 24  1 15 10 15  0 15  1 24 20  6 21 20  4 13  5 11 20 17 14 18 11 20\n",
      "  0 17 17 20  0]\n",
      "mean abs err: 5.4324\n",
      "mean phys Q: 11.2077\n",
      "mean agent Q: 14.2817\n",
      "------------------------\n",
      "Saved Model, step is 79000\n",
      "Average loss is  0.234238090515\n",
      "Saving PER and importance weights\n",
      "step: 79000\n",
      "physactions  [ 0  0  0 10  0  0 12  5  0 20  0  0  0 10 15 20  0  0 20  0  5  0  0  5  0\n",
      "  0  0  0  0 24]\n",
      " chosen actions  [15  1  0 11 17  5 17  5  1  6  1  6 12 11 11 11 20 16 21  5  5  6 24 11  8\n",
      " 13 17  0  4 20]\n",
      "mean abs err: 5.43283\n",
      "mean phys Q: 10.7488\n",
      "mean agent Q: 13.3301\n",
      "------------------------\n",
      "Saved Model, step is 80000\n",
      "Average loss is  0.138844356537\n",
      "Saving PER and importance weights\n",
      "step: 80000\n",
      "physactions  [10  5  5  0  0  6 20  0  0  0  0  5  0  0  0  0  1  0  5  0 10  0  0  0 24\n",
      "  0  0 15  0  0]\n",
      " chosen actions  [ 6  8 15 10  0 17  4  8  0  5  0  4 11 15  0 11 23  6 15 15 24 17  0 15 15\n",
      "  6  0 10 15  4]\n",
      "mean abs err: 5.63589\n",
      "mean phys Q: 11.3002\n",
      "mean agent Q: 14.3325\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Model, step is 81000\n",
      "Average loss is  0.130662606239\n",
      "Saving PER and importance weights\n",
      "step: 81000\n",
      "physactions  [ 0  0  0  0  5  0 10  7  0  0 24  5  0  0  0  5 10  0  5  0  5  0  0  7  0\n",
      "  5  5  5  5  0]\n",
      " chosen actions  [21 18 10 10 16  0 11 11 20  0  6 15  0  0 16  8  8  0  6 10 11  6  6 20  4\n",
      "  6 11 11 11  0]\n",
      "mean abs err: 5.3419\n",
      "mean phys Q: 11.5518\n",
      "mean agent Q: 14.1699\n",
      "------------------------\n",
      "Saved Model, step is 82000\n",
      "Average loss is  0.199467320442\n",
      "Saving PER and importance weights\n",
      "step: 82000\n",
      "physactions  [ 0 15 15 10 14 10 22  0 10  0 19  5  0  0  0  0  0 20  0  5 10 10  5 10  0\n",
      "  5 10 15  0 10]\n",
      " chosen actions  [15  6 17  0 15  6  0 13 17 11 20 21 15 12  0 11 21 11 15  0  6  0 15 20 14\n",
      " 15 14  0 13 11]\n",
      "mean abs err: 5.48343\n",
      "mean phys Q: 11.5326\n",
      "mean agent Q: 14.5819\n",
      "------------------------\n",
      "Saved Model, step is 83000\n",
      "Average loss is  0.166183551311\n",
      "Saving PER and importance weights\n",
      "step: 83000\n",
      "physactions  [ 0  0 10  5  0 10 15  0  0  0  0 13  5  0  9  0  5 15  0  7  0  0  5  0 12\n",
      "  0 20  0 10  0]\n",
      " chosen actions  [10  0  6 17  6  8 15 13 10 12  7 17  8 23  0 10  0 16  6  6 15 15 15  4  8\n",
      " 10 11  6 16  0]\n",
      "mean abs err: 5.41709\n",
      "mean phys Q: 11.4938\n",
      "mean agent Q: 14.5057\n",
      "------------------------\n",
      "Saved Model, step is 84000\n",
      "Average loss is  0.184769850731\n",
      "Saving PER and importance weights\n",
      "step: 84000\n",
      "physactions  [11  5  5  0 23 15 10 23  5  0 10  0  0  5  0 15  0  0  0  0  0  8 17  0 15\n",
      "  5  0  0  0 15]\n",
      " chosen actions  [ 6 10 15 18 15 22 10 23 11  6 11 13 15  0 15 18 16 23 14 16  6 15 18 16  0\n",
      " 11 12 18  0 24]\n",
      "mean abs err: 5.14954\n",
      "mean phys Q: 11.0159\n",
      "mean agent Q: 14.4502\n",
      "------------------------\n",
      "Saved Model, step is 85000\n",
      "Average loss is  0.276327409744\n",
      "Saving PER and importance weights\n",
      "step: 85000\n",
      "physactions  [10 24  0  5  0  0 10  0 20  0  0  0  0 15  0 10  0 10 11  5  5 10 13  0 20\n",
      " 23  0  0  0  3]\n",
      " chosen actions  [13  6 11 14  8 23 24 23 20  0 12 18 13 15  3 13 24 23  8 17 11 11 20 11 10\n",
      " 21 10  1 10 24]\n",
      "mean abs err: 5.36638\n",
      "mean phys Q: 12.2731\n",
      "mean agent Q: 15.8146\n",
      "------------------------\n",
      "Saved Model, step is 86000\n",
      "Average loss is  0.207475100517\n",
      "Saving PER and importance weights\n",
      "step: 86000\n",
      "physactions  [ 5  0  0  0  0 15  0  0 11  5 20  0  0 15 15  5  0  0 10  0  0 10 15 10 10\n",
      " 22 20  5 10  0]\n",
      " chosen actions  [15  6  0  0 18  0  0  5  0 17  0 15  6 11 20 15  0 13 17 10 17 17 15 15 17\n",
      " 17  4  5 16 15]\n",
      "mean abs err: 5.79837\n",
      "mean phys Q: 10.4109\n",
      "mean agent Q: 13.7738\n",
      "------------------------\n",
      "Saved Model, step is 87000\n",
      "Average loss is  0.199979162216\n",
      "Saving PER and importance weights\n",
      "step: 87000\n",
      "physactions  [17  1 10 10  0 15  5  5  0  0  0  0 10  2  0  0  0  0  0  5 23  0  0  0  5\n",
      "  0  0 13 15 24]\n",
      " chosen actions  [ 4  5  6 14  0  6 11 15 11  1  6 10 17 15  8 11 20 20  5 20  0 20  4  0 16\n",
      " 17  5 10 20 17]\n",
      "mean abs err: 5.68539\n",
      "mean phys Q: 11.8039\n",
      "mean agent Q: 15.329\n",
      "------------------------\n",
      "Saved Model, step is 88000\n",
      "Average loss is  0.217491153717\n",
      "Saving PER and importance weights\n",
      "step: 88000\n",
      "physactions  [ 0  0  0 15 20  0  0 20  5  0  5  0  0 15  0 19 15  1  5 20 20  0  0  0 15\n",
      " 10  5  0  0  5]\n",
      " chosen actions  [24 20  0  0  0  6  0 21 18  4  6  0 11  0  0  0 15  5  0  4 22  0  0 17 11\n",
      " 18 16 18  0 20]\n",
      "mean abs err: 5.87552\n",
      "mean phys Q: 11.9452\n",
      "mean agent Q: 14.5094\n",
      "------------------------\n",
      "Saved Model, step is 89000\n",
      "Average loss is  0.199218472958\n",
      "Saving PER and importance weights\n",
      "step: 89000\n",
      "physactions  [15  0 17  3  5 20  0 15  0 10 15 10 12  0  0  0  0  0  5 18  0  5  2  0  5\n",
      "  5  0 10 21 20]\n",
      " chosen actions  [11 22  0  0  6 11  6 11 16  6 15 14  6 20  8 22 18 18 20  0 21  6 15 12  0\n",
      " 15 15 16 11 21]\n",
      "mean abs err: 5.63877\n",
      "mean phys Q: 11.2456\n",
      "mean agent Q: 13.8705\n",
      "------------------------\n",
      "Saved Model, step is 90000\n",
      "Average loss is  0.264137797356\n",
      "Saving PER and importance weights\n",
      "step: 90000\n",
      "physactions  [10  0 17  0 15  0  5  0  0 20 14 15  0 20 23  0  5 15 20 10  0 10 20 15 15\n",
      "  0 15  0  5  0]\n",
      " chosen actions  [ 6  1  4 19 18 24  0 13 17 17 15 20 18  8  5  1 20 20 24 14 21 11  1  0 11\n",
      " 13  0  0  7  1]\n",
      "mean abs err: 5.50651\n",
      "mean phys Q: 11.7549\n",
      "mean agent Q: 14.5217\n",
      "------------------------\n",
      "Saved Model, step is 91000\n",
      "Average loss is  0.205346245766\n",
      "Saving PER and importance weights\n",
      "step: 91000\n",
      "physactions  [10 10  5  0 15  0  0  0 22  0 10 19 10  0 20  8 10  0  0  5  5  0 10 12 15\n",
      " 15  0 20 10  0]\n",
      " chosen actions  [11 11 20  0 11  0  0 20  4  5 11 23 17 14 12 20  5 16 13  0  5 20 17 17 24\n",
      "  6  0 17  6 13]\n",
      "mean abs err: 5.54755\n",
      "mean phys Q: 11.379\n",
      "mean agent Q: 14.2098\n",
      "------------------------\n",
      "Saved Model, step is 92000\n",
      "Average loss is  0.160916116714\n",
      "Saving PER and importance weights\n",
      "step: 92000\n",
      "physactions  [ 0  0  0  0  0 19 15 10  5 17  0  0  0  5  0  5 10 12  0  0  0 10  5  0  5\n",
      " 15 15  5  5 20]\n",
      " chosen actions  [21  1  0 22  6 17 20 17 11 17 20  1 20  7 21  5 23 17 13 20  4  6 15 13 10\n",
      "  4  0 11  6 16]\n",
      "mean abs err: 5.36558\n",
      "mean phys Q: 11.6176\n",
      "mean agent Q: 14.5339\n",
      "------------------------\n",
      "Saved Model, step is 93000\n",
      "Average loss is  0.135477410316\n",
      "Saving PER and importance weights\n",
      "step: 93000\n",
      "physactions  [ 0  0 15  0  0  0  0  0 16  0 15  0  5 20  0 10  0  5 15  0  0  0  0 20  5\n",
      " 22  0  5  0  0]\n",
      " chosen actions  [16  0 24 20 22 15 17 15  8  0 11 20 15 14  0 15 11 24 15 15 20 20  1 11 11\n",
      " 17  1 23 10 20]\n",
      "mean abs err: 6.18168\n",
      "mean phys Q: 10.6667\n",
      "mean agent Q: 13.409\n",
      "------------------------\n",
      "Saved Model, step is 94000\n",
      "Average loss is  0.244036859512\n",
      "Saving PER and importance weights\n",
      "step: 94000\n",
      "physactions  [ 0  0  5  5  6 20  0 15 15  0  5  2  5  5 10 10  0 10  0  0  9  0 10 20 15\n",
      "  0  0  0 20  5]\n",
      " chosen actions  [15  6  8 11  0  5 10  8 11  0 22 10  6  0 11  0 12 17 24  0 24  1 24 11 17\n",
      " 16 13  1 16 17]\n",
      "mean abs err: 5.66107\n",
      "mean phys Q: 11.722\n",
      "mean agent Q: 14.656\n",
      "------------------------\n",
      "Saved Model, step is 95000\n",
      "Average loss is  0.200929170609\n",
      "Saving PER and importance weights\n",
      "step: 95000\n",
      "physactions  [ 0 10  5  0  0 15 17  0  5  0 17  5  0  0 10 20  8 13  0 10  0  0  0 20  0\n",
      " 15 11  5  0  0]\n",
      " chosen actions  [21 24 13  6  1 20 16 20  7 15  8  0  1 11  7  5  0 23 16 18 22  6  1 23 10\n",
      " 18  0 13 15  6]\n",
      "mean abs err: 5.64099\n",
      "mean phys Q: 12.4164\n",
      "mean agent Q: 15.0661\n",
      "------------------------\n",
      "Saved Model, step is 96000\n",
      "Average loss is  0.277035431862\n",
      "Saving PER and importance weights\n",
      "step: 96000\n",
      "physactions  [15 20  0 10  5  8  0  5  0 20 10 24  0 12 19 20 19 15  8  5  0 10  0 15 15\n",
      "  0 10  5  5 20]\n",
      " chosen actions  [18  7 15  6 13  0  5  8 22 14  4  0 15 15 12 16  0  7  0  1 23  8 11  8 19\n",
      " 15 20 11  7 16]\n",
      "mean abs err: 6.25648\n",
      "mean phys Q: 12.0411\n",
      "mean agent Q: 14.6156\n",
      "------------------------\n",
      "Saved Model, step is 97000\n",
      "Average loss is  0.240010554314\n",
      "Saving PER and importance weights\n",
      "step: 97000\n",
      "physactions  [10  0 14  5 10 15  0  5  9 10  0  0 15  5  0  0 24  2 10  0  0  0 24  0  0\n",
      " 20  0  0  5 22]\n",
      " chosen actions  [ 6  0 15 20  7 20  8  0  6 15 20  0 15  4 10 23 17 15  4 20 20 15 20 23 23\n",
      " 22 11  0 22 20]\n",
      "mean abs err: 6.54321\n",
      "mean phys Q: 11.013\n",
      "mean agent Q: 14.0239\n",
      "------------------------\n",
      "Saved Model, step is 98000\n",
      "Average loss is  0.230289403915\n",
      "Saving PER and importance weights\n",
      "step: 98000\n",
      "physactions  [ 0  5 20  0  0 16 15 15  0  5  5  0  8  0  0 15  5  0  0  0  0  0 10  0  0\n",
      " 15 23  0 16  0]\n",
      " chosen actions  [15  6 14  1 17  5 13 14 21  0  8  0  0 17 20 17  7 15  1 20 11 21 17 16 15\n",
      "  0 17 10  0 15]\n",
      "mean abs err: 5.81987\n",
      "mean phys Q: 9.87518\n",
      "mean agent Q: 13.4252\n",
      "------------------------\n",
      "Saved Model, step is 99000\n",
      "Average loss is  0.181288960457\n",
      "Saving PER and importance weights\n",
      "step: 99000\n",
      "physactions  [ 0  0  0 18 17 10 10  5 12  5  0  0  5  0  0 10  5 10  0  5 10  0 15  5 20\n",
      "  0 20 10 19 10]\n",
      " chosen actions  [12  6  6 10 17 15 17 15 17 15 18 14 18 15 10 17 15  8 24 15  7  5 10  7  7\n",
      " 21  6 15 11  8]\n",
      "mean abs err: 5.80863\n",
      "mean phys Q: 11.5561\n",
      "mean agent Q: 15.1566\n",
      "------------------------\n",
      "Saved Model, step is 100000\n",
      "Average loss is  0.196451426506\n",
      "Saving PER and importance weights\n",
      "step: 100000\n",
      "physactions  [ 0  0 11  0 10  0 20 10  5 10  0  0 10  5  0  0  0  1  3  0  0  0  0  0  5\n",
      "  0  0 11 20 10]\n",
      " chosen actions  [ 0 22  8 11 11  8 11 21  5 22 13 15 17 11 20 15 15 15  0  5 20 17 24 15 11\n",
      " 13 21  8 23 15]\n",
      "mean abs err: 6.5578\n",
      "mean phys Q: 10.5446\n",
      "mean agent Q: 13.157\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Model, step is 101000\n",
      "Average loss is  0.189395370483\n",
      "Saving PER and importance weights\n",
      "step: 101000\n",
      "physactions  [ 0  5  0  0  0  5  0  0  5  5 15  0 10  0  5  0 20  5  3 10  0  5  5 17 10\n",
      " 24  0 11 10  5]\n",
      " chosen actions  [22 14  7  5 13 15 15 15 22 20 15 22  5 15 20 11 23 17 24 14 17  0 17  8  0\n",
      " 13 13  6  8 15]\n",
      "mean abs err: 5.99929\n",
      "mean phys Q: 11.1536\n",
      "mean agent Q: 13.7877\n",
      "------------------------\n",
      "Saved Model, step is 102000\n",
      "Average loss is  0.187538276672\n",
      "Saving PER and importance weights\n",
      "step: 102000\n",
      "physactions  [ 5  5  0  5  0  5  0  5  5 10  5 15 10 10  0  0  0 15  0 15  0 10  0  1  5\n",
      "  5 15  0  8 10]\n",
      " chosen actions  [11 17  1 11  0 11 14 11 21  5  0 21 17 11  0 16  4  0  1  0 21 11 21 20 22\n",
      "  0  7  8 11 17]\n",
      "mean abs err: 6.03562\n",
      "mean phys Q: 11.0104\n",
      "mean agent Q: 14.0396\n",
      "------------------------\n",
      "Saved Model, step is 103000\n",
      "Average loss is  0.16456703186\n",
      "Saving PER and importance weights\n",
      "step: 103000\n",
      "physactions  [ 0  0  0  5  5 20  0 13  0  0  0  0 15 20  0 15 16  0  0  6  5 10 15  0 15\n",
      " 20  0  0  0  0]\n",
      " chosen actions  [11 16 10 15  8 11 23  0 20 15 16  6  7  4  6 20  8  6 16  0 23  8  0 15  0\n",
      " 15 10  8  6  0]\n",
      "mean abs err: 5.82723\n",
      "mean phys Q: 10.4657\n",
      "mean agent Q: 13.7068\n",
      "------------------------\n",
      "Saved Model, step is 104000\n",
      "Average loss is  0.233777229309\n",
      "Saving PER and importance weights\n",
      "step: 104000\n",
      "physactions  [ 0  0  7 20 16  0  0  0 20 10 12  5  0 23  0  5  0  5 15  5  0  0 14  0  0\n",
      " 20  0  5  5  0]\n",
      " chosen actions  [15 15 15  0 17 13  7 11 18 15 15 11 16  6 15 11 16 11  0 14 16 14  0 10  0\n",
      " 14 17  4 15  0]\n",
      "mean abs err: 6.49594\n",
      "mean phys Q: 10.7631\n",
      "mean agent Q: 13.4213\n",
      "------------------------\n",
      "Saved Model, step is 105000\n",
      "Average loss is  0.199498534203\n",
      "Saving PER and importance weights\n",
      "step: 105000\n",
      "physactions  [ 0  0 15  0  5 10  5  0  0  5 17  0 16  0 20 10  0  0  0  5  5 10  0  5 10\n",
      "  5  4 13  0  0]\n",
      " chosen actions  [20 23 11  8  0 22 15 20 16  0  0 16 16  6  6 22 14 11  6 11 11 18  0 11 20\n",
      "  0 17 24 13 23]\n",
      "mean abs err: 6.77489\n",
      "mean phys Q: 11.7459\n",
      "mean agent Q: 14.6188\n",
      "------------------------\n",
      "Saved Model, step is 106000\n",
      "Average loss is  0.203196935654\n",
      "Saving PER and importance weights\n",
      "step: 106000\n",
      "physactions  [ 0  0  5  3 21  0  0  0  0  0 10 23  0  5  0  0 19 15  0  0  0 12  0  5  0\n",
      " 15  0 11 13  0]\n",
      " chosen actions  [ 1 20 17 23 17  5 23  5 20 17 15 21 20 20 18  0 21 11 23 17 17 17 24 15  0\n",
      " 16 20 22  5 22]\n",
      "mean abs err: 6.69279\n",
      "mean phys Q: 9.31513\n",
      "mean agent Q: 13.2057\n",
      "------------------------\n",
      "Saved Model, step is 107000\n",
      "Average loss is  0.169346056461\n",
      "Saving PER and importance weights\n",
      "step: 107000\n",
      "physactions  [ 5 20  0 12  5  5  7  3 15 10 21 15 15  0  0 15 15 18  5  5  0  0 15 18  3\n",
      " 10  5  5  0  5]\n",
      " chosen actions  [20  1 18 18  1 16 17 21  4 15 15 11  7  1 16 11 14 18 16 11 14  6 17 18  0\n",
      " 16 18 14 17 13]\n",
      "mean abs err: 6.09179\n",
      "mean phys Q: 12.6895\n",
      "mean agent Q: 15.9009\n",
      "------------------------\n",
      "Saved Model, step is 108000\n",
      "Average loss is  0.266262058258\n",
      "Saving PER and importance weights\n",
      "step: 108000\n",
      "physactions  [20 10  0 10 12 15 10  0  5 20 18 20 20  0 10  0  0  0  0 10  0  5 17  0 10\n",
      "  5  0  0 15  0]\n",
      " chosen actions  [21  7 21  6 17 11 14 16 16 15 14  8 20  1  8 21 16 17  6 15 23  0  0  6 21\n",
      " 10 15  0  4 16]\n",
      "mean abs err: 5.84443\n",
      "mean phys Q: 11.6311\n",
      "mean agent Q: 14.4054\n",
      "------------------------\n",
      "Saved Model, step is 109000\n",
      "Average loss is  0.188685856819\n",
      "Saving PER and importance weights\n",
      "step: 109000\n",
      "physactions  [ 0  0  0 20  5 24  0 10 23 15  0  0  0 15  0  0  0  5  0  0  0 20  5  0  0\n",
      " 20  5  0 10 15]\n",
      " chosen actions  [15 16  1  6  4 23 15 15  8 11  0 10 21 17 15 15 21 15  5 14  1 11 21 22 17\n",
      "  6 11 23 11 11]\n",
      "mean abs err: 5.81762\n",
      "mean phys Q: 10.7436\n",
      "mean agent Q: 13.764\n",
      "------------------------\n",
      "Saved Model, step is 110000\n",
      "Average loss is  0.243821374893\n",
      "Saving PER and importance weights\n",
      "step: 110000\n",
      "physactions  [ 0 19 24  0 20  0  5 10  0 10 24  7  5  0 10  0  0  0  0  0 10  0  0 17 15\n",
      "  0  0  0  0  4]\n",
      " chosen actions  [12  0  4 13 11  6 11 17 15  8 18  0  8 15 23 15 15 16 15  6 17 15 13  4  4\n",
      " 15 11 16 15 17]\n",
      "mean abs err: 6.23219\n",
      "mean phys Q: 10.8339\n",
      "mean agent Q: 13.4134\n",
      "------------------------\n",
      "Saved Model, step is 111000\n",
      "Average loss is  0.206183107376\n",
      "Saving PER and importance weights\n",
      "step: 111000\n",
      "physactions  [15  5  0  5  0  0 10 10  0 10  0  0  0  0  0 10  5  5 14  0  0  5 20  0  0\n",
      " 20  0  5  0 20]\n",
      " chosen actions  [15 11 13 11 20 16  9 15  0  8 14 17 16 17 15  4  0 20  0  6 18  0  3  6 21\n",
      "  7 17 18 15 15]\n",
      "mean abs err: 6.11245\n",
      "mean phys Q: 10.92\n",
      "mean agent Q: 13.4533\n",
      "------------------------\n",
      "Saved Model, step is 112000\n",
      "Average loss is  0.191750026703\n",
      "Saving PER and importance weights\n",
      "step: 112000\n",
      "physactions  [ 0 15 18  5 20  0  5  0 13  5  0 10  0  0  0  0  0  6  0  0  0 20  5 10  5\n",
      "  0 10 10  0 15]\n",
      " chosen actions  [ 0  7 17  0 16  8 11 20  0 11  0 11 16 16 11  8 15 21 21  6  1  0 14  0 22\n",
      " 20 17 23 16  7]\n",
      "mean abs err: 6.84635\n",
      "mean phys Q: 11.3842\n",
      "mean agent Q: 13.9521\n",
      "------------------------\n",
      "Saved Model, step is 113000\n",
      "Average loss is  0.22527700448\n",
      "Saving PER and importance weights\n",
      "step: 113000\n",
      "physactions  [ 0 10  2  5 15 15  5  0 15  0 19 10  0  0 20 15  0  0 23 15 10  0  0  5  5\n",
      "  5 15  5  0 10]\n",
      " chosen actions  [11 23 16 13 15 22  0 14  4 21 15 11 14  1  0 23 15 15  0  4  1 20 21 17 17\n",
      " 18  1  1 16 10]\n",
      "mean abs err: 6.51802\n",
      "mean phys Q: 10.0198\n",
      "mean agent Q: 13.0962\n",
      "------------------------\n",
      "Saved Model, step is 114000\n",
      "Average loss is  0.233590476036\n",
      "Saving PER and importance weights\n",
      "step: 114000\n",
      "physactions  [ 0  5 23 10  0  5  0 17 20  5  5 15  0 15  0  0  0 10  0  0  0  0 10 22  0\n",
      " 15 10 20  6 15]\n",
      " chosen actions  [ 6  5  0 14 13 16 18  6  7  1  8 23 11 18  7  6 20 20  1  1 17 21 10 20 11\n",
      " 18 22 15 17 18]\n",
      "mean abs err: 6.69174\n",
      "mean phys Q: 10.288\n",
      "mean agent Q: 12.7801\n",
      "------------------------\n",
      "Saved Model, step is 115000\n",
      "Average loss is  0.159146162033\n",
      "Saving PER and importance weights\n",
      "step: 115000\n",
      "physactions  [15  0  0 16  0 10 10  0  5 15  0 21 15  5 15 13  0  0  5  0  0  0 15  0 10\n",
      "  0  0 12  0  5]\n",
      " chosen actions  [18  5 21 15 20  0 22 17 11 20  1 16  5 22 21 17 11  5  4 21  0  1 11 14 17\n",
      "  0  1  0  1 13]\n",
      "mean abs err: 5.65166\n",
      "mean phys Q: 12.7398\n",
      "mean agent Q: 15.1769\n",
      "------------------------\n",
      "Saved Model, step is 116000\n",
      "Average loss is  0.210196429253\n",
      "Saving PER and importance weights\n",
      "step: 116000\n",
      "physactions  [ 6  0  0 10  0  0 23  5  5  5  0  0  0 10  5  0 15  0 20  0 10 15 10 15 13\n",
      " 10 23  5 21  0]\n",
      " chosen actions  [ 0 15 15 14 22 17  5 23  1  2 11 20 20  6  4  1  7 18  1  1 18  1  1 16 18\n",
      " 17 15  6  8 11]\n",
      "mean abs err: 6.76426\n",
      "mean phys Q: 10.4462\n",
      "mean agent Q: 13.2256\n",
      "------------------------\n",
      "Saved Model, step is 117000\n",
      "Average loss is  0.205956359863\n",
      "Saving PER and importance weights\n",
      "step: 117000\n",
      "physactions  [ 0  5  0 20 16 15 15  0  0  0  0  0  0 18 10  0  0  0  0  0 23 10 15 24  0\n",
      "  0  0 15 20  0]\n",
      " chosen actions  [20 18 18  7  8  7 17  0 18 16 12 15  5 16 21 20 21  1 17 24 13  7 18 17 16\n",
      " 11 23 18 10 12]\n",
      "mean abs err: 7.64116\n",
      "mean phys Q: 11.0966\n",
      "mean agent Q: 13.781\n",
      "------------------------\n",
      "Saved Model, step is 118000\n",
      "Average loss is  0.243491544724\n",
      "Saving PER and importance weights\n",
      "step: 118000\n",
      "physactions  [ 5 10 13  5 14  0 11  0 21 15 18  0  0 10 15  5 10 10 23  5 20  5  5  5 24\n",
      " 10  0  0  0 10]\n",
      " chosen actions  [20 18 17  5 17 14 15 10 18 11  0 15 15  1 15  7  6 23 17 24 11 17 11 22 15\n",
      " 18 18 13  1 20]\n",
      "mean abs err: 6.07085\n",
      "mean phys Q: 10.4312\n",
      "mean agent Q: 13.4607\n",
      "------------------------\n",
      "Saved Model, step is 119000\n",
      "Average loss is  0.176158346176\n",
      "Saving PER and importance weights\n",
      "step: 119000\n",
      "physactions  [ 0  5  0 10 23 10 14  0 20  0  0 10  5  0  5 10 24 10  0 15 20  0  5  1  0\n",
      "  5 10  0  0  5]\n",
      " chosen actions  [ 0 12 16  0  0  0  0 16 20 22  0 22  6 11 20 22 15 17 13 15  0 13  0 20  1\n",
      " 13 11 20 18  8]\n",
      "mean abs err: 6.02129\n",
      "mean phys Q: 11.2078\n",
      "mean agent Q: 13.9168\n",
      "------------------------\n",
      "Saved Model, step is 120000\n",
      "Average loss is  0.153085781097\n",
      "Saving PER and importance weights\n",
      "step: 120000\n",
      "physactions  [ 0 10  0  5 15 20  0 15  0 11 15  0  0 10 21  0 10  0 13  5 10  5  0  5 10\n",
      "  5 15 22 24  0]\n",
      " chosen actions  [ 5 24  0 11  6  7 16 17  6 18  0  7  6 15  3 19 20 11 18 21 14 11  8 16 17\n",
      "  8  1 11  0 11]\n",
      "mean abs err: 5.95273\n",
      "mean phys Q: 10.9969\n",
      "mean agent Q: 13.6853\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Model, step is 121000\n",
      "Average loss is  0.285980156898\n",
      "Saving PER and importance weights\n",
      "step: 121000\n",
      "physactions  [15 10 20  5  0  0  0  0  0 23  0  0 15  0 15  0 20  0 10 20  0  0  5  0 20\n",
      " 20  0  0  0 15]\n",
      " chosen actions  [11 18  0 21 18  1 20 21  5  6 15  1  0 10 17 15  7 23  0 16 12 11 18  6  0\n",
      "  8  1 14 10 17]\n",
      "mean abs err: 6.57883\n",
      "mean phys Q: 9.63588\n",
      "mean agent Q: 12.8041\n",
      "------------------------\n",
      "Saved Model, step is 122000\n",
      "Average loss is  0.142714976311\n",
      "Saving PER and importance weights\n",
      "step: 122000\n",
      "physactions  [ 0  0  0 15 10  0  8  0 20  5  0  5  0 15  0 11 10  5  5  0  5  0  0  5  5\n",
      " 15  5 20  5  5]\n",
      " chosen actions  [23 13  0 16 20 15 20 20 13 17 15  8  0 11  5  0  0 11  0 15  0 11 21 17 15\n",
      " 12  0  5  7 17]\n",
      "mean abs err: 6.04711\n",
      "mean phys Q: 9.77055\n",
      "mean agent Q: 12.3106\n",
      "------------------------\n",
      "Saved Model, step is 123000\n",
      "Average loss is  0.229894126415\n",
      "Saving PER and importance weights\n",
      "step: 123000\n",
      "physactions  [ 5  0  0 15  7  0  5  0 13  5  5  0  0  0 15  0 10  3 20  0 15  0 15 10  0\n",
      " 13  0 23  5  5]\n",
      " chosen actions  [23 19  0 16  0  0  6 23 18 11 17  0 18 13  1 16 20 23 15  6  8 15  0 20  5\n",
      " 16  0  4  6 18]\n",
      "mean abs err: 7.35697\n",
      "mean phys Q: 10.7228\n",
      "mean agent Q: 13.2879\n",
      "------------------------\n",
      "Saved Model, step is 124000\n",
      "Average loss is  0.227275900841\n",
      "Saving PER and importance weights\n",
      "step: 124000\n",
      "physactions  [ 9  0 24  0 10  8  1  0  0  0 20  0  0  5  0 10  5  0 20  5 13 15  0  5  5\n",
      "  0  0 19 12 10]\n",
      " chosen actions  [ 1 13 11  0  0 15 13  5 13  1 18 20 24 23 20  0 15  6 11  0 17  6 13 20 10\n",
      " 11  0 15 11 23]\n",
      "mean abs err: 7.60804\n",
      "mean phys Q: 10.0556\n",
      "mean agent Q: 12.6141\n",
      "------------------------\n",
      "Saved Model, step is 125000\n",
      "Average loss is  0.168618138313\n",
      "Saving PER and importance weights\n",
      "step: 125000\n",
      "physactions  [ 0  5  0  0  0  0 15 15  0  0 10 19 10  0  5 24  0 12  0  0 18 10  0  0 17\n",
      "  0 10  0 10  5]\n",
      " chosen actions  [ 0  6  0 23  1 12 20 11  6 13  0  0 17  4  0 15  0 14 13 15  0 20  0 20  6\n",
      " 15 10  0 17  6]\n",
      "mean abs err: 6.7537\n",
      "mean phys Q: 11.5001\n",
      "mean agent Q: 14.4677\n",
      "------------------------\n",
      "Saved Model, step is 126000\n",
      "Average loss is  0.170124958992\n",
      "Saving PER and importance weights\n",
      "step: 126000\n",
      "physactions  [ 5  0  5  0 10 10  0  5  0 10  5 15 15 19 10  0  5  0  0  5  0 10  0 24  0\n",
      "  5  0 10  0  0]\n",
      " chosen actions  [ 3 15  8 18  4 17  4  2  1 16  8  1  6 21 17 18  6 15  0  0 11  6 21  6 10\n",
      " 15 10 11  0  8]\n",
      "mean abs err: 7.86015\n",
      "mean phys Q: 11.5019\n",
      "mean agent Q: 14.0782\n",
      "------------------------\n",
      "Saved Model, step is 127000\n",
      "Average loss is  0.153238517761\n",
      "Saving PER and importance weights\n",
      "step: 127000\n",
      "physactions  [ 0 10 11  8  0 15  0  5  0  5 15  0  5 10  0  5  0  0 15 16  5 15  0  0 20\n",
      " 15 10  0  0  0]\n",
      " chosen actions  [24  7 24  0  6 18  5  8  0 17 16 20 13 17 15 11 11  1 20  0 11  6 20  6  6\n",
      " 20 17  4 20 20]\n",
      "mean abs err: 7.8606\n",
      "mean phys Q: 11.2894\n",
      "mean agent Q: 14.0551\n",
      "------------------------\n",
      "Saved Model, step is 128000\n",
      "Average loss is  0.164259541512\n",
      "Saving PER and importance weights\n",
      "step: 128000\n",
      "physactions  [ 0  0  5  5  0 20  5  0 20  0 15  0 10 18  0  0  0  0  0  5 10  0 10 10  5\n",
      "  5  0 20 15  0]\n",
      " chosen actions  [11 14 16 17 20 11 13 13  7  6 17 20  7  0 13  0  5 23 16 20 18  6 13 11 18\n",
      " 11 13 20  5 21]\n",
      "mean abs err: 7.2121\n",
      "mean phys Q: 10.9879\n",
      "mean agent Q: 13.7264\n",
      "------------------------\n",
      "Saved Model, step is 129000\n",
      "Average loss is  0.196984161377\n",
      "Saving PER and importance weights\n",
      "step: 129000\n",
      "physactions  [ 0  0  0 15  5 20 20  0  0  0 20 15 14 10  5  0  5 17  0 15 10  5  5  0  5\n",
      "  0 20  0  5 15]\n",
      " chosen actions  [15 13 21 22  7 18 21 21 22 21 17 18 15  7 13 15 20 17  8  6 22 14  6  0 18\n",
      " 15 11  6  0  6]\n",
      "mean abs err: 6.74346\n",
      "mean phys Q: 11.4514\n",
      "mean agent Q: 14.0471\n",
      "------------------------\n",
      "Saved Model, step is 130000\n",
      "Average loss is  0.138378751755\n",
      "Saving PER and importance weights\n",
      "step: 130000\n",
      "physactions  [ 5  0  0 20 20  0  0  5  0  5  0  0  0  5  5  5  0 20 12  0  0 10  5 16  0\n",
      "  5  0  0 10  5]\n",
      " chosen actions  [11  4 13 11  6 15 20 17 15  6  5 22 20 15  0  6 20 13 21  5 15 11  0 18  8\n",
      " 16 21 13 24  6]\n",
      "mean abs err: 6.69715\n",
      "mean phys Q: 11.5127\n",
      "mean agent Q: 14.3355\n",
      "------------------------\n",
      "Saved Model, step is 131000\n",
      "Average loss is  0.105995192528\n",
      "Saving PER and importance weights\n",
      "step: 131000\n",
      "physactions  [15 10  6 10  0  0  0  5  0  5 23  0 20 19  0  9  0  0 10 10 15 15  0 24 20\n",
      " 10 10 15  0 12]\n",
      " chosen actions  [20 13 20 18 23 13  6  0 13 13  0 23  0  0 17 17 11 11 11 22 16 20 15  0 22\n",
      " 12 20 13  6 22]\n",
      "mean abs err: 6.63954\n",
      "mean phys Q: 10.2654\n",
      "mean agent Q: 12.988\n",
      "------------------------\n",
      "Saved Model, step is 132000\n",
      "Average loss is  0.140818076134\n",
      "Saving PER and importance weights\n",
      "step: 132000\n",
      "physactions  [20 15 15 23 24  0  5  5  5 15  0 15  0  0  0  0 20  0 22  0  0  8 10 10  0\n",
      "  0 10  5  5  0]\n",
      " chosen actions  [ 4  4  6 16 15 11  6 20  0  0 20 11 23  0 23 11  8 20 16 16 16  6  7  4 22\n",
      " 11 15  8  6  6]\n",
      "mean abs err: 6.07822\n",
      "mean phys Q: 10.6366\n",
      "mean agent Q: 13.5812\n",
      "------------------------\n",
      "Saved Model, step is 133000\n",
      "Average loss is  0.24157185936\n",
      "Saving PER and importance weights\n",
      "step: 133000\n",
      "physactions  [20  0  0  0  5  0 20  0  0  0  0  5 10 10 24 10  0 15 10  5 15 22 15  0  0\n",
      "  0  5  5  5  0]\n",
      " chosen actions  [18 21 20 16  6 11  7 16 11 15  8  0 14 11  6 23 18 15 16  6  6  0 24  7  0\n",
      "  0 15 13 11  6]\n",
      "mean abs err: 6.16219\n",
      "mean phys Q: 11.3302\n",
      "mean agent Q: 13.9386\n",
      "------------------------\n",
      "Saved Model, step is 134000\n",
      "Average loss is  0.173779779434\n",
      "Saving PER and importance weights\n",
      "step: 134000\n",
      "physactions  [10  0  0  5  0  0 20  5 10  0 17  0  0  0  5  5 15  0  1 10 24 15  0 20  0\n",
      "  7 10  5  5  5]\n",
      " chosen actions  [ 5 11  2 17 15 15  0  0 21  0  6 13  9 16 18 19  0 15 15  0 18 13 16  0 13\n",
      " 20  0  7 21 18]\n",
      "mean abs err: 6.99488\n",
      "mean phys Q: 8.99271\n",
      "mean agent Q: 11.9443\n",
      "------------------------\n",
      "Saved Model, step is 135000\n",
      "Average loss is  0.187663161278\n",
      "Saving PER and importance weights\n",
      "step: 135000\n",
      "physactions  [ 0  0 20  5  0  0 15 16 22  0  0  5 22  5  0  0 15 15  0  0  0  5  0 15 10\n",
      "  0  0 10  0  0]\n",
      " chosen actions  [ 0 10  0  8  0 24  4 16 15 16 20  0 14 18 15  0 15 15 23 23  0 16 17 16 22\n",
      " 15 10 23 17 17]\n",
      "mean abs err: 6.89614\n",
      "mean phys Q: 10.8214\n",
      "mean agent Q: 13.7177\n",
      "------------------------\n",
      "Saved Model, step is 136000\n",
      "Average loss is  0.162374196053\n",
      "Saving PER and importance weights\n",
      "step: 136000\n",
      "physactions  [24  0 15 10  0 20 10 10  0  0  0 19 15  0 15  0  5  0 15  0 10  5  0  0  0\n",
      "  0  0 10  5  0]\n",
      " chosen actions  [12 20  4  0  5 11 18 15 11  1  2 12 20 20  0 17 11 15 18 23 11 17  0  6 15\n",
      "  0 23  1  7 23]\n",
      "mean abs err: 6.57058\n",
      "mean phys Q: 11.2666\n",
      "mean agent Q: 13.7249\n",
      "------------------------\n",
      "Saved Model, step is 137000\n",
      "Average loss is  0.165324524879\n",
      "Saving PER and importance weights\n",
      "step: 137000\n",
      "physactions  [ 5 10  0  0  5  0  5  0  5  0  0 10  0 23  5  0 15  5  0  5 15 15 16  5  5\n",
      "  5 15 15  5  0]\n",
      " chosen actions  [21 16  0 14 18  0 15  2  6 10 18 18  1 11  0 20  7  8 13 10 18  0 18 15 24\n",
      "  0 16 18 20  1]\n",
      "mean abs err: 6.84158\n",
      "mean phys Q: 10.2483\n",
      "mean agent Q: 12.9417\n",
      "------------------------\n",
      "Saved Model, step is 138000\n",
      "Average loss is  0.141608766556\n",
      "Saving PER and importance weights\n",
      "step: 138000\n",
      "physactions  [ 0  7  0  0  0  0 22  0  0 20  0  5 23 10 10 15 20  0 10  0  0  5 20  0 24\n",
      "  5  5  0  0 10]\n",
      " chosen actions  [10 11 18  9  0 11 11 13 15 21 11 21 18 14 21 14  0 11  0 16 18 17 15 18 19\n",
      " 14  6 19 24 15]\n",
      "mean abs err: 8.22354\n",
      "mean phys Q: 10.7424\n",
      "mean agent Q: 13.5861\n",
      "------------------------\n",
      "Saved Model, step is 139000\n",
      "Average loss is  0.207890007973\n",
      "Saving PER and importance weights\n",
      "step: 139000\n",
      "physactions  [10 10  0  0  0  0 10 23 20  5  0  0  0 10 10  5  0 19 18  0  0  0  0 24  5\n",
      "  1  0  5  0  0]\n",
      " chosen actions  [11 17 15 20 15  0  6 21 15 13  7  0 14 17 10 15 11 18 18 13  0 16 11 11 15\n",
      "  4 13 20 13  1]\n",
      "mean abs err: 7.41738\n",
      "mean phys Q: 10.4706\n",
      "mean agent Q: 13.176\n",
      "------------------------\n",
      "Saved Model, step is 140000\n",
      "Average loss is  0.215227203846\n",
      "Saving PER and importance weights\n",
      "step: 140000\n",
      "physactions  [ 0 10 10 10 10  0  0  0  0  0  0 20 20  7 15 15  5  0  5 10  0 10 15  0  0\n",
      "  5  5  0  0 10]\n",
      " chosen actions  [21 17  0  0  7 18  0  0 16 10  6 11 14 11  6  1 15 10  7 10 20  6 10 20 11\n",
      "  8 10 20 10 13]\n",
      "mean abs err: 6.80028\n",
      "mean phys Q: 10.2157\n",
      "mean agent Q: 12.9105\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Model, step is 141000\n",
      "Average loss is  0.121809846401\n",
      "Saving PER and importance weights\n",
      "step: 141000\n",
      "physactions  [10  0  0  0 19 15 15  5  0  0 20  5  0 15  0  0  0  5  0  0 20  0  5 10  5\n",
      "  0 15 10 13  0]\n",
      " chosen actions  [ 8 18 10  0 10 17  0  7  1 23  0  0 13 20  0  5 14 16  1 20  6 22  0 17 15\n",
      " 11 14 17  3  2]\n",
      "mean abs err: 8.26582\n",
      "mean phys Q: 8.78602\n",
      "mean agent Q: 11.5686\n",
      "------------------------\n",
      "Saved Model, step is 142000\n",
      "Average loss is  0.123375450134\n",
      "Saving PER and importance weights\n",
      "step: 142000\n",
      "physactions  [ 3 23  0  0  0 15  8  0  0  0  0  5  0  0  0 15  5 20  5  0  0 15 12  0  0\n",
      "  0 15 10  5  0]\n",
      " chosen actions  [15 15 11 21  0 17 17 13 13 11 15 15  7 13 13  8 18  0 17 14  2 21 20 11 16\n",
      " 23  6  0 14 15]\n",
      "mean abs err: 7.38713\n",
      "mean phys Q: 10.2722\n",
      "mean agent Q: 13.1456\n",
      "------------------------\n",
      "Saved Model, step is 143000\n",
      "Average loss is  0.180289680481\n",
      "Saving PER and importance weights\n",
      "step: 143000\n",
      "physactions  [21  0  0  0  0  0  0  0  0  5  5 24 20  0  5  0  0  0  5  5  5  0 19  5  0\n",
      "  0  0  5  5  0]\n",
      " chosen actions  [17 21  0 18 14 16 15 23 23  0  0  6  5  0  6 15  6 15 20  0 17 13 12  6  0\n",
      " 21 15 20 23 22]\n",
      "mean abs err: 8.13545\n",
      "mean phys Q: 10.3241\n",
      "mean agent Q: 13.7481\n",
      "------------------------\n",
      "Saved Model, step is 144000\n",
      "Average loss is  0.249512818336\n",
      "Saving PER and importance weights\n",
      "step: 144000\n",
      "physactions  [ 0 19  5 15 10  0  0 10 10 20  5  0  5  0 10  0 10  0 15 10  0  5  0  5  0\n",
      " 22  5  5  0  5]\n",
      " chosen actions  [ 0  0 15  0  0  0 24 14 12 18 20 13  0 16 14 16 13 16 16  0 23 15  0  0 16\n",
      "  0 20  0 16  0]\n",
      "mean abs err: 8.17427\n",
      "mean phys Q: 9.98368\n",
      "mean agent Q: 12.6522\n",
      "------------------------\n",
      "Saved Model, step is 145000\n",
      "Average loss is  0.185568553925\n",
      "Saving PER and importance weights\n",
      "step: 145000\n",
      "physactions  [20 10  5 20  5  0  0 21  0  0 15 20 10 15 10 11  5  0  0  0  0  0 10 20  0\n",
      "  0 15  0  5 20]\n",
      " chosen actions  [22 24 22  0 20 11 15 14 16 10 15 20 17 24  0 24 10 16 11 13 11 16  1  7 16\n",
      " 16 11 22 15 17]\n",
      "mean abs err: 7.33969\n",
      "mean phys Q: 11.1888\n",
      "mean agent Q: 15.0039\n",
      "------------------------\n",
      "Saved Model, step is 146000\n",
      "Average loss is  0.176165030003\n",
      "Saving PER and importance weights\n",
      "step: 146000\n",
      "physactions  [ 0  0 15  5 10  0 10 20  5 21  0  0  5 15  0  0 15 15  5  5 12  0  0 15  0\n",
      "  0  0  5 24  5]\n",
      " chosen actions  [13 15 16 17 14 21  8 10  1  0  5 20  6 17 23 16 13 17  8 20  0 12 10 17 15\n",
      " 18 20 17  8  0]\n",
      "mean abs err: 7.03158\n",
      "mean phys Q: 10.8409\n",
      "mean agent Q: 14.0193\n",
      "------------------------\n",
      "Saved Model, step is 147000\n",
      "Average loss is  0.217699968338\n",
      "Saving PER and importance weights\n",
      "step: 147000\n",
      "physactions  [ 5  0  0  0  5  5  0  0 21  5 10 10 10  0  0 20  5  5  0  5  0  0  5  0  0\n",
      "  0  5  0  0  0]\n",
      " chosen actions  [22  4  5 15  8 16 15 14  6 18 16 17  8 21  8 15 15  6 11  1 22 15 17  8 13\n",
      " 17  5 15  0 11]\n",
      "mean abs err: 7.52446\n",
      "mean phys Q: 9.62875\n",
      "mean agent Q: 12.9316\n",
      "------------------------\n",
      "Saved Model, step is 148000\n",
      "Average loss is  0.1972641716\n",
      "Saving PER and importance weights\n",
      "step: 148000\n",
      "physactions  [10 10  5  0  0 10  0  5 20 10  0 24  5 20  0 15  5  5  0  5  5  0  0 15  0\n",
      "  0  0 15  0 23]\n",
      " chosen actions  [10  0 10 16  1 11  0 18  8 20 14 15  8 16 10 10  6  6  8 18  7  7 13 24 21\n",
      "  1  0  0 10 17]\n",
      "mean abs err: 7.95374\n",
      "mean phys Q: 10.5225\n",
      "mean agent Q: 13.4461\n",
      "------------------------\n",
      "Saved Model, step is 149000\n",
      "Average loss is  0.195069009781\n",
      "Saving PER and importance weights\n",
      "step: 149000\n",
      "physactions  [24  0  5 10  0 22  3 11  0  0  0 10  0 20  0  0  5  0 20 16  0 10  5  5  0\n",
      " 10 10  0  0  0]\n",
      " chosen actions  [15  6 15  8 24 17 15  7  1  0  1 11  7 15 10 15 15  5 12 11  1 10 14  4 18\n",
      " 21  7 16  0  0]\n",
      "mean abs err: 8.44212\n",
      "mean phys Q: 10.0141\n",
      "mean agent Q: 12.7554\n",
      "------------------------\n",
      "Saved Model, step is 150000\n",
      "Average loss is  0.189615365028\n",
      "Saving PER and importance weights\n",
      "step: 150000\n",
      "physactions  [10  0  0 20 10  0 24  0  0 15  0  8  0  5  5  0 10  0  0 20  5 14  0  0  0\n",
      "  0  0  5 10  0]\n",
      " chosen actions  [ 6  1 18 11  6 11  0 21 21  6 17 20 24  8 20 17 11  8 21 21 17 15 24  6  6\n",
      "  1 21 17 21 11]\n",
      "mean abs err: 7.60037\n",
      "mean phys Q: 10.5786\n",
      "mean agent Q: 13.6236\n",
      "------------------------\n",
      "Saved Model, step is 151000\n",
      "Average loss is  0.220097847939\n",
      "Saving PER and importance weights\n",
      "step: 151000\n",
      "physactions  [ 0  0  8  5  0 10 20 10 12  0  5  0  0  5  0  0  0  5 12 17 10  1  0  0  0\n",
      "  0 10 15  0  0]\n",
      " chosen actions  [20  5 12 15 18 15 16  6  1 15 15 15 11  8 24  5  1 15  6 22 10  8 14 16  4\n",
      " 15 14  4  1 15]\n",
      "mean abs err: 7.89857\n",
      "mean phys Q: 10.4891\n",
      "mean agent Q: 13.375\n",
      "------------------------\n",
      "Saved Model, step is 152000\n",
      "Average loss is  0.18750478363\n",
      "Saving PER and importance weights\n",
      "step: 152000\n",
      "physactions  [ 5 10  0  0 10  0  5 15 10  0  5  5  0  5  0  0  5 15  0  0  0 15  0 20  0\n",
      " 22  0  5  0 20]\n",
      " chosen actions  [24 15  0  0  4  0 22  7 22 23 22 16 15 13 24 11  7  6 20 15  5 16 14  4 15\n",
      " 13  0 23  6 10]\n",
      "mean abs err: 8.04494\n",
      "mean phys Q: 9.42304\n",
      "mean agent Q: 12.6601\n",
      "------------------------\n",
      "Saved Model, step is 153000\n",
      "Average loss is  0.18538265276\n",
      "Saving PER and importance weights\n",
      "step: 153000\n",
      "physactions  [10 15  0  0  6  0 20  0  0 10  0  0  5  0  0 10  0 24  0  5 13  0 24  0  5\n",
      "  0 15 22 10 20]\n",
      " chosen actions  [ 1 13  1 23 16 15 11 20 15  5 16 15 18  6 14 21 24 11 15  8  8 15 15 15 20\n",
      " 15 17  0  6 13]\n",
      "mean abs err: 9.54706\n",
      "mean phys Q: 9.9334\n",
      "mean agent Q: 13.0393\n",
      "------------------------\n",
      "Saved Model, step is 154000\n",
      "Average loss is  0.157576217651\n",
      "Saving PER and importance weights\n",
      "step: 154000\n",
      "physactions  [15 15  0  0  0 15  0  0  0  5 15  5 15 20  0  5  0 16  5  0 15  0 20  0  5\n",
      " 18  0  5  0 10]\n",
      " chosen actions  [13 11  0  0  6 11  0 20  1  0  0  0  1 18 21 18  0  0  6  8  0  0  0 20  0\n",
      " 18  0  0  0 13]\n",
      "mean abs err: 8.13985\n",
      "mean phys Q: 10.1265\n",
      "mean agent Q: 13.0973\n",
      "------------------------\n",
      "Saved Model, step is 155000\n",
      "Average loss is  0.236278268814\n",
      "Saving PER and importance weights\n",
      "step: 155000\n",
      "physactions  [10  5  4 15  0  5  0 15  8  0  0  0  0 10 10  5 15 18 15  0  5 10  5 10  5\n",
      " 15 10  0  9  0]\n",
      " chosen actions  [17 15 15 17  1 11 23  4 13 10 22 11 11  7 15 21 18  0 11 23 11 14  1 20  0\n",
      "  8 17 20  0 13]\n",
      "mean abs err: 7.14927\n",
      "mean phys Q: 10.8166\n",
      "mean agent Q: 13.9091\n",
      "------------------------\n",
      "Saved Model, step is 156000\n",
      "Average loss is  0.212429538727\n",
      "Saving PER and importance weights\n",
      "step: 156000\n",
      "physactions  [ 0  0 24 20  0 20 15  0  0 21 10  0 20  0  5  5  5 15  0  5  0 20  1  5  5\n",
      "  0  5 15  0  0]\n",
      " chosen actions  [21 15 14 16 12  0 18  5 12 15 23 19  4 16 23 15  1  7 22 17 16 11 18 21  8\n",
      "  9 14 18  6  0]\n",
      "mean abs err: 6.82364\n",
      "mean phys Q: 10.8235\n",
      "mean agent Q: 14.2573\n",
      "------------------------\n",
      "Saved Model, step is 157000\n",
      "Average loss is  0.174681984425\n",
      "Saving PER and importance weights\n",
      "step: 157000\n",
      "physactions  [ 5  5 10  0 20  0 15 10  5 20 10  0  0  0  5  5 10 10 21  5  0  0 10  5 15\n",
      " 15  0 10  5  0]\n",
      " chosen actions  [10 16 13 12  6 23  3 16 20 21 16  1 13 20  4  7 17 18  8  1 15 13  6 20 20\n",
      " 20 20  6 20  9]\n",
      "mean abs err: 9.09525\n",
      "mean phys Q: 9.60414\n",
      "mean agent Q: 12.8143\n",
      "------------------------\n",
      "Saved Model, step is 158000\n",
      "Average loss is  0.194120110512\n",
      "Saving PER and importance weights\n",
      "step: 158000\n",
      "physactions  [18  0  9 20  5 10  8 10  0  0 20  0  0 15  0  0  0 20 15 19 15  0  0  0  5\n",
      "  0  0  0  0  5]\n",
      " chosen actions  [18  7 11 10 23  0 16  4  4  0 11  0 12 22 14  0 10  8 10  6 24 15 20 23 18\n",
      " 20  6 10 13 20]\n",
      "mean abs err: 9.21432\n",
      "mean phys Q: 10.8034\n",
      "mean agent Q: 13.5817\n",
      "------------------------\n",
      "Saved Model, step is 159000\n",
      "Average loss is  0.182448587418\n",
      "Saving PER and importance weights\n",
      "step: 159000\n",
      "physactions  [ 0  0 20 20 10 10 20  7  0 10 17  0  0 10 15  0  0 10  0  5 24 10 15  5  5\n",
      "  0  0 10  0  5]\n",
      " chosen actions  [15 16  6  8 11  6 17  7 22  0 22 14 24 18 24 16 16 13 21  0  0  1 15  0 11\n",
      "  5 11 17 23  0]\n",
      "mean abs err: 8.26519\n",
      "mean phys Q: 10.2611\n",
      "mean agent Q: 13.4287\n",
      "------------------------\n",
      "Saved Model, step is 160000\n",
      "Average loss is  0.186814529419\n",
      "Saving PER and importance weights\n",
      "step: 160000\n",
      "physactions  [24  0  0 15  3  0 15  0  0 17  0  5  0 15  5 15  0  0 21 10 15 16  0  9 15\n",
      "  0 15  0 15 20]\n",
      " chosen actions  [11 10 22 17 21 21 21 18 15  4  1  0 15 22 22 21  6 22  0 13 11 14 11 17 11\n",
      " 22 16 20  7 24]\n",
      "mean abs err: 9.12398\n",
      "mean phys Q: 9.10645\n",
      "mean agent Q: 12.2324\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Model, step is 161000\n",
      "Average loss is  0.186032026291\n",
      "Saving PER and importance weights\n",
      "step: 161000\n",
      "physactions  [ 0 24  5 20 10  0  5  5  5 12  0  0  0  0  0  0  5 22  0 15  0  0  5  0 10\n",
      " 20  5 10  0 10]\n",
      " chosen actions  [16  0 24 18 13  8 20 16 11 19 13 20 20 20 18 24 11  0 20  0  1  8 15 20  0\n",
      "  4  6 18 11  3]\n",
      "mean abs err: 8.96546\n",
      "mean phys Q: 8.9558\n",
      "mean agent Q: 12.2453\n",
      "------------------------\n",
      "Saved Model, step is 162000\n",
      "Average loss is  0.200010473251\n",
      "Saving PER and importance weights\n",
      "step: 162000\n",
      "physactions  [ 0  0 10  0  5 15 13  0 10 10  0 18  0  5  0  0  8 10 12  0  0  0  0 10  5\n",
      "  0  0  5  0  0]\n",
      " chosen actions  [ 1 21  0  1 15 13 10 10 18 10 12  0 16 15 15 11 17  6 21 21  5  8 17 15  6\n",
      " 11  0 17 15  0]\n",
      "mean abs err: 8.16106\n",
      "mean phys Q: 10.8536\n",
      "mean agent Q: 13.6115\n",
      "------------------------\n",
      "Saved Model, step is 163000\n",
      "Average loss is  0.164190644264\n",
      "Saving PER and importance weights\n",
      "step: 163000\n",
      "physactions  [ 0  5 10  0 10  0 10 19  4  0  0  0 20  0 10  0 11 20 15  0 15  0 10  5 10\n",
      " 15 10  5  0 15]\n",
      " chosen actions  [11  0 18 24  4  1 15 18 17 20 20 24 13 20  0  5  9  0 20 23  0 24  0 11 15\n",
      "  1  6 20 11 14]\n",
      "mean abs err: 7.01336\n",
      "mean phys Q: 10.683\n",
      "mean agent Q: 13.5317\n",
      "------------------------\n",
      "Saved Model, step is 164000\n",
      "Average loss is  0.259964490891\n",
      "Saving PER and importance weights\n",
      "step: 164000\n",
      "physactions  [ 0  0 17  0 21 14  0  8  0  0 13  5  0 15  0 10 15 10 10  0 15 20 20 15  0\n",
      "  0 15  5  0  5]\n",
      " chosen actions  [ 1 10  8 16 15  0  5  6  1 21  6 13 16 11  0 20 10  6  8  0  0 22 22  6  5\n",
      "  0 21 17 23 11]\n",
      "mean abs err: 7.34591\n",
      "mean phys Q: 10.2077\n",
      "mean agent Q: 13.5293\n",
      "------------------------\n",
      "Saved Model, step is 165000\n",
      "Average loss is  0.169003548622\n",
      "Saving PER and importance weights\n",
      "step: 165000\n",
      "physactions  [ 0 23  0  0  0  0  0  6  5 15 15  0 23  0  0  5  5 10  0  5  0  5  0  5  0\n",
      "  0  0  5  5  0]\n",
      " chosen actions  [11  4  7  6 20 20  0 17 11  7  1 20  8 10 12 15 14 11  0  6 24 15  6 23  0\n",
      " 15 20 20  8  1]\n",
      "mean abs err: 7.24298\n",
      "mean phys Q: 10.6343\n",
      "mean agent Q: 13.3824\n",
      "------------------------\n",
      "Saved Model, step is 166000\n",
      "Average loss is  0.207063135624\n",
      "Saving PER and importance weights\n",
      "step: 166000\n",
      "physactions  [13  0  5  5  5 20  0  5  0  0 15  0 20  5  0 10 13 22  0  5  0 10 10 10  0\n",
      "  0  5  0  5  0]\n",
      " chosen actions  [20  0 20 10  5 11 23 23 17  0 13  5  0 13  5  0  8 11 15 20  8 24  4 24 15\n",
      " 14 16  0  8 20]\n",
      "mean abs err: 7.33276\n",
      "mean phys Q: 10.7067\n",
      "mean agent Q: 13.9579\n",
      "------------------------\n",
      "Saved Model, step is 167000\n",
      "Average loss is  0.164047254562\n",
      "Saving PER and importance weights\n",
      "step: 167000\n",
      "physactions  [12  0 10  0 15 15  0  0  5 10 20  0 20  0  0  0  0 10  0 15  0  0  0  0  0\n",
      "  0 20  5  0  0]\n",
      " chosen actions  [22 16 11  0 21 11  0  1 17 14 15 13  8 23 15  0 10 17 14 15 16 20 15  5 23\n",
      " 23  6 16 17 23]\n",
      "mean abs err: 7.23362\n",
      "mean phys Q: 11.6463\n",
      "mean agent Q: 14.4987\n",
      "------------------------\n",
      "Saved Model, step is 168000\n",
      "Average loss is  0.14161439991\n",
      "Saving PER and importance weights\n",
      "step: 168000\n",
      "physactions  [ 0  5  5 10  5  0 15  0  0  0  0  5 15  0 10  0  0  0  0 23 10  0 20  0  0\n",
      "  0  5  5  5 10]\n",
      " chosen actions  [15 15 11 11 10  8 20 10 15 14 20  6  5 17 15  8 15 15  4 14  8  1 11 12  3\n",
      " 16 13 11 17 15]\n",
      "mean abs err: 6.53951\n",
      "mean phys Q: 11.1859\n",
      "mean agent Q: 13.9816\n",
      "------------------------\n",
      "Saved Model, step is 169000\n",
      "Average loss is  0.246085618973\n",
      "Saving PER and importance weights\n",
      "step: 169000\n",
      "physactions  [ 0 10  0 20 15  0 20  0  5  0  5  5  9 10  0  0 17 20  0 10  0  0  0 23 20\n",
      "  0  0  5  0 10]\n",
      " chosen actions  [13 10  3 10 16  1  1 11  4  6  0 11 10  6 14 21 24 11 20  0  0 16  5 17  4\n",
      " 20  6 22 11 16]\n",
      "mean abs err: 7.23689\n",
      "mean phys Q: 11.9508\n",
      "mean agent Q: 14.5467\n",
      "------------------------\n",
      "Saved Model, step is 170000\n",
      "Average loss is  0.256377456665\n",
      "Saving PER and importance weights\n",
      "step: 170000\n",
      "physactions  [ 5  0  0 15 10  5 20  3  5  0  0  0 20  0 24  0 15  0  0  5 10  0  0 12  0\n",
      " 15 20 15  5  0]\n",
      " chosen actions  [23 13 17 21  6 17 15 17 22 17  6  0 22  7  0  1 17 11 20 20 15 23  0  6 20\n",
      " 10  0 17 14 20]\n",
      "mean abs err: 6.70724\n",
      "mean phys Q: 11.436\n",
      "mean agent Q: 14.4083\n",
      "------------------------\n",
      "Saved Model, step is 171000\n",
      "Average loss is  0.24246525526\n",
      "Saving PER and importance weights\n",
      "step: 171000\n",
      "physactions  [10  0  0  0 22  5  0  0  0  7 10  0  5 15  0 15  5 10 16 10  0  5  5  5  0\n",
      " 11  0  5  8 10]\n",
      " chosen actions  [ 5 13 16 10 20 11 22 20 18 15  6 16 15 16 18  4 16  8 11 14 11  0 13 18  3\n",
      " 18  1 16 11 14]\n",
      "mean abs err: 7.16357\n",
      "mean phys Q: 10.4081\n",
      "mean agent Q: 13.6581\n",
      "------------------------\n",
      "Saved Model, step is 172000\n",
      "Average loss is  0.151193310738\n",
      "Saving PER and importance weights\n",
      "step: 172000\n",
      "physactions  [ 5  0 14  0  0  0  5  0  0 24  0 24  5  0  0  5 15  5  0  5  5  0  0  0 20\n",
      " 10  0  0  0 15]\n",
      " chosen actions  [ 6 18 18 21 15 11 21 14  1  4 15  9  5 13 12 11 15 10 14  6  7 15 13 13  5\n",
      "  0 21 20 17  0]\n",
      "mean abs err: 7.46998\n",
      "mean phys Q: 9.64001\n",
      "mean agent Q: 13.39\n",
      "------------------------\n",
      "Saved Model, step is 173000\n",
      "Average loss is  0.15429625082\n",
      "Saving PER and importance weights\n",
      "step: 173000\n",
      "physactions  [ 0  0  5 15  5 10  0  5 16  0  0 20  0  5  0  0  0  5  0  8  0 10 20  0  0\n",
      "  5 10  0 14  5]\n",
      " chosen actions  [11 15 17 16 17  0 15  8 20 15 15 14 15 11 13 17  5  0 11 14 20  3  6  6  6\n",
      "  5  0 15 15 15]\n",
      "mean abs err: 7.69761\n",
      "mean phys Q: 9.83112\n",
      "mean agent Q: 14.22\n",
      "------------------------\n",
      "Saved Model, step is 174000\n",
      "Average loss is  0.241382699966\n",
      "Saving PER and importance weights\n",
      "step: 174000\n",
      "physactions  [18 10 19  0 23  5  5 13  5  0  0 20  0  0 24  8  0  0 15  0 15  7  5 20  0\n",
      "  0  0  0  5 20]\n",
      " chosen actions  [11 11 14  7 15 18 22  8 13  0  0 11  1 10  6 13  1 20 22  7  7  5  1 15 20\n",
      "  6 20 13 23 20]\n",
      "mean abs err: 8.40731\n",
      "mean phys Q: 10.0717\n",
      "mean agent Q: 13.7062\n",
      "------------------------\n",
      "Saved Model, step is 175000\n",
      "Average loss is  0.18346797657\n",
      "Saving PER and importance weights\n",
      "step: 175000\n",
      "physactions  [ 0  0  5  0  5  0  0  5  0  1  0  0 15  5  0  9  0  5  0  0  0 15 22  0  0\n",
      "  0 24  0  5  0]\n",
      " chosen actions  [22 21 16 12 19 15 10  6  0 11 23  5  9  8 22  8 16 11 21  0 14 21 17  0 15\n",
      " 16 11  0 17  9]\n",
      "mean abs err: 8.91831\n",
      "mean phys Q: 9.79623\n",
      "mean agent Q: 13.5987\n",
      "------------------------\n",
      "Saved Model, step is 176000\n",
      "Average loss is  0.158162474632\n",
      "Saving PER and importance weights\n",
      "step: 176000\n",
      "physactions  [ 5  0  5 15  5 24  0  0  0 10  0  0  0  5 15 20 10  5  0  0  0 15  0 14  0\n",
      "  5  5 24  0 22]\n",
      " chosen actions  [21  3  6 20 11 13  0  6 20  6  8 10 21 14 13  8 14 14 23  7  8  6 21 17 23\n",
      " 13 11 15 18 14]\n",
      "mean abs err: 8.50063\n",
      "mean phys Q: 9.98862\n",
      "mean agent Q: 13.1407\n",
      "------------------------\n",
      "Saved Model, step is 177000\n",
      "Average loss is  0.171372611046\n",
      "Saving PER and importance weights\n",
      "step: 177000\n",
      "physactions  [24  0 10  5  0  0  0 10  0  0  5 10  0  5 15  0  0 15  0  0 11 20 20  0 15\n",
      "  7  6 10 10 15]\n",
      " chosen actions  [18 15 16 15 18  1 21  6  1  0 20 13 15  9 11 21  1 13  6 21 17 10  6  0 18\n",
      " 17 21 11 16 17]\n",
      "mean abs err: 9.59318\n",
      "mean phys Q: 9.67267\n",
      "mean agent Q: 13.0597\n",
      "------------------------\n",
      "Saved Model, step is 178000\n",
      "Average loss is  0.176147961617\n",
      "Saving PER and importance weights\n",
      "step: 178000\n",
      "physactions  [ 0  5  5 10  0 15 10 11 15 10  0  0 22  0  5  0 10 15  0  5 10  0  0  0  0\n",
      "  5  0 16  0  0]\n",
      " chosen actions  [24 15 24 20 20 11  8 24 11 19  8  1 15  9  6 11 15  4 11 10  8 13  5 13 10\n",
      "  0  7  8 21 13]\n",
      "mean abs err: 7.5968\n",
      "mean phys Q: 9.22914\n",
      "mean agent Q: 12.6245\n",
      "------------------------\n",
      "Saved Model, step is 179000\n",
      "Average loss is  0.208134993553\n",
      "Saving PER and importance weights\n",
      "step: 179000\n",
      "physactions  [20 10  0  5  3  5 23  0  4  0  0  4  5 20  0 16  1  0  0  5  0  0 15  5  0\n",
      "  0 20  5  0  0]\n",
      " chosen actions  [20 11  0 17 11 21  0 13 17 24 16 21  4 21 23  0  7 21 10 13  1  1  5 16 16\n",
      "  6  6  6 13 21]\n",
      "mean abs err: 7.52649\n",
      "mean phys Q: 9.49406\n",
      "mean agent Q: 12.4961\n",
      "------------------------\n",
      "Saved Model, step is 180000\n",
      "Average loss is  0.170495049953\n",
      "Saving PER and importance weights\n",
      "step: 180000\n",
      "physactions  [ 5 10  5  0  0  5 15  0 10 10 15  0  5  0  0  5  5 20 10  0 15  5  0 10  5\n",
      "  7 10 20  5  0]\n",
      " chosen actions  [ 0  8  2  7 21 14 16 24 13  8 15 13 17 11 21 17  5 22  8 20  1 19 20  5 17\n",
      "  7 21 12 10 20]\n",
      "mean abs err: 7.54387\n",
      "mean phys Q: 11.2363\n",
      "mean agent Q: 14.2275\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Model, step is 181000\n",
      "Average loss is  0.173847006798\n",
      "Saving PER and importance weights\n",
      "step: 181000\n",
      "physactions  [ 5  0  0  0 15 15  0 24  0  0  0 10 15  5 10  0  0 10 12  0  5 15  0 24 15\n",
      " 24  0 19  0  5]\n",
      " chosen actions  [21  1  1 13 17 15  0 17 16  1 21  8 20 10 20 21 22 11 16 20  0  0 17  0  7\n",
      " 15 20 17  1  0]\n",
      "mean abs err: 7.62198\n",
      "mean phys Q: 10.9539\n",
      "mean agent Q: 14.3572\n",
      "------------------------\n",
      "Saved Model, step is 182000\n",
      "Average loss is  0.183545660496\n",
      "Saving PER and importance weights\n",
      "step: 182000\n",
      "physactions  [ 0 15 10  5  0  0  0 15  5  5  0 10  5  0  0 15 24 15  5 20  0  0  0 10  0\n",
      "  0 10  0  0 23]\n",
      " chosen actions  [20  6  0 11  1  6  1  0  0 12 13 11 13 20  1  8 17 22 20 15 23  2 21  0  6\n",
      "  0  0  1 20  0]\n",
      "mean abs err: 6.93467\n",
      "mean phys Q: 12.1298\n",
      "mean agent Q: 15.3091\n",
      "------------------------\n",
      "Saved Model, step is 183000\n",
      "Average loss is  0.24547613287\n",
      "Saving PER and importance weights\n",
      "step: 183000\n",
      "physactions  [15  1  5 10 15 15 10 10  0 20 10  0 21  5 15  0  5  0 15  0  5  5  5 10  0\n",
      "  0  0  0 20  0]\n",
      " chosen actions  [ 7 16  0  6 20  8 18 15  6  1 16  1 13 24 17 10 15  0 13 12  0  8 18  1 12\n",
      "  6 11  1 15  0]\n",
      "mean abs err: 8.52236\n",
      "mean phys Q: 9.6733\n",
      "mean agent Q: 12.9898\n",
      "------------------------\n",
      "Saved Model, step is 184000\n",
      "Average loss is  0.198406375408\n",
      "Saving PER and importance weights\n",
      "step: 184000\n",
      "physactions  [15 16  0  0  0 21 15 15  0  5  0 11 20 10 18 10  0  0  0  0 15  0 10  0  5\n",
      "  0  8  5 10  5]\n",
      " chosen actions  [11  0 20  1 21 17 23  0  6 20 17  0 19 17  9  7 15 13 11 13 18 20 16  1 13\n",
      " 13 17 20 20  9]\n",
      "mean abs err: 8.63926\n",
      "mean phys Q: 10.6109\n",
      "mean agent Q: 14.7355\n",
      "------------------------\n",
      "Saved Model, step is 185000\n",
      "Average loss is  0.161223577499\n",
      "Saving PER and importance weights\n",
      "step: 185000\n",
      "physactions  [20 15  5  5  0  0 12  8  0  0 16  0  0 15  0  0 24  0 15  0  0 15  0  0 24\n",
      " 16 24  0  0 15]\n",
      " chosen actions  [17  7 17 11 11  2 21 14  5 13 21 13  5  2 13 18  0  1 18  1 11 22  5 15  0\n",
      "  6  5 16 16  8]\n",
      "mean abs err: 8.67915\n",
      "mean phys Q: 10.9011\n",
      "mean agent Q: 14.3553\n",
      "------------------------\n",
      "Saved Model, step is 186000\n",
      "Average loss is  0.258118672848\n",
      "Saving PER and importance weights\n",
      "step: 186000\n",
      "physactions  [ 5 18  5  0  0  5  5  0 10 15  0  5  0 10  5  0 20  5 11 20 20  0  0  0 22\n",
      " 16  0  5  0 15]\n",
      " chosen actions  [20 21 23 10 21 15 10  0  7  6 14  0  0 17  8  8 14 14  7 11 18  0  1 16 21\n",
      " 17  7 20 18  1]\n",
      "mean abs err: 7.75611\n",
      "mean phys Q: 10.6303\n",
      "mean agent Q: 13.7584\n",
      "------------------------\n",
      "Saved Model, step is 187000\n",
      "Average loss is  0.201742637634\n",
      "Saving PER and importance weights\n",
      "step: 187000\n",
      "physactions  [10 20 23 24  0  0  0 23 15  5 19 15  0  0 10 15 10  0  0 15  0  0 15 10  5\n",
      " 20  8  0  5  0]\n",
      " chosen actions  [17  6  8  8 15 21  1  0 17  2 20 21 14 20  6 18  5 20  1 18 15 17  7 23 20\n",
      "  7 18 20 22  6]\n",
      "mean abs err: 8.02394\n",
      "mean phys Q: 9.73942\n",
      "mean agent Q: 13.2834\n",
      "------------------------\n",
      "Saved Model, step is 188000\n",
      "Average loss is  0.175263538361\n",
      "Saving PER and importance weights\n",
      "step: 188000\n",
      "physactions  [15  0  0 20 20  0 22  0  5  0  0  5 10 19  0  0 15  0  7  0  0  0  0  6 23\n",
      "  0  0  0 20 10]\n",
      " chosen actions  [22 24 19  0 11 15  1 20  8 15 10 22 17  0  5 11  6  4 17 20 11 20  7 16  6\n",
      "  1 17  8  0 23]\n",
      "mean abs err: 8.48266\n",
      "mean phys Q: 8.59433\n",
      "mean agent Q: 12.4281\n",
      "------------------------\n",
      "Saved Model, step is 189000\n",
      "Average loss is  0.243817023277\n",
      "Saving PER and importance weights\n",
      "step: 189000\n",
      "physactions  [13 15  0  0  0 24  0  0  0  0 10  0  0 24  0 10 15 10 16  0  0  0 20 10 10\n",
      "  5  0  0 20  0]\n",
      " chosen actions  [ 8 17  7 14 13 15  5 15 24  1  5  1 13 11 15 11  6 11  8  8  8 20 22 22 23\n",
      " 20 16 18  5  1]\n",
      "mean abs err: 8.65136\n",
      "mean phys Q: 8.90858\n",
      "mean agent Q: 12.8035\n",
      "------------------------\n",
      "Saved Model, step is 190000\n",
      "Average loss is  0.1917548666\n",
      "Saving PER and importance weights\n",
      "step: 190000\n",
      "physactions  [ 0  0 15 15  0 15  0  0  5  0 10 15  0  0  5 10  0  0 10  5 15  0  0  0  0\n",
      "  0  0  0 20 15]\n",
      " chosen actions  [21 16 11 16  7  9  6 18  0 17  8 21 10  8 23 19 16  8 14 16 20  5 21 20 13\n",
      "  1  1 18  7  1]\n",
      "mean abs err: 9.08445\n",
      "mean phys Q: 10.8581\n",
      "mean agent Q: 14.352\n",
      "------------------------\n",
      "Saved Model, step is 191000\n",
      "Average loss is  0.23877745533\n",
      "Saving PER and importance weights\n",
      "step: 191000\n",
      "physactions  [15 20 15  0  0 10  0  5  0  5 10  0 10  0  5  5 20  5  5 20  0  0  0  0 14\n",
      "  5  0  5 16  0]\n",
      " chosen actions  [14  7  8 13 19 19 15 15 18  1 11  6 18  6 19 19  9 20  8 11  1 12  0 15  6\n",
      " 18 15 18 14 21]\n",
      "mean abs err: 9.0265\n",
      "mean phys Q: 10.1254\n",
      "mean agent Q: 13.4462\n",
      "------------------------\n",
      "Saved Model, step is 192000\n",
      "Average loss is  0.177379683495\n",
      "Saving PER and importance weights\n",
      "step: 192000\n",
      "physactions  [15 15  0  0  0 20  0 10 15 20 10  5  6  0  0  0  5 15  5 15  0  0 10 20  0\n",
      " 15  0  5  0 24]\n",
      " chosen actions  [ 0  0 15 21 18  0 18  1  7  6  0  1  7  0 15 15  7 17 22 16 23 14 16  1 18\n",
      "  0  5 21  6  7]\n",
      "mean abs err: 9.14354\n",
      "mean phys Q: 10.243\n",
      "mean agent Q: 14.0251\n",
      "------------------------\n",
      "Saved Model, step is 193000\n",
      "Average loss is  0.174754940033\n",
      "Saving PER and importance weights\n",
      "step: 193000\n",
      "physactions  [13 15  0  0  0 10  0  0  0 20 10  0  0  5  5  0  5  0  0 10  0  5 18  0  0\n",
      "  0  0  0 20  4]\n",
      " chosen actions  [ 0 20  0  1  6  5 21 16 15 18  0 17  1 23 13 23  1 10  6  7 23  1  0 13  1\n",
      " 12 21 21  9 20]\n",
      "mean abs err: 9.38029\n",
      "mean phys Q: 9.34422\n",
      "mean agent Q: 12.7835\n",
      "------------------------\n",
      "Saved Model, step is 194000\n",
      "Average loss is  0.234148304939\n",
      "Saving PER and importance weights\n",
      "step: 194000\n",
      "physactions  [ 0  0  0 23 10  5  0  0  0 23  0  0  0  5  0  5 23  0 19 23  0  5 19 20 12\n",
      " 16  0  5 13  0]\n",
      " chosen actions  [ 1 21  1  0  8 21 11  1 15 17  6  2 15 19  7 15 15  1 20 11  1 17 15 14 21\n",
      "  1 14 16 15 21]\n",
      "mean abs err: 8.74596\n",
      "mean phys Q: 10.3458\n",
      "mean agent Q: 14.1215\n",
      "------------------------\n",
      "Saved Model, step is 195000\n",
      "Average loss is  0.134730638981\n",
      "Saving PER and importance weights\n",
      "step: 195000\n",
      "physactions  [ 0 15 10 20  0 17  0  0  0  5  0 13  0  0  0  0  0 10  0  0  0  0 10  0  0\n",
      "  0 15 15  0 16]\n",
      " chosen actions  [13  9 15  1  9 15 21  1 17  6 16 16 15  7  2 23  0 11 15 18 21 17  0 17  6\n",
      " 15 15 17 10 19]\n",
      "mean abs err: 9.33352\n",
      "mean phys Q: 9.06659\n",
      "mean agent Q: 12.9162\n",
      "------------------------\n",
      "Saved Model, step is 196000\n",
      "Average loss is  0.214476751804\n",
      "Saving PER and importance weights\n",
      "step: 196000\n",
      "physactions  [ 0  0  0 10 15 15  0  0  0 19  0  0 15  0 10 20  5  5  0 10  0  8  5 23  5\n",
      "  5  0  0  0  0]\n",
      " chosen actions  [15  0 23 19 17 16 24 21 21 15 14 15 11 15  8 11  6 21 17  0 15 17 15 20  6\n",
      "  0  1 20  7 20]\n",
      "mean abs err: 8.1993\n",
      "mean phys Q: 9.67234\n",
      "mean agent Q: 13.3634\n",
      "------------------------\n",
      "Saved Model, step is 197000\n",
      "Average loss is  0.149337532043\n",
      "Saving PER and importance weights\n",
      "step: 197000\n",
      "physactions  [ 0  0  0 20  0 15  0  0  0 10  0  5  0  0  0  0  5  0  5 10 10  0  0 10  0\n",
      "  5  0  0 15  0]\n",
      " chosen actions  [23 16 17 18  6 22 23  8  8 20 17 15  8 16 23 15  9 11 15 11  0 23 15 11 10\n",
      " 13 10 13  8 13]\n",
      "mean abs err: 7.82294\n",
      "mean phys Q: 11.1038\n",
      "mean agent Q: 14.8554\n",
      "------------------------\n",
      "Saved Model, step is 198000\n",
      "Average loss is  0.164002700806\n",
      "Saving PER and importance weights\n",
      "step: 198000\n",
      "physactions  [ 0 15  0  0 10  0 10  5 10  5  5  0  0  0  0 15  5  0  0 20 17 10  0 21 10\n",
      "  5  5 20  5 10]\n",
      " chosen actions  [13 15 13 13 15  0 15 22  0 18 12 20  9 15 23 11 19  8 19 18  0 20  0  6 19\n",
      " 24 11  7  0  9]\n",
      "mean abs err: 8.22149\n",
      "mean phys Q: 11.0987\n",
      "mean agent Q: 14.8549\n",
      "------------------------\n",
      "Saved Model, step is 199000\n",
      "Average loss is  0.197458240032\n",
      "Saving PER and importance weights\n",
      "step: 199000\n",
      "physactions  [ 0 15 18 13 20  0 10  0  0  0  0  5  0  0 20 10  0 21  0  0  0  0 12 20  0\n",
      " 10 20  0 10  4]\n",
      " chosen actions  [23 23 18 15 11 20 16 13  8 18 12  8 15 15 15 11  7  8 14  7 20 20 13 11 19\n",
      "  5 12 18  1 16]\n",
      "mean abs err: 8.65708\n",
      "mean phys Q: 10.1147\n",
      "mean agent Q: 13.4273\n",
      "------------------------\n",
      "Saved Model, step is 200000\n",
      "Average loss is  0.157521491051\n",
      "Saving PER and importance weights\n",
      "step: 200000\n",
      "physactions  [ 0 19 15  8  0 10  0  0  0 21  5 10  0  0  0 15  0  0 20  6 20 15  0  0 16\n",
      "  0  0  5  0 13]\n",
      " chosen actions  [20 24  5  0  5  0 20 13 20 11 19  6 20 13 16 11  5 18 24 17 13 11  0 15  0\n",
      "  7 16 16 20 22]\n",
      "mean abs err: 9.91439\n",
      "mean phys Q: 9.39259\n",
      "mean agent Q: 13.1763\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Model, step is 201000\n",
      "Average loss is  0.166215187073\n",
      "Saving PER and importance weights\n",
      "step: 201000\n",
      "physactions  [ 0 16  5  0  0  0  0 19 10 20  0  5 15  0 15  0  5 23  8  5  0  5 10 19 15\n",
      "  0  0 13  0  0]\n",
      " chosen actions  [18  8 13  6  5  6  0  5  8 18 16 13 16  0 12 24  8 24  0  4  3 13 20 15  0\n",
      "  6  0  6  8  9]\n",
      "mean abs err: 10.5024\n",
      "mean phys Q: 10.8134\n",
      "mean agent Q: 14.0758\n",
      "------------------------\n",
      "Saved Model, step is 202000\n",
      "Average loss is  0.249111051559\n",
      "Saving PER and importance weights\n",
      "step: 202000\n",
      "physactions  [13  0  0  0  5 10 24  5 10  0  0  0  0  0  0  5  0 15  0 10  1  0  0 10  0\n",
      " 15 22  5  5  5]\n",
      " chosen actions  [14 14 21  6  6  4  1  6 20  6 18 18 11 16 24  0 10  0 16  1 17 13 13 12  0\n",
      "  0  1 20 16 10]\n",
      "mean abs err: 9.08031\n",
      "mean phys Q: 8.9261\n",
      "mean agent Q: 12.6418\n",
      "------------------------\n",
      "Saved Model, step is 203000\n",
      "Average loss is  0.176986809731\n",
      "Saving PER and importance weights\n",
      "step: 203000\n",
      "physactions  [ 5  0 15  0 20 18  0 15  0 23  0  0  0  5 10  0  0 20  0 10  0  0  0  0  0\n",
      " 20  5 15  0 10]\n",
      " chosen actions  [ 6  0 11  6 16 15  6 18 15  8 21  1 15 17  8 16 17  0 16 18  0  8 20 14  0\n",
      " 23  6 12 15 14]\n",
      "mean abs err: 8.61986\n",
      "mean phys Q: 10.2099\n",
      "mean agent Q: 13.8689\n",
      "------------------------\n",
      "Saved Model, step is 204000\n",
      "Average loss is  0.179079162598\n",
      "Saving PER and importance weights\n",
      "step: 204000\n",
      "physactions  [ 0  5  0 20  0  0 18  0  4  0  5 20  0 10 10  0 24  0 15 15  0 10 15 10 21\n",
      " 20  5  0  0 10]\n",
      " chosen actions  [ 7 16  1 16 10 13  0  1  9 21  0 20  9 11 15 13  8 13 17  9  6  7  6 21 24\n",
      " 11 22 21 21 18]\n",
      "mean abs err: 8.63134\n",
      "mean phys Q: 9.19985\n",
      "mean agent Q: 12.8122\n",
      "------------------------\n",
      "Saved Model, step is 205000\n",
      "Average loss is  0.183227911949\n",
      "Saving PER and importance weights\n",
      "step: 205000\n",
      "physactions  [ 0 16  0  5  5 19  0  0  0  0  0  0  0  0  5  1 10  0 20  0  5 20  0 20  0\n",
      " 20  0 10  0  5]\n",
      " chosen actions  [ 1 16 15  7  9  8  0 18 21  7 16 16 20  8  0 20  5 13 11 20  6  6 21  7 16\n",
      "  9  9 13 18 21]\n",
      "mean abs err: 9.59702\n",
      "mean phys Q: 9.00037\n",
      "mean agent Q: 12.9681\n",
      "------------------------\n",
      "Saved Model, step is 206000\n",
      "Average loss is  0.250565889359\n",
      "Saving PER and importance weights\n",
      "step: 206000\n",
      "physactions  [ 1 10 23  0  5 15  0  5 10 10  5  0 24  0  0 10 20  0  5 10  0  0  0  5  0\n",
      "  5  0 15 10  0]\n",
      " chosen actions  [18 15 15 15 11 17  0 23 23 15 11  0  8  6  0 13  6 15 24 11  6  0 21 23  3\n",
      " 10  1 11 16 17]\n",
      "mean abs err: 9.13431\n",
      "mean phys Q: 9.13246\n",
      "mean agent Q: 12.5651\n",
      "------------------------\n",
      "Saved Model, step is 207000\n",
      "Average loss is  0.184504283905\n",
      "Saving PER and importance weights\n",
      "step: 207000\n",
      "physactions  [ 5 10  0  0  0 10  5  0  5 15  0 10 20  0  0  5  5  0 10  0  0 12  0 24 24\n",
      "  5 15  0  5  0]\n",
      " chosen actions  [ 0 14 13 20  1 24  6 20  6  6 23  7 18 23  6  0 11  3  4  6 10 15  1  3 24\n",
      " 10  0 15  2  1]\n",
      "mean abs err: 8.65949\n",
      "mean phys Q: 10.321\n",
      "mean agent Q: 13.6857\n",
      "------------------------\n",
      "Saved Model, step is 208000\n",
      "Average loss is  0.143964118481\n",
      "Saving PER and importance weights\n",
      "step: 208000\n",
      "physactions  [16  5  0  0  5 10 10  6  5  5  0 16  0 15  1 15 10  5  0 10  0  0 10 20 10\n",
      "  0 10  0  5  0]\n",
      " chosen actions  [10  0 10 20 10 17  0  6  0  1 22 10  1 11 17 18 14 23  1  0 15  0 19  9 14\n",
      " 16 21 13 18  0]\n",
      "mean abs err: 8.94657\n",
      "mean phys Q: 10.3291\n",
      "mean agent Q: 13.919\n",
      "------------------------\n",
      "Saved Model, step is 209000\n",
      "Average loss is  0.2406240201\n",
      "Saving PER and importance weights\n",
      "step: 209000\n",
      "physactions  [ 0 10  0 10  0  0  5  0  5  5  0  0 20 15  4  0  0  0 14 10  0 20 10  0  0\n",
      " 10 15 15 20  5]\n",
      " chosen actions  [15 11 18 11 16 15 15 13 15 11 18  5  7  6  8  5  1  1 14 15 22  0 20 15  1\n",
      " 12 17 13  6 21]\n",
      "mean abs err: 7.82473\n",
      "mean phys Q: 8.91082\n",
      "mean agent Q: 12.7875\n",
      "------------------------\n",
      "Saved Model, step is 210000\n",
      "Average loss is  0.22410904026\n",
      "Saving PER and importance weights\n",
      "step: 210000\n",
      "physactions  [21  5  0 15  0  5  6 15  0 15 18  5 10  5  5 20  5  0 15  5 17 10  0  5 10\n",
      "  5  0  0 10 10]\n",
      " chosen actions  [16 20  9 20 13 11  0  0  1 17  3  0  6 15 16  7 18 21 17  0 16  6 16 18  1\n",
      " 20 16 21 18  5]\n",
      "mean abs err: 9.1091\n",
      "mean phys Q: 6.85514\n",
      "mean agent Q: 11.0158\n",
      "------------------------\n",
      "Saved Model, step is 211000\n",
      "Average loss is  0.254425678253\n",
      "Saving PER and importance weights\n",
      "step: 211000\n",
      "physactions  [ 5 10  0 10 20  0 10  0  0 20  0  0 20  0  0 15 15  0  5  5  5 15 21 20 10\n",
      " 10 15 21 15 13]\n",
      " chosen actions  [ 7 18  3  3  7 15 20 18 13 14 15 16 21 24 18  0  0  6 11 21  0  7 15 12  9\n",
      "  7 18 17  9  6]\n",
      "mean abs err: 8.47286\n",
      "mean phys Q: 8.94027\n",
      "mean agent Q: 12.5971\n",
      "------------------------\n",
      "Saved Model, step is 212000\n",
      "Average loss is  0.268729102612\n",
      "Saving PER and importance weights\n",
      "step: 212000\n",
      "physactions  [ 9  5  0 11 10  5 15  5  4 21  0 20 10  0 15  5  0  0 15 15 15  0 20  0  5\n",
      "  5 15  0  5  6]\n",
      " chosen actions  [15 15 17 18 15 20 21  1 16 15  0 11 11  0  9  6 13 18 10  0 17 22  8  1  0\n",
      "  8 14  0  6 21]\n",
      "mean abs err: 9.22692\n",
      "mean phys Q: 9.06145\n",
      "mean agent Q: 12.3112\n",
      "------------------------\n",
      "Saved Model, step is 213000\n",
      "Average loss is  0.188196603298\n",
      "Saving PER and importance weights\n",
      "step: 213000\n",
      "physactions  [20  0  0  0 10  5  0  0  0  0  0  0  0  0 10  5 15  5 21  5 20 10 11  0  9\n",
      "  5  0 20  0  0]\n",
      " chosen actions  [19  8  3 12 15  0 13 10 23  0  2  7 12  7  6  5  8  4  8 18 17  5 15  6  8\n",
      " 17  0  6 13 20]\n",
      "mean abs err: 9.38825\n",
      "mean phys Q: 8.85042\n",
      "mean agent Q: 11.8717\n",
      "------------------------\n",
      "Saved Model, step is 214000\n",
      "Average loss is  0.186902621746\n",
      "Saving PER and importance weights\n",
      "step: 214000\n",
      "physactions  [ 0 10 20  5  0  0  5  5 10  0  0  0  0 15  0  5 14  0 20  0 19 20 15  5  0\n",
      " 20  0  0 15  3]\n",
      " chosen actions  [ 6 15 11  6  1  3 15 20  8  3 19 16 10  6  1 17 15 15 15  6 22  8  0 10  7\n",
      " 23 16  0 13  4]\n",
      "mean abs err: 9.11309\n",
      "mean phys Q: 8.63386\n",
      "mean agent Q: 12.2285\n",
      "------------------------\n",
      "Saved Model, step is 215000\n",
      "Average loss is  0.244385825157\n",
      "Saving PER and importance weights\n",
      "step: 215000\n",
      "physactions  [18 10  0 15 15  0  0  3 20  0  0  0  0  5 15 11 10 24  0  0  5 15  5  0 10\n",
      " 24  0 10 15 15]\n",
      " chosen actions  [21  0 21  0 12  1 18  1  0 18  9 17 12 17  7  7  2 16 13  0 13 15 13  0  6\n",
      "  0  8  0 16 12]\n",
      "mean abs err: 8.39635\n",
      "mean phys Q: 8.3685\n",
      "mean agent Q: 11.9286\n",
      "------------------------\n",
      "Saved Model, step is 216000\n",
      "Average loss is  0.119374528408\n",
      "Saving PER and importance weights\n",
      "step: 216000\n",
      "physactions  [14 13  0  5  0  0  6  0  0  0  8  5  5  5 15 10  0  0 11  0 15 22 15 10  0\n",
      "  0  0  0  0 15]\n",
      " chosen actions  [ 0 17  0  0 21  6 15  7 20 14 17  0 17  3  1 13 21  1  8  6 20  0 17  0 13\n",
      " 13 20 18 13  0]\n",
      "mean abs err: 7.98583\n",
      "mean phys Q: 10.9949\n",
      "mean agent Q: 14.1979\n",
      "------------------------\n",
      "Saved Model, step is 217000\n",
      "Average loss is  0.211435256958\n",
      "Saving PER and importance weights\n",
      "step: 217000\n",
      "physactions  [ 0 20 20  0  0 15  0  0 10  0  0  0  0  0  0  5  0  0 15 15  0 10 10 15  4\n",
      "  5 15  6 20  0]\n",
      " chosen actions  [13  5 18 15 20 17 21 13  0 18  6 13 20  0 16  0 15 13 17  0  1  6 11  0 16\n",
      " 23  6 11  0  0]\n",
      "mean abs err: 9.09746\n",
      "mean phys Q: 8.96479\n",
      "mean agent Q: 12.1544\n",
      "------------------------\n",
      "Saved Model, step is 218000\n",
      "Average loss is  0.135293441772\n",
      "Saving PER and importance weights\n",
      "step: 218000\n",
      "physactions  [15  0  5  0  0  0  5  8  5 15  0 10  5  0 13 24  0  0 12 15  5  0  0 10  0\n",
      "  5  0  0 10  8]\n",
      " chosen actions  [22 10  7 13 11 21 11 17  8 11 18 21  5  1  5 15 13 20 18 15 10 21 11 17 24\n",
      "  3 20 13 24 16]\n",
      "mean abs err: 9.15258\n",
      "mean phys Q: 9.70444\n",
      "mean agent Q: 13.5704\n",
      "------------------------\n",
      "Saved Model, step is 219000\n",
      "Average loss is  0.165503130913\n",
      "Saving PER and importance weights\n",
      "step: 219000\n",
      "physactions  [ 0  5  0  4  9  0 10  0  5  0  0 20  0  5 10 24 15  5  0  0  0  5  0  0  5\n",
      "  0  0 14 15  5]\n",
      " chosen actions  [18  0 16 17  1 20 24  6 10  6 20  7 20  6 21  0 17 11  3  6 11 15 13  8  9\n",
      " 20  0 14  5 13]\n",
      "mean abs err: 8.28218\n",
      "mean phys Q: 10.3225\n",
      "mean agent Q: 13.556\n",
      "------------------------\n",
      "Saved Model, step is 220000\n",
      "Average loss is  0.20300788784\n",
      "Saving PER and importance weights\n",
      "step: 220000\n",
      "physactions  [ 0 15  5  0 24 20 23  4 10  0  0  0  5 15 20  5 10  5 10  5 15  0  0  5  0\n",
      "  0 10  3  5  5]\n",
      " chosen actions  [21 18 19 21  0 11  0 17  0  7 10  6 11  0 14 19 19 21 13 13  0 11 21 18 20\n",
      " 21  5 15 11 16]\n",
      "mean abs err: 8.20206\n",
      "mean phys Q: 10.7669\n",
      "mean agent Q: 14.4982\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Model, step is 221000\n",
      "Average loss is  0.265733604908\n",
      "Saving PER and importance weights\n",
      "step: 221000\n",
      "physactions  [ 5 15  0  0  0 15  0 10 15  0  0  5 10 20 10  5  0  5  0  5 11 10  0  0  5\n",
      "  5 10 10 10 12]\n",
      " chosen actions  [18  8  1 10 20 14 14 11 20  6 23 11 20 20 17  6 16 11 15 15  0 16 20 20 16\n",
      " 10  6  0  7 17]\n",
      "mean abs err: 8.39642\n",
      "mean phys Q: 9.97882\n",
      "mean agent Q: 13.6728\n",
      "------------------------\n",
      "Saved Model, step is 222000\n",
      "Average loss is  0.254849157333\n",
      "Saving PER and importance weights\n",
      "step: 222000\n",
      "physactions  [20 22  0 19  0 10 19 15 20 24 17  0 10  0 20  0 24 20  0 10  0  0  5  5  0\n",
      "  5 12  0  0 10]\n",
      " chosen actions  [ 7  0 24 17 14  7 11  1 21  4 12 10 20  6 16 23  7  6 23 11 20 20  6 17  1\n",
      "  0 17 13 20 13]\n",
      "mean abs err: 7.50247\n",
      "mean phys Q: 10.7536\n",
      "mean agent Q: 13.8909\n",
      "------------------------\n",
      "Saved Model, step is 223000\n",
      "Average loss is  0.178478263855\n",
      "Saving PER and importance weights\n",
      "step: 223000\n",
      "physactions  [ 5 24  0 15  0  0 10 20 10  0  0 10 15  0  5  0 20  0 10  0 10  0  0  5 10\n",
      "  0  0 23  0  0]\n",
      " chosen actions  [ 8  1 21  7 15 14 18  6  8  0  7 17 16 20  5 20 22  4 22 21  0 14  5  1 15\n",
      " 14 24  1  6 20]\n",
      "mean abs err: 8.86509\n",
      "mean phys Q: 8.70337\n",
      "mean agent Q: 12.9014\n",
      "------------------------\n",
      "Saved Model, step is 224000\n",
      "Average loss is  0.150230588913\n",
      "Saving PER and importance weights\n",
      "step: 224000\n",
      "physactions  [ 6  0 15  0 10  0  0  0 20  5 10 20  0  5  0  0  0  0  0  0 15  5  0 10  0\n",
      "  0  0  5 15  0]\n",
      " chosen actions  [ 4 20  7  1 13  5  5 22 23 16 15  6 14 23 18 21 17 15  7 17 11 18 21 11  6\n",
      " 21  1 13 13  5]\n",
      "mean abs err: 10.1372\n",
      "mean phys Q: 8.1378\n",
      "mean agent Q: 11.931\n",
      "------------------------\n",
      "Saved Model, step is 225000\n",
      "Average loss is  0.217298035622\n",
      "Saving PER and importance weights\n",
      "step: 225000\n",
      "physactions  [ 5  5 10  6  5  0  0  0  0  0 10 10  0 13 19 11  0  5  5  5  0  5  0  0  7\n",
      " 24  5  0  5  5]\n",
      " chosen actions  [19 17 13 10  0 21 13 24 24  7  0 21 11  8 15 24 18  3 15 20 11 22  0  0 18\n",
      " 15 13 20  3 13]\n",
      "mean abs err: 10.2085\n",
      "mean phys Q: 9.40811\n",
      "mean agent Q: 13.1638\n",
      "------------------------\n",
      "Saved Model, step is 226000\n",
      "Average loss is  0.118588660717\n",
      "Saving PER and importance weights\n",
      "step: 226000\n",
      "physactions  [ 5 23  0  0  0 10  0  0  0 20  5  0  0  0  0  0 16  0 24  5  0  0  5 15  5\n",
      "  5 12  5  0 15]\n",
      " chosen actions  [17 23 11 11 11 22  0 20  6  3 18 21  1 20  7  6 24 20 15 13 15  1  0 15  7\n",
      " 13  6  7 20  6]\n",
      "mean abs err: 7.34914\n",
      "mean phys Q: 9.721\n",
      "mean agent Q: 13.3376\n",
      "------------------------\n",
      "Saved Model, step is 227000\n",
      "Average loss is  0.178970666885\n",
      "Saving PER and importance weights\n",
      "step: 227000\n",
      "physactions  [15 15  0 15  0  0  0  5  0 15 16  5  0 16  0 15 10  0  0 15  5  5 15 10  0\n",
      "  0 15  0 15 10]\n",
      " chosen actions  [15 15 15 13  7 24 15 18  6 15 11  0 20  0 20  0 14 15 18 23 22  1  8  7  7\n",
      " 23 17 17 24 12]\n",
      "mean abs err: 7.85366\n",
      "mean phys Q: 10.4138\n",
      "mean agent Q: 13.6031\n",
      "------------------------\n",
      "Saved Model, step is 228000\n",
      "Average loss is  0.159289613247\n",
      "Saving PER and importance weights\n",
      "step: 228000\n",
      "physactions  [10  0  0 20  0  4  5  0  0  0  0 15  5  0 10 10  0 10 15 15  5  0  0  0  0\n",
      " 10  5 18  0  0]\n",
      " chosen actions  [22 15 15 20  5 17 13  0  0 20  6  4 17  7 12 20  0 13 10 17 16 15  1 23 23\n",
      " 17  0  6  6  7]\n",
      "mean abs err: 8.73893\n",
      "mean phys Q: 9.06375\n",
      "mean agent Q: 12.6945\n",
      "------------------------\n",
      "Saved Model, step is 229000\n",
      "Average loss is  0.211115127087\n",
      "Saving PER and importance weights\n",
      "step: 229000\n",
      "physactions  [ 0  5 20  5  0  5 17  0  0  0  5 18  0 10 20 24 10 10  0 10  0 10  0  0  0\n",
      " 20  0  5  0 10]\n",
      " chosen actions  [15 10 14  6  0  1 18  7  7  7  5  4 15 17  0 20  0 14  2 22 15 22 23 20 11\n",
      "  8 13 15 15 16]\n",
      "mean abs err: 8.1687\n",
      "mean phys Q: 9.45862\n",
      "mean agent Q: 12.9254\n",
      "------------------------\n",
      "Saved Model, step is 230000\n",
      "Average loss is  0.176614149094\n",
      "Saving PER and importance weights\n",
      "step: 230000\n",
      "physactions  [ 7 10 20 15  0  0  0 10  0  0  0  0  5 10  5  9 13  0  5  0  5 20  0  0  0\n",
      "  0 20  9  0 10]\n",
      " chosen actions  [ 8  6 21 11 13 13  3 15  0  7  7 15  8  7 16  1 21 20 15 16 12  7 13  6 13\n",
      "  5 15 17 16  7]\n",
      "mean abs err: 8.7625\n",
      "mean phys Q: 9.68404\n",
      "mean agent Q: 13.3786\n",
      "------------------------\n",
      "Saved Model, step is 231000\n",
      "Average loss is  0.17172820282\n",
      "Saving PER and importance weights\n",
      "step: 231000\n",
      "physactions  [ 0  5 20  0 15  0  0  0  5  0  5 15  0  5  0  5 10  5  0  0 10  0 15  0 24\n",
      "  0  0 16 10 15]\n",
      " chosen actions  [11  8  0 20  8  1 20  0  0  6  7 15 16 11 15 15 13  6 16  7  6 20 18 15 17\n",
      " 10  0  0  7  8]\n",
      "mean abs err: 8.72969\n",
      "mean phys Q: 9.22481\n",
      "mean agent Q: 12.6758\n",
      "------------------------\n",
      "Saved Model, step is 232000\n",
      "Average loss is  0.155942726135\n",
      "Saving PER and importance weights\n",
      "step: 232000\n",
      "physactions  [20  5  0  0  3  6  5  0 20  0  0 15  0 15 21 15  5  0 20  0 10 24  0 14  0\n",
      " 15  0 15  5 20]\n",
      " chosen actions  [ 0 11 23  6  6  6  6 14  6 12 14 18  8 15  7 17  2 10  1 13  0 24  6  7 11\n",
      " 24 15  0 14 13]\n",
      "mean abs err: 10.4074\n",
      "mean phys Q: 9.85161\n",
      "mean agent Q: 13.4037\n",
      "------------------------\n",
      "Saved Model, step is 233000\n",
      "Average loss is  0.227631537199\n",
      "Saving PER and importance weights\n",
      "step: 233000\n",
      "physactions  [ 0 10  0  0 15  5  5 20  0  0 15 18 10 10 20  5 10 12  5  0 20  0 11  0  0\n",
      "  0  5  5  0  5]\n",
      " chosen actions  [11 10  6 24 15  8 13 13 16  1 12  7 13  7  8 14 24  0 18  1 18  7  6 20 23\n",
      " 11 23  8 22 17]\n",
      "mean abs err: 10.0695\n",
      "mean phys Q: 9.29385\n",
      "mean agent Q: 12.6476\n",
      "------------------------\n",
      "Saved Model, step is 234000\n",
      "Average loss is  0.26783067894\n",
      "Saving PER and importance weights\n",
      "step: 234000\n",
      "physactions  [ 5  5  0  5  0  0 20  5  0 20  0 20  0  5 18  0  0 15  0  0  0 20  0 15  5\n",
      " 15 20 10 15  0]\n",
      " chosen actions  [ 8 17  1  6 13 14 15  0  1 15 13  7 13  9 15 13 15  6  7 18  0 15  7 15 17\n",
      "  2  8 11 13  6]\n",
      "mean abs err: 9.9493\n",
      "mean phys Q: 9.10662\n",
      "mean agent Q: 12.7283\n",
      "------------------------\n",
      "Saved Model, step is 235000\n",
      "Average loss is  0.241066287041\n",
      "Saving PER and importance weights\n",
      "step: 235000\n",
      "physactions  [20 13  8  0  5  5  5  5  0  0  6  5 13  0 16  0  5  0  0 10 10 15  5  0 10\n",
      "  0 10 24  0 15]\n",
      " chosen actions  [ 7  5  5  5  6 11  7 17 15  1 23  8  0 16 12  7  6 13 23  7 20 23 17  5 15\n",
      "  7  0  0 15  0]\n",
      "mean abs err: 9.29131\n",
      "mean phys Q: 9.47471\n",
      "mean agent Q: 13.225\n",
      "------------------------\n",
      "Saved Model, step is 236000\n",
      "Average loss is  0.208091862679\n",
      "Saving PER and importance weights\n",
      "step: 236000\n",
      "physactions  [10 15  0 23 15  5 10  5  0  0  5  0 10 10  0  5  5 20  0  0  0  5 15 24 15\n",
      "  0 10  0  5  5]\n",
      " chosen actions  [17 17 13 14  1 13 24 12  5  9 16 21  2 16  7 15  0 21 11  2  5  8  5 18 15\n",
      "  6 12  6 18  8]\n",
      "mean abs err: 8.9387\n",
      "mean phys Q: 9.98319\n",
      "mean agent Q: 13.503\n",
      "------------------------\n",
      "Saved Model, step is 237000\n",
      "Average loss is  0.235748403549\n",
      "Saving PER and importance weights\n",
      "step: 237000\n",
      "physactions  [ 0 15  0  0  4 10  0 15 10  0 10  0  5  0 10 15 15  0  5 17 10 20  5 15 15\n",
      "  5  5  0  0 15]\n",
      " chosen actions  [ 9 16 23 15 17 15 21  1  9  1 11  7 18 12 14 14  7 12  8  7 13 17 21  5  2\n",
      "  8  6  6  3 18]\n",
      "mean abs err: 8.77533\n",
      "mean phys Q: 9.3332\n",
      "mean agent Q: 12.7364\n",
      "------------------------\n",
      "Saved Model, step is 238000\n",
      "Average loss is  0.232567775249\n",
      "Saving PER and importance weights\n",
      "step: 238000\n",
      "physactions  [16 24  8 18 14  5  3  0  0 15  0  5 13  0  0  0  0 22  0 22 15  0  0 10  0\n",
      "  8  5 10 20 20]\n",
      " chosen actions  [21  6 14 18 18  8  7  6  6 11 16 18  5 14 16 23 12  9 14 10 16 23 20 10 12\n",
      " 21 20  0 16 19]\n",
      "mean abs err: 8.89771\n",
      "mean phys Q: 8.46475\n",
      "mean agent Q: 11.8961\n",
      "------------------------\n",
      "Saved Model, step is 239000\n",
      "Average loss is  0.151293714285\n",
      "Saving PER and importance weights\n",
      "step: 239000\n",
      "physactions  [ 0  0  5  0  8  0  5  0 20  0 10  0 15 10  0  0  0  5 15 15  0 15  5  0  0\n",
      "  0  0  9  5 24]\n",
      " chosen actions  [15 10 11 24 22  7 15 24  8 14 21 18  8 17 20  5 20  7  7 19 20  8  8  1 20\n",
      "  6 20 23 15 13]\n",
      "mean abs err: 8.90206\n",
      "mean phys Q: 11.8628\n",
      "mean agent Q: 14.9604\n",
      "------------------------\n",
      "Saved Model, step is 240000\n",
      "Average loss is  0.194950973511\n",
      "Saving PER and importance weights\n",
      "step: 240000\n",
      "physactions  [ 0  0  0  4  0  0 11  5 22  0  0  0  5 10 20 10  0 15  0 10  5  5  0  0 20\n",
      " 20  0 10  5  0]\n",
      " chosen actions  [10 24 17 20 18 24  6 19  0 21  6 21  6  7 19  5 21  8 20 15  6 13 21 11  0\n",
      " 14 21  0  3 16]\n",
      "mean abs err: 7.76532\n",
      "mean phys Q: 10.8886\n",
      "mean agent Q: 14.3023\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Model, step is 241000\n",
      "Average loss is  0.20212849474\n",
      "Saving PER and importance weights\n",
      "step: 241000\n",
      "physactions  [ 0 10 10 20 20  9 10  0  4  1 15  0  1 10  0  0  0  5 15  0 22  0  5  0  0\n",
      "  5 23  0  0 15]\n",
      " chosen actions  [15  0  0  8  7 17  0 24 12  0 13  1 17 20 20  6 23 19  0  6 11  5  7 13 14\n",
      "  3  0 23  8 11]\n",
      "mean abs err: 8.95152\n",
      "mean phys Q: 10.2148\n",
      "mean agent Q: 13.4536\n",
      "------------------------\n",
      "Saved Model, step is 242000\n",
      "Average loss is  0.22422422123\n",
      "Saving PER and importance weights\n",
      "step: 242000\n",
      "physactions  [11  0  5 15 15 20  0 10  0 10 19  0 15 15 10 10 11 10 15  0  0  5  0 15  5\n",
      " 20  5  0  0  0]\n",
      " chosen actions  [15 21 13  7  0  6 21 17  6 13  0  1  0 18 17 11  6 18  6 21 11 13 13 15  1\n",
      " 14 17 18 21  0]\n",
      "mean abs err: 9.47129\n",
      "mean phys Q: 10.7849\n",
      "mean agent Q: 14.0437\n",
      "------------------------\n",
      "Saved Model, step is 243000\n",
      "Average loss is  0.229861734867\n",
      "Saving PER and importance weights\n",
      "step: 243000\n",
      "physactions  [ 5  0  0  5  0 11  0  5  5 10  0 15  0  5  5 20 10 10  0  0 20  0 10  5  0\n",
      " 13  0  0  5 10]\n",
      " chosen actions  [17  0 20 16  6  8 11 16  6 21 17 11  6  1  2 15  8  1 16  0 15  6  2 14 13\n",
      " 15 16  6 19 16]\n",
      "mean abs err: 9.38353\n",
      "mean phys Q: 10.2863\n",
      "mean agent Q: 13.6483\n",
      "------------------------\n",
      "Saved Model, step is 244000\n",
      "Average loss is  0.212505298138\n",
      "Saving PER and importance weights\n",
      "step: 244000\n",
      "physactions  [ 5 10 15 10 10 10  0  0  5  0  0 20  5  5  5 20  0  5 20  5  0  0  0 11 20\n",
      "  0  5  0 20  8]\n",
      " chosen actions  [ 2  5  0 18  1 21  5 17  0 12 23 15  5  6  8  1  0  9  6  9  3 13 16 15 16\n",
      " 11 15  6  0 12]\n",
      "mean abs err: 8.82858\n",
      "mean phys Q: 9.80032\n",
      "mean agent Q: 13.0032\n",
      "------------------------\n",
      "Saved Model, step is 245000\n",
      "Average loss is  0.203933182716\n",
      "Saving PER and importance weights\n",
      "step: 245000\n",
      "physactions  [ 0  0 15  0 10  0  0  0 10  5  0  0 10 20  5  5  0 15  0 24  0  0 10 10  0\n",
      "  5 10  0  0 15]\n",
      " chosen actions  [15 12 11 16 15 11  1 17 24  0 21 21  0 23 17 16 15 19 21 16 13 21 11 18 21\n",
      " 18  8 17  5 10]\n",
      "mean abs err: 7.68287\n",
      "mean phys Q: 9.64631\n",
      "mean agent Q: 13.4177\n",
      "------------------------\n",
      "Saved Model, step is 246000\n",
      "Average loss is  0.21102676487\n",
      "Saving PER and importance weights\n",
      "step: 246000\n",
      "physactions  [20  0  0  0 15  5  5  0  0 10 17  5  0  0 14  5 10 15 15  0 15 15  0  5  0\n",
      "  0  0  5  5 20]\n",
      " chosen actions  [ 6 13  8 21 22  0 15  6 21 17  0 13 11 23 15 21  8 11 11  1 16 18 18 24  0\n",
      " 21 17 18 18 21]\n",
      "mean abs err: 7.94214\n",
      "mean phys Q: 9.9587\n",
      "mean agent Q: 13.7004\n",
      "------------------------\n",
      "Saved Model, step is 247000\n",
      "Average loss is  0.251577075005\n",
      "Saving PER and importance weights\n",
      "step: 247000\n",
      "physactions  [10  0  0  0  5  0  0  7  0  0 20  0  0  5 14  5 20  0  0  0 15 20 15 21  0\n",
      " 19  0  5 10 10]\n",
      " chosen actions  [11 22  6 11 16  4  6  6 21 22 14  3 13  0 17 13  6 13 21 10 11  7  0  0 16\n",
      "  0 21 15 22  8]\n",
      "mean abs err: 7.78615\n",
      "mean phys Q: 9.92485\n",
      "mean agent Q: 13.5184\n",
      "------------------------\n",
      "Saved Model, step is 248000\n",
      "Average loss is  0.230909889698\n",
      "Saving PER and importance weights\n",
      "step: 248000\n",
      "physactions  [ 0 20  0  5 20 10 15 23  3 10  0  0 11  0  0 15  0  0 15 15  5 20 10  5  0\n",
      "  0  5  0  9  5]\n",
      " chosen actions  [ 8 13 20 20 21  7  6 15 24 11 16 11 17 18 10  7 20  7  1 17  0 18 22 20  5\n",
      "  8 13  7  8 12]\n",
      "mean abs err: 8.67641\n",
      "mean phys Q: 8.96021\n",
      "mean agent Q: 12.7699\n",
      "------------------------\n",
      "Saved Model, step is 249000\n",
      "Average loss is  0.21943767643\n",
      "Saving PER and importance weights\n",
      "step: 249000\n",
      "physactions  [ 0 17 16  0 10 15  0 10  5  0  0  0  0  0 13  0  0 20 15  0 12  0 20 20  0\n",
      "  5  0  0 10 10]\n",
      " chosen actions  [ 0  4  0 12 21 21 15  4  0  6 17  6 20 13 20 15 15 24 17 24  6  0 13  8  6\n",
      " 22 16 17 13 17]\n",
      "mean abs err: 9.06002\n",
      "mean phys Q: 10.4593\n",
      "mean agent Q: 14.3089\n",
      "------------------------\n",
      "Saved Model, step is 250000\n",
      "Average loss is  0.16207676506\n",
      "Saving PER and importance weights\n",
      "step: 250000\n",
      "physactions  [ 0  0  5  0  0  5 20  0  0 20 20  6  0  0  5  0  0  5  0  5  0  5  5  0 22\n",
      " 24  0  0  5  0]\n",
      " chosen actions  [20  6 18 23 23  1  8 20 21 11 15 17 20  7 13 15 11 21 13 23 16 21 14 15 17\n",
      " 24 15  6 15 10]\n",
      "mean abs err: 8.86874\n",
      "mean phys Q: 9.80971\n",
      "mean agent Q: 13.6151\n",
      "------------------------\n",
      "Saved Model, step is 251000\n",
      "Average loss is  0.222681900024\n",
      "Saving PER and importance weights\n",
      "step: 251000\n",
      "physactions  [10  0  5 10 20 24 10 10  5 17  0  0  0  5  0 20  0 10  0  0  0 10  5  0  5\n",
      " 22 15  0  0 10]\n",
      " chosen actions  [ 0 11 16  8 18 10 21  0 15  6 13 18 14 13  9  0 11  8 13  0 19 17 12  7  7\n",
      " 11 17 13 15 13]\n",
      "mean abs err: 8.25366\n",
      "mean phys Q: 10.6546\n",
      "mean agent Q: 14.3075\n",
      "------------------------\n",
      "Saved Model, step is 252000\n",
      "Average loss is  0.217908328533\n",
      "Saving PER and importance weights\n",
      "step: 252000\n",
      "physactions  [ 6  0  0  5  0 10  0 10  0  0 20  5  0  0 15  0  5  0  5  0  1  0  0 20 20\n",
      " 10 12  0  0  5]\n",
      " chosen actions  [17 20 10  0 16 11 21 12  6 21 15  7  7 16  9 12 21 23 10  0 24 17 18  9 14\n",
      "  7 24 13 12 18]\n",
      "mean abs err: 9.39651\n",
      "mean phys Q: 10.0137\n",
      "mean agent Q: 14.9553\n",
      "------------------------\n",
      "Saved Model, step is 253000\n",
      "Average loss is  0.277068303585\n",
      "Saving PER and importance weights\n",
      "step: 253000\n",
      "physactions  [ 0 20 11 20  0 20 14 14 21 24 10 20  5 10  0  5 20 15  0  0  0  5  0 20 10\n",
      "  0 10  0 15 15]\n",
      " chosen actions  [18 16 17 16 16 17  0  0  5 15 17 19 17 18 20 16 11 24  3  0 13 12 15 11  6\n",
      " 16  0 15  0 18]\n",
      "mean abs err: 8.96897\n",
      "mean phys Q: 9.41379\n",
      "mean agent Q: 13.1225\n",
      "------------------------\n",
      "Saved Model, step is 254000\n",
      "Average loss is  0.175982738495\n",
      "Saving PER and importance weights\n",
      "step: 254000\n",
      "physactions  [10 15  9  0  5 15  0  0  0 15  0  0  0 10 16 20 10  0 10 20  0 20  5  0  0\n",
      "  0  0  0 20  0]\n",
      " chosen actions  [17 13 14 21 13 11 16 16 16 22 15 17 24  7 10 12 17  0 21 22 13  6  7 13 17\n",
      " 15 12 20  6 12]\n",
      "mean abs err: 8.73128\n",
      "mean phys Q: 9.30946\n",
      "mean agent Q: 13.355\n",
      "------------------------\n",
      "Saved Model, step is 255000\n",
      "Average loss is  0.227658697128\n",
      "Saving PER and importance weights\n",
      "step: 255000\n",
      "physactions  [10  5 10 15  5 10 15  0 18  5  0 10  5 15  0  0  5  5  0 22  0 20 12  0  5\n",
      "  5  0  5  0 24]\n",
      " chosen actions  [11 11 20 20 11 21  7 15 13 24 21  6 23 12 13 21 15  6  0 18 12  4 11 14 17\n",
      "  6 18  0 20 15]\n",
      "mean abs err: 9.10788\n",
      "mean phys Q: 7.93954\n",
      "mean agent Q: 12.1952\n",
      "------------------------\n",
      "Saved Model, step is 256000\n",
      "Average loss is  0.117946650505\n",
      "Saving PER and importance weights\n",
      "step: 256000\n",
      "physactions  [10  0  5  0 15  0 20 24  0  5  0  5  0  8  0  0  5  0  0 10  0 23  0  0 10\n",
      "  0  0  0  0 15]\n",
      " chosen actions  [ 8  0  8  0 13 12  8 20 13  8 16 21  2  0 21  1  6  6 13  6 20  8 19  6 12\n",
      " 10  0  0 20 17]\n",
      "mean abs err: 8.39744\n",
      "mean phys Q: 9.63127\n",
      "mean agent Q: 13.3181\n",
      "------------------------\n",
      "Saved Model, step is 257000\n",
      "Average loss is  0.198375719666\n",
      "Saving PER and importance weights\n",
      "step: 257000\n",
      "physactions  [ 0  0 10  0  0 20 15  0 14  0 11  0 15  0 10  0 23  5 12  0 17 15  5 15  5\n",
      "  7 15  0 20  0]\n",
      " chosen actions  [21  9 20  8 24 20 13 13 16  4 17 12  6  7  6 15  8  8 17 16 18 23 20 24 22\n",
      " 13 13 18  6 15]\n",
      "mean abs err: 9.20963\n",
      "mean phys Q: 8.83115\n",
      "mean agent Q: 12.4365\n",
      "------------------------\n",
      "Saved Model, step is 258000\n",
      "Average loss is  0.163539607048\n",
      "Saving PER and importance weights\n",
      "step: 258000\n",
      "physactions  [ 0 15  0  5  0 10  5  5  0  0 10 19  0  0  0  0 12  0  0  0  0 15 15 15 15\n",
      "  0 16  0 11  0]\n",
      " chosen actions  [13 15 20 20  0  6 16 17 20 23  0 18  7 13  2  8 18 17 20 13 12  6 24 18  0\n",
      "  7 15 16  0 24]\n",
      "mean abs err: 8.88755\n",
      "mean phys Q: 9.58667\n",
      "mean agent Q: 13.0135\n",
      "------------------------\n",
      "Saved Model, step is 259000\n",
      "Average loss is  0.209776151657\n",
      "Saving PER and importance weights\n",
      "step: 259000\n",
      "physactions  [15  0  5  0  0 20  0  0  0  0  0  0 22  7  7 10  5 10 15 15  0  0  0 15 11\n",
      " 13 23 21  0  0]\n",
      " chosen actions  [19 21 22  1 18  6 16 16 21  8  0 18 23  4  4 13 14 11 22 15  6  6  5 21  7\n",
      " 21 13  8  0 19]\n",
      "mean abs err: 8.35665\n",
      "mean phys Q: 10.8165\n",
      "mean agent Q: 14.1856\n",
      "------------------------\n",
      "Saved Model, step is 260000\n",
      "Average loss is  0.259553638458\n",
      "Saving PER and importance weights\n",
      "step: 260000\n",
      "physactions  [ 0  6 15  5  0 10 15 20 10 10 10 10  0 20  0  5 15  0  0  0  5 22 11 20  0\n",
      "  5  0  0 20 10]\n",
      " chosen actions  [ 6  4 22  2 18 22 20  8 18 23  8 18 12  6 16 12  6 11  8  6 13  3  8 17  7\n",
      "  0  3  1 23 11]\n",
      "mean abs err: 8.35097\n",
      "mean phys Q: 9.83915\n",
      "mean agent Q: 13.4284\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Model, step is 261000\n",
      "Average loss is  0.153152537346\n",
      "Saving PER and importance weights\n",
      "step: 261000\n",
      "physactions  [10 10  0 20  5  0  0  0  0  0  0  0  5 20  5  0 10  0 10  5  5 17  0  6  0\n",
      "  5  5 15 20  0]\n",
      " chosen actions  [17 24  0  8  0 17  8 15 21  1 14 13  0  1 12 13  0 16 11 20 17 24 13  8 19\n",
      "  1  6  7 20  8]\n",
      "mean abs err: 8.14992\n",
      "mean phys Q: 9.02497\n",
      "mean agent Q: 12.5607\n",
      "------------------------\n",
      "Saved Model, step is 262000\n",
      "Average loss is  0.255448509693\n",
      "Saving PER and importance weights\n",
      "step: 262000\n",
      "physactions  [ 5 20 10 20 20  5  0  5  0 24  0  5 15  0 15 24 15 22  0 10 15 10 10  0 10\n",
      "  0 15  0  5  5]\n",
      " chosen actions  [20  1 13 16  0  0 21  8  1  0  6 18  0 21  9  0  0 15 16 18  0 19 18 15 22\n",
      " 21  6 16  8  2]\n",
      "mean abs err: 9.48619\n",
      "mean phys Q: 10.4646\n",
      "mean agent Q: 13.8132\n",
      "------------------------\n",
      "Saved Model, step is 263000\n",
      "Average loss is  0.146025939941\n",
      "Saving PER and importance weights\n",
      "step: 263000\n",
      "physactions  [20  0  5 15 10  0 18  0  0 10  5 10  0 15  0  0  0  5 20 15  0  5  0  0  0\n",
      " 15  5 15 20  0]\n",
      " chosen actions  [15 10 19 12 17 15 15 14 10 12 12 23  0  9  6 10 15 11 22 21 17 15 17  7 15\n",
      " 17 20  7  6 20]\n",
      "mean abs err: 10.5974\n",
      "mean phys Q: 8.66687\n",
      "mean agent Q: 12.1984\n",
      "------------------------\n",
      "Saved Model, step is 264000\n",
      "Average loss is  0.232906580925\n",
      "Saving PER and importance weights\n",
      "step: 264000\n",
      "physactions  [ 0 10  0  5 10 17 10  9  0  0  5  0  0  5  5  0  0  0  0  5  5  5  0 10  4\n",
      " 20  0 10 19  5]\n",
      " chosen actions  [ 5 20 13 23  4  6  9 15 16  5 20 21 16  3 16  0 22 24  6 21  6  5  5  0 17\n",
      " 13 17 17  8  8]\n",
      "mean abs err: 9.85018\n",
      "mean phys Q: 9.77203\n",
      "mean agent Q: 13.2877\n",
      "------------------------\n",
      "Saved Model, step is 265000\n",
      "Average loss is  0.245268113136\n",
      "Saving PER and importance weights\n",
      "step: 265000\n",
      "physactions  [ 5  5  5 15  5  5  5  3  0  0  5 10 20 20  0 20  0 10  5 10  0  0  5  0  0\n",
      " 20  0  0  0  0]\n",
      " chosen actions  [16 10 14 12 12 18  9 15 18  6  0 15 11 17  1  3 23 11 14 20 20  9  6  7 16\n",
      "  0  6 10 15  8]\n",
      "mean abs err: 9.12206\n",
      "mean phys Q: 9.6284\n",
      "mean agent Q: 13.2879\n",
      "------------------------\n",
      "Saved Model, step is 266000\n",
      "Average loss is  0.171563980103\n",
      "Saving PER and importance weights\n",
      "step: 266000\n",
      "physactions  [22 20  0  0  0  0  5  0  0  0  0  0  0 20  5  0 15  0  0  5  0  0  0  5 15\n",
      " 15  0  0  0  0]\n",
      " chosen actions  [ 7  7  8  5 23 16 17 13 13 11 13  5 20  7  6 10 18 15  6  8 17 11 19  7 17\n",
      " 11 12 19 21  0]\n",
      "mean abs err: 9.4366\n",
      "mean phys Q: 9.69851\n",
      "mean agent Q: 13.5199\n",
      "------------------------\n",
      "Saved Model, step is 267000\n",
      "Average loss is  0.157726610661\n",
      "Saving PER and importance weights\n",
      "step: 267000\n",
      "physactions  [20  5  0  0 19 15  0  5  5  0  0 15  4  0  0 14 15 10  5  0  0  0  1  5 20\n",
      " 15  5  5 10 10]\n",
      " chosen actions  [20  6 18 11  0  5 13 23  0  9 15 12 21  7 18 18 12 14 23 14  8 11 18 17  0\n",
      " 13  0 14  0 13]\n",
      "mean abs err: 8.39609\n",
      "mean phys Q: 10.2291\n",
      "mean agent Q: 13.9973\n",
      "------------------------\n",
      "Saved Model, step is 268000\n",
      "Average loss is  0.213506938457\n",
      "Saving PER and importance weights\n",
      "step: 268000\n",
      "physactions  [ 0  0  0  0 10 18  5  0  0  5  0  5  5 15  5  5  0 10  5 14 13 20  0  0 21\n",
      "  0  0 15  0  0]\n",
      " chosen actions  [20 20 24 15 11 21  1  5 16  0  5  8 17  6 17 20 13 15  8 14  2 15 20 20  6\n",
      " 23  5 11  6 20]\n",
      "mean abs err: 11.2645\n",
      "mean phys Q: 8.53204\n",
      "mean agent Q: 12.684\n",
      "------------------------\n",
      "Saved Model, step is 269000\n",
      "Average loss is  0.214708258867\n",
      "Saving PER and importance weights\n",
      "step: 269000\n",
      "physactions  [10  0 15  0 15 17  9 13  0  0  5  5 15  5 12  0  0  0 11 15  5  0 15  0 15\n",
      "  5  5  0  0 10]\n",
      " chosen actions  [13 18 16 18 17  0  3  9  6 16 13  9 14 11 23 12 11 12  0 17  9  1 18 12  9\n",
      " 21 17 20 21  0]\n",
      "mean abs err: 8.34783\n",
      "mean phys Q: 9.13967\n",
      "mean agent Q: 12.9442\n",
      "------------------------\n",
      "Saved Model, step is 270000\n",
      "Average loss is  0.221016960144\n",
      "Saving PER and importance weights\n",
      "step: 270000\n",
      "physactions  [ 0 15  5  0  5  5 13 15  5 15  0  0  0  5 15 15  0  5 14 18  0  0  5 20 14\n",
      "  0 20  0  0 19]\n",
      " chosen actions  [ 0  8  1 13  5  7 20  8 20  8 20 14 13  5 10 15 15  7  4 20 24 10 17 17 17\n",
      " 10 22 10 10 11]\n",
      "mean abs err: 9.82292\n",
      "mean phys Q: 8.63663\n",
      "mean agent Q: 12.4261\n",
      "------------------------\n",
      "Saved Model, step is 271000\n",
      "Average loss is  0.0971335077286\n",
      "Saving PER and importance weights\n",
      "step: 271000\n",
      "physactions  [10 20  5  0  5  0 20  0 17  0  0 15 10  5  5 15  0  0 12  0  0 20  5 10 20\n",
      "  0  5  0  0 10]\n",
      " chosen actions  [22  0  7 20 15  0 20 15  4 17  0 17 15 23 22  0 10 21 21  6 15 11 22 20  9\n",
      " 20 13  4 13  6]\n",
      "mean abs err: 9.90328\n",
      "mean phys Q: 9.43927\n",
      "mean agent Q: 13.9859\n",
      "------------------------\n",
      "Saved Model, step is 272000\n",
      "Average loss is  0.20555431366\n",
      "Saving PER and importance weights\n",
      "step: 272000\n",
      "physactions  [10  0 10 20  4  0  0  0  5 11 10 10  0  0  2  0  0  5  5  5  0 15  0  0 10\n",
      " 12 15  0  0  0]\n",
      " chosen actions  [19 10  0 20  0 20 15  7 21  6 11 17  6 17 15  1 15 15 24 23  0  6 17 15  6\n",
      "  0 22  0 15  9]\n",
      "mean abs err: 9.09459\n",
      "mean phys Q: 9.02223\n",
      "mean agent Q: 12.9345\n",
      "------------------------\n",
      "Saved Model, step is 273000\n",
      "Average loss is  0.180142868996\n",
      "Saving PER and importance weights\n",
      "step: 273000\n",
      "physactions  [ 5  0 15 15 16  0 20 10 24  5  5  0  0  0 15  5  5  0  5  5  0  6  0 20  5\n",
      "  5  0 15  0  5]\n",
      " chosen actions  [17 15 20  1 10 13 17 10  0  8 13 12 16 16  2 11  7 12  8  9 13 17  0  7 20\n",
      "  0 21 20 17 15]\n",
      "mean abs err: 9.18608\n",
      "mean phys Q: 11.1626\n",
      "mean agent Q: 14.7754\n",
      "------------------------\n",
      "Saved Model, step is 274000\n",
      "Average loss is  0.180951248169\n",
      "Saving PER and importance weights\n",
      "step: 274000\n",
      "physactions  [ 0  5 21 10  0  0 10  0 22  0  0 15 10  5  0  0  5 23  0 10  0 20 10  0 10\n",
      "  5 15  0 18  0]\n",
      " chosen actions  [21 15  0 15 12  6 15  6  0 13 22 13  7 19 18  1  6 15 15 13 11 18 18 23 17\n",
      " 18 24 11 16  0]\n",
      "mean abs err: 9.53096\n",
      "mean phys Q: 10.8805\n",
      "mean agent Q: 14.6252\n",
      "------------------------\n",
      "Saved Model, step is 275000\n",
      "Average loss is  0.234140385628\n",
      "Saving PER and importance weights\n",
      "step: 275000\n",
      "physactions  [10 14 20  0 10  0  0  0 16  0  0  5 20  6 20  9  5  5  0  0  0 20  0  0 10\n",
      "  0  0 24  0  0]\n",
      " chosen actions  [22  0  2 20 23  6 18 16 18 16 15 13  0  0 11 15 23 13  7 20  6  9 20 20  6\n",
      "  1 20 24  7 10]\n",
      "mean abs err: 11.1078\n",
      "mean phys Q: 7.69422\n",
      "mean agent Q: 11.855\n",
      "------------------------\n",
      "Saved Model, step is 276000\n",
      "Average loss is  0.2051130867\n",
      "Saving PER and importance weights\n",
      "step: 276000\n",
      "physactions  [10  5  0 12  0 15  0 15  5 10  0  5  0 13 22  5  0  0  5  0 15  7 15  0 15\n",
      "  0  0  0  0  5]\n",
      " chosen actions  [17 21 20 17 13 11 13 17 21 10 20  2 20 24 17 21  6  4 11 15  1 21  6 20 10\n",
      "  1 20 20 20  9]\n",
      "mean abs err: 9.57454\n",
      "mean phys Q: 10.0563\n",
      "mean agent Q: 13.7335\n",
      "------------------------\n",
      "Saved Model, step is 277000\n",
      "Average loss is  0.177573681831\n",
      "Saving PER and importance weights\n",
      "step: 277000\n",
      "physactions  [21  5  0  0 10  0  0  0 15  5  5 20  5  0  0  0  0  5 15 15  0 15  0  0  5\n",
      "  0  0 24 13  6]\n",
      " chosen actions  [ 7 11 21 12  6  9 21 18  7  9  9  7 20 11  1 15 21 23 17  9  9 22 18  7  0\n",
      "  1 14 15 17 23]\n",
      "mean abs err: 8.86151\n",
      "mean phys Q: 10.4119\n",
      "mean agent Q: 13.8984\n",
      "------------------------\n",
      "Saved Model, step is 278000\n",
      "Average loss is  0.167230674744\n",
      "Saving PER and importance weights\n",
      "step: 278000\n",
      "physactions  [10  0 15 10  0  0  0  5  0  0 15 20  5  0 15 12  5 24  0  0  0  5 23  0  0\n",
      "  0 24 10 15 15]\n",
      " chosen actions  [23  1 17 14 20 13 20 23 15  6 18 14 22 18 17 13 15 17 11 20  8  6 11 20 20\n",
      " 23  5 11 15 14]\n",
      "mean abs err: 10.6088\n",
      "mean phys Q: 8.61466\n",
      "mean agent Q: 12.6564\n",
      "------------------------\n",
      "Saved Model, step is 279000\n",
      "Average loss is  0.290298601627\n",
      "Saving PER and importance weights\n",
      "step: 279000\n",
      "physactions  [ 0 24  0  0  0 15  5 23 20 10  0 10  4  0 22 10  0 15 15  0 19 24 20 11 10\n",
      "  0 18 15  5  0]\n",
      " chosen actions  [20  1  6  6 20  5 23 17 11  0  1  6  6 17  6 11  1 24 20 13 18  2 20  8  6\n",
      " 13 20  0 21  1]\n",
      "mean abs err: 9.68137\n",
      "mean phys Q: 9.45529\n",
      "mean agent Q: 13.1928\n",
      "------------------------\n",
      "Saved Model, step is 280000\n",
      "Average loss is  0.225123569489\n",
      "Saving PER and importance weights\n",
      "step: 280000\n",
      "physactions  [ 0  0  0 20 20  0  0  5  5  0  9 11 15 10  0 10  5  0  0  0 10  0  0  0  0\n",
      " 15 15  5 10  7]\n",
      " chosen actions  [ 1 10 11 11 20 11 16 12 18  0  9 14  1  6  7 10 22  6 15  2  6  1 22 11 21\n",
      "  7 10 20 14 15]\n",
      "mean abs err: 9.44619\n",
      "mean phys Q: 8.40254\n",
      "mean agent Q: 12.6982\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Model, step is 281000\n",
      "Average loss is  0.185968512535\n",
      "Saving PER and importance weights\n",
      "step: 281000\n",
      "physactions  [15  0  0  0 20  0  0  0  0 15  0  0 20  0  0  0  5  0  0  0  0  0 15  0  0\n",
      "  5  0 12 10  0]\n",
      " chosen actions  [24 15 15 15 15 20 15 15 21 15 22 17 20 15 15 20 11 10 13 15 15 15 22 14 18\n",
      "  8 15  3 24 14]\n",
      "mean abs err: 9.45194\n",
      "mean phys Q: 9.93355\n",
      "mean agent Q: 13.6702\n",
      "------------------------\n",
      "Saved Model, step is 282000\n",
      "Average loss is  0.269302135468\n",
      "Saving PER and importance weights\n",
      "step: 282000\n",
      "physactions  [ 0 20  0  0  0  0  0 10  0  0  0 24  0  0 10 16  0  5  0 15  0  0 15  0  0\n",
      "  0 10 19 23  0]\n",
      " chosen actions  [21 23 11 20 10 21 13 13  6 11  5 12 23 23 18 17  0 14  6 16 16  6 11  9 12\n",
      " 17 13 11 18 15]\n",
      "mean abs err: 9.32375\n",
      "mean phys Q: 9.68515\n",
      "mean agent Q: 13.4767\n",
      "------------------------\n",
      "Saved Model, step is 283000\n",
      "Average loss is  0.203678431988\n",
      "Saving PER and importance weights\n",
      "step: 283000\n",
      "physactions  [20  0  0  5  0  0 15  0  0 15  0 10  0  0 15 10  5  0 10 10  5 15  5  0  5\n",
      "  5  5  0 10  0]\n",
      " chosen actions  [17  6 14 18  1 15 19 16 13  1 20 15 15  7 13  6 15 20  0 18 17 18 14 17  0\n",
      " 15 23 18 21 23]\n",
      "mean abs err: 9.40086\n",
      "mean phys Q: 8.79243\n",
      "mean agent Q: 12.8663\n",
      "------------------------\n",
      "Saved Model, step is 284000\n",
      "Average loss is  0.180063264847\n",
      "Saving PER and importance weights\n",
      "step: 284000\n",
      "physactions  [10 20  0  0  0 10  0  0  2  0  6  0  0 15  0 15  0  0  3  0 15 10  0  5 10\n",
      "  5  0  0  0  5]\n",
      " chosen actions  [11 23 18 15 15  6 22 16 13 24  6 15 18  8 24 19  1 14  0 13  7 15 12  9  8\n",
      " 21  6 17  8 17]\n",
      "mean abs err: 10.446\n",
      "mean phys Q: 9.28355\n",
      "mean agent Q: 13.3888\n",
      "------------------------\n",
      "Saved Model, step is 285000\n",
      "Average loss is  0.159349596977\n",
      "Saving PER and importance weights\n",
      "step: 285000\n",
      "physactions  [ 0 10  0 10  0 19  0  0  0  5  0 10  0 10  0  0 13  5  0 16 20  5  5  0  0\n",
      " 15  0 10 22  5]\n",
      " chosen actions  [ 6 18 24 19 24 18 13 22 24 18 13 14  6  7 24 21  0  7 22 23 13 22 22  8 15\n",
      " 20  8 14  0 20]\n",
      "mean abs err: 8.93711\n",
      "mean phys Q: 8.94115\n",
      "mean agent Q: 12.882\n",
      "------------------------\n",
      "Saved Model, step is 286000\n",
      "Average loss is  0.147660750389\n",
      "Saving PER and importance weights\n",
      "step: 286000\n",
      "physactions  [ 5 15  0  5  0  0 11  0 10 20 17  0  5 18  0  4  0  0 15  5 20  0  0  5  0\n",
      "  0  5  0  5 20]\n",
      " chosen actions  [21 22  0  0  7 15 20 23 21  3  0 13 10  8 16 16 16 18 18  6  7 15 23  6  5\n",
      "  7 23 20 22  8]\n",
      "mean abs err: 8.89487\n",
      "mean phys Q: 8.95615\n",
      "mean agent Q: 12.9494\n",
      "------------------------\n",
      "Saved Model, step is 287000\n",
      "Average loss is  0.171847416401\n",
      "Saving PER and importance weights\n",
      "step: 287000\n",
      "physactions  [15  0  0  0  0  0  0  5  0 15 21 10 15  0  0  5  5  1  0  5  0 20  0 15 13\n",
      "  5  0  5  5  5]\n",
      " chosen actions  [17 15  0 21  6  5 14  3 23 20 12  0 21 17  5  0  0 23  0  0 24  0  0 11 13\n",
      " 16 13  7 17 22]\n",
      "mean abs err: 10.4198\n",
      "mean phys Q: 9.31511\n",
      "mean agent Q: 13.5387\n",
      "------------------------\n",
      "Saved Model, step is 288000\n",
      "Average loss is  0.210360330582\n",
      "Saving PER and importance weights\n",
      "step: 288000\n",
      "physactions  [ 0 21 11  0 19  0  0 15 13 18 20 23 15  0 20  0 10  5 10 10  0  5  0 15  0\n",
      " 20  5  0  0 24]\n",
      " chosen actions  [ 6  8 11 16 19 24  7  7  8  0 11 22  6  6 13  1 24  9 14 22 15 21 20 16 18\n",
      " 23  7  5 20  1]\n",
      "mean abs err: 10.6566\n",
      "mean phys Q: 8.26904\n",
      "mean agent Q: 12.2809\n",
      "------------------------\n",
      "Saved Model, step is 289000\n",
      "Average loss is  0.302692680359\n",
      "Saving PER and importance weights\n",
      "step: 289000\n",
      "physactions  [ 5  0 24 10  0 10 10  0 21 20  0  0 11  0 23  0  0  5 15  5 10 12  0  0  0\n",
      "  0  5  0  5  0]\n",
      " chosen actions  [22 21 23 17  0  7 11 15  6 16 16 13 16 23 17 15 23  6 18  6 21  8 16  6  2\n",
      " 18 20  6  4 21]\n",
      "mean abs err: 11.4129\n",
      "mean phys Q: 8.80167\n",
      "mean agent Q: 12.5519\n",
      "------------------------\n",
      "Saved Model, step is 290000\n",
      "Average loss is  0.164856820583\n",
      "Saving PER and importance weights\n",
      "step: 290000\n",
      "physactions  [ 0  0 15  5  0  0 15  5  0  0 10  0  0  0 24 20  0  0  0  0  0  0 15 17  0\n",
      "  5 23 15  0 10]\n",
      " chosen actions  [16  0  6  6 15 13 11 22 12 23  0  1 24 16 20 20 11 20 16 17 18  6 12 24  0\n",
      " 21  8  8  6 20]\n",
      "mean abs err: 8.63953\n",
      "mean phys Q: 10.6152\n",
      "mean agent Q: 14.1688\n",
      "------------------------\n",
      "Saved Model, step is 291000\n",
      "Average loss is  0.232403144836\n",
      "Saving PER and importance weights\n",
      "step: 291000\n",
      "physactions  [10  0  0  0  0  0  0  5  3 10  5 20  0 15 15  5 10  0  0  5  0  5  0  0 10\n",
      "  0 11  9  0  0]\n",
      " chosen actions  [13  1 18  6 20 18 20 22 17 16 17 17  7  2 15 15 22  0  3 15  0  0  1 24 13\n",
      "  6 17  8 15 13]\n",
      "mean abs err: 9.61371\n",
      "mean phys Q: 8.31749\n",
      "mean agent Q: 12.4211\n",
      "------------------------\n",
      "Saved Model, step is 292000\n",
      "Average loss is  0.231126775742\n",
      "Saving PER and importance weights\n",
      "step: 292000\n",
      "physactions  [ 5  5  0  0 10 15 10  0  5  0  5  5  5  5  5  0 12 10  5 15 22 11  0 15  5\n",
      "  5  5  5 15 22]\n",
      " chosen actions  [15 24 24 23 15 11 23  6  6 20 10 13 10 20 15  1  2 14  8 11 10  0 24 13 22\n",
      " 15 17 10 15 18]\n",
      "mean abs err: 10.7517\n",
      "mean phys Q: 8.03171\n",
      "mean agent Q: 12.3528\n",
      "------------------------\n",
      "Saved Model, step is 293000\n",
      "Average loss is  0.169090247154\n",
      "Saving PER and importance weights\n",
      "step: 293000\n",
      "physactions  [ 0  0  0  0  0 10  5  0 20 20 11  5 10  2  0  0  0 20 10 18  0 15 20 21  0\n",
      " 10  0  5 15 10]\n",
      " chosen actions  [ 1  0  0 16  0 23 13 13  3 17 20 17 20 18 10 20 16 14 13 14  8 11  1  0  2\n",
      " 11  1 24 23 20]\n",
      "mean abs err: 9.59661\n",
      "mean phys Q: 7.82485\n",
      "mean agent Q: 12.4735\n",
      "------------------------\n",
      "Saved Model, step is 294000\n",
      "Average loss is  0.150418855667\n",
      "Saving PER and importance weights\n",
      "step: 294000\n",
      "physactions  [ 5  0 15  0  5  7  5 11  4  0  0 13  0  0  0  0 15 15 10 15 19  0  0 13 24\n",
      "  0  0 12  0  0]\n",
      " chosen actions  [13  5  3  5 23 13 10 18 16  0  0  6 18 21 16  0 17  8 13 23  7 18 13 17  0\n",
      "  1  7  6  6  1]\n",
      "mean abs err: 8.1581\n",
      "mean phys Q: 9.93976\n",
      "mean agent Q: 13.7082\n",
      "------------------------\n",
      "Saved Model, step is 295000\n",
      "Average loss is  0.193872220993\n",
      "Saving PER and importance weights\n",
      "step: 295000\n",
      "physactions  [ 5 11 13  0  0 10  0 15 10  0 22  4  0  0 12 10  0 10  0 17  5  0  0 22 15\n",
      "  5 19  5  0 15]\n",
      " chosen actions  [ 5 18  0  8  2 22 16  6 20 14 24 17 23  5  5  7  1 17 12 19  9  2  0 21 20\n",
      " 24 15 13  6 11]\n",
      "mean abs err: 9.55404\n",
      "mean phys Q: 9.97788\n",
      "mean agent Q: 13.8573\n",
      "------------------------\n",
      "Saved Model, step is 296000\n",
      "Average loss is  0.198532910347\n",
      "Saving PER and importance weights\n",
      "step: 296000\n",
      "physactions  [ 0  0 20  5  0 20  0 16  0 15  0  0  0 19  5  0  5 20  0 15 15 10  0 15  8\n",
      "  0 13  5  0  0]\n",
      " chosen actions  [11 10 15 20 20  7  7 20 15  6 10 20  5 22 21 20 15 13 10 19 22 22 15 23 14\n",
      " 15  8 17  0 23]\n",
      "mean abs err: 10.6484\n",
      "mean phys Q: 7.99814\n",
      "mean agent Q: 12.1502\n",
      "------------------------\n",
      "Saved Model, step is 297000\n",
      "Average loss is  0.277598100185\n",
      "Saving PER and importance weights\n",
      "step: 297000\n",
      "physactions  [ 0 20  5  0  0  0  5 20  0  8 15  5  5 10  0  0  5  0 16  5  0  0  0  0 20\n",
      "  0  0  0 13  0]\n",
      " chosen actions  [ 7 13 19  6 23  0 17  9 18  6 19 17 21  2 15  6 23  0 22 11  3  3 18 15 16\n",
      " 21 12  0  0  7]\n",
      "mean abs err: 10.9114\n",
      "mean phys Q: 8.66158\n",
      "mean agent Q: 13.2992\n",
      "------------------------\n",
      "Saved Model, step is 298000\n",
      "Average loss is  0.229634781837\n",
      "Saving PER and importance weights\n",
      "step: 298000\n",
      "physactions  [10 10  0 16  0  0  0  0 20 10  5  5  0 16  4 14 21 13  5  0 15  0  5  0  0\n",
      "  0  5 24 16  0]\n",
      " chosen actions  [ 7  0 21 23  8  6  7 24 17  2  7 17 13 17  9 21  5  6  8 11 15  2 15  2  0\n",
      "  2 11 22  0 14]\n",
      "mean abs err: 9.36596\n",
      "mean phys Q: 8.12007\n",
      "mean agent Q: 12.7971\n",
      "------------------------\n",
      "Saved Model, step is 299000\n",
      "Average loss is  0.181948999405\n",
      "Saving PER and importance weights\n",
      "step: 299000\n",
      "physactions  [ 0 10  0  5  0  0 13  5  5  0 15 24  0  0 15  0 16 10 15  0  5 20 15 15  0\n",
      "  5 21  0  0 19]\n",
      " chosen actions  [20  6 20  2 12 13 23  1 17 12 19 24 16 20  1 12  6 20 18  2 18 11  0 13 13\n",
      " 15  5  6 22 13]\n",
      "mean abs err: 9.21405\n",
      "mean phys Q: 9.18507\n",
      "mean agent Q: 13.582\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "# The main training loop is here\n",
    "per_alpha = 0.6 # PER hyperparameter\n",
    "per_epsilon = 0.01 # PER hyperparameter\n",
    "batch_size = 30 #How many experiences to use for each training step.\n",
    "gamma = 0.99 #Discount factor on the target Q-values\n",
    "num_steps = 300000\n",
    "load_model = False #Whether to load a saved model.\n",
    "save_dir = '../../data/dqn/'\n",
    "save_path = \"./model/\"#The path to save our model to.\n",
    "tau = 0.001 #Rate to update target network toward primary network\n",
    "tf.reset_default_graph()\n",
    "mainQN = Qnetwork()\n",
    "targetQN = Qnetwork()\n",
    "av_q_list = []\n",
    "save_results = False\n",
    "\n",
    "saver = tf.train.Saver(tf.global_variables())\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "trainables = tf.trainable_variables()\n",
    "target_ops = update_target_graph(trainables, tau)\n",
    "\n",
    "#Make a path for our model to be saved in.\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    if load_model == True:\n",
    "        print('Trying to load model...')\n",
    "        try:\n",
    "            restorer = tf.train.import_meta_graph(save_path + 'ckpt.meta')\n",
    "            restorer.restore(sess, tf.train.latest_checkpoint(save_dir))\n",
    "            print (\"Model restored\")\n",
    "        except IOError:\n",
    "            print (\"No previous model found, running default init\")\n",
    "            sess.run(init)\n",
    "        try:\n",
    "            per_weights = pickle.load(open( save_dir + \"per_weights.p\", \"rb\" ))\n",
    "            imp_weights = pickle.load(open( save_dir + \"imp_weights.p\", \"rb\" ))\n",
    "            \n",
    "            # the PER weights, governing probability of sampling, and importance sampling\n",
    "            # weights for use in the gradient descent updates\n",
    "            train['prob'] = per_weights\n",
    "            train['imp_weight'] = imp_weights\n",
    "            print (\"PER and Importance weights restored\")\n",
    "        except IOError:\n",
    "            print(\"No PER weights found - default being used for PER and importance sampling\")\n",
    "    else:\n",
    "        print(\"Running default init\")\n",
    "        sess.run(init)\n",
    "    print(\"Init done\")\n",
    "    \n",
    "    for i in range(num_steps):\n",
    "        \n",
    "        if save_results:\n",
    "            do_save_results()\n",
    "            break\n",
    "            \n",
    "        net_loss = 0.0\n",
    "        net_q = 0.0\n",
    "        states, actions, rewards, next_states, done_flags, sampled_df = process_batch(batch_size)\n",
    "        # firstly get the chosen actions at the next timestep\n",
    "        actions_from_q1 = sess.run(mainQN.predict, feed_dict={mainQN.state:next_states, mainQN.phase : 1})\n",
    "        # actions chosen now, as a check\n",
    "        cur_act = sess.run(mainQN.predict, feed_dict={mainQN.state:states, mainQN.phase : 1})\n",
    "        \n",
    "        # Q values for the next timestep from target network, as part of the Double DQN update\n",
    "        Q2 = sess.run(targetQN.q_output, feed_dict={targetQN.state:next_states, targetQN.phase : 1})\n",
    "        # handles the case when a trajectory is finished\n",
    "        end_multiplier = 1 - done_flags\n",
    "        \n",
    "        # target Q value using Q values from target, and actions from main\n",
    "        double_q_value = Q2[range(batch_size), actions_from_q1]\n",
    "        \n",
    "        # empirical hack to make the Q values never exceed the threshold - helps learning\n",
    "        double_q_value[double_q_value > REWARD_THRESHOLD] = REWARD_THRESHOLD\n",
    "        double_q_value[double_q_value < -REWARD_THRESHOLD] = -REWARD_THRESHOLD\n",
    "        \n",
    "        # definition of target Q\n",
    "        targetQ = rewards + (gamma * double_q_value * end_multiplier)\n",
    "        \n",
    "        # Calculate the importance sampling weights for PER\n",
    "        imp_sampling_weights = np.array(sampled_df['imp_weight'] / float(max(train['imp_weight'])))\n",
    "        imp_sampling_weights[np.isnan(imp_sampling_weights)] = 1\n",
    "        imp_sampling_weights[imp_sampling_weights <= 0.001] = 0.001\n",
    "        \n",
    "        # Train with the batch\n",
    "        _, loss, error, q_output = sess.run([mainQN.update_model, mainQN.loss, mainQN.abs_error, mainQN.q_output], \\\n",
    "            feed_dict={mainQN.state: states,\n",
    "                       mainQN.targetQ: targetQ, \n",
    "                       mainQN.actions: actions,\n",
    "                       mainQN.phase: True,\n",
    "                       mainQN.imp_weights: imp_sampling_weights})\n",
    "        \n",
    "        # print (q_output)\n",
    "        \n",
    "        ### TODO: update the target network every 200 steps\n",
    "        # Update target towards main network\n",
    "        # if i % 200 == 0:\n",
    "        update_target(target_ops, sess)\n",
    "        \n",
    "        net_loss += sum(error)\n",
    "        net_q += np.mean(targetQ)\n",
    "        \n",
    "        # Set the selection weight/prob to the abs prediction error and update the importance sampling weight\n",
    "        new_weights = pow((error + per_epsilon), per_alpha)\n",
    "        train.loc[train.index.isin(sampled_df.index), 'prob'] = new_weights\n",
    "        temp = 1.0 / new_weights\n",
    "        train.loc[train.index.isin(sampled_df.index), 'imp_weight'] = pow(((1.0/len(train)) * temp), beta_start)\n",
    "        \n",
    "        \n",
    "        if i % 1000 == 0 and i > 0:\n",
    "            saver.save(sess,save_path)\n",
    "            print(\"Saved Model, step is \" + str(i))\n",
    "            \n",
    "            av_loss = net_loss / 1000.0\n",
    "            print(\"Average loss is \", av_loss)\n",
    "            net_loss = 0.0\n",
    "             \n",
    "            print (\"Saving PER and importance weights\")\n",
    "            with open(save_dir + 'per_weights.p', 'wb') as f:\n",
    "                pickle.dump(train['prob'], f)\n",
    "            with open(save_dir + 'imp_weights.p', 'wb') as f:\n",
    "                pickle.dump(train['imp_weight'], f)\n",
    "        \n",
    "        if (i % 1000 == 0) and i > 0:\n",
    "            print ('step:', i)\n",
    "            print (\"physactions \", actions)\n",
    "            print (\" chosen actions \", cur_act)\n",
    "            if i >= 1000:\n",
    "                # run an evaluation on the validation set\n",
    "                phys_q, phys_actions, agent_q, agent_actions, mean_abs_error = do_eval(eval_type = 'test')       \n",
    "                print ('mean abs err:', mean_abs_error)\n",
    "                print ('mean phys Q:', np.mean(phys_q))\n",
    "                print ('mean agent Q:', np.mean(agent_q))\n",
    "            print ('------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15    10368\n",
       "19     9346\n",
       "17     5810\n",
       "20     4746\n",
       "16     4742\n",
       "22     3091\n",
       "4      2698\n",
       "21     1680\n",
       "14     1642\n",
       "24     1518\n",
       "0      1134\n",
       "3      1084\n",
       "13      663\n",
       "10      501\n",
       "5       459\n",
       "6       439\n",
       "8       367\n",
       "18      244\n",
       "1       152\n",
       "12       80\n",
       "11       64\n",
       "7        21\n",
       "23        8\n",
       "9         1\n",
       "2         1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(agent_actions).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1201602e8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x125a5b048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "% matplotlib inline\n",
    "pd.Series(agent_actions).hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "662"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(agent_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50859,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5645"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(phys_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
