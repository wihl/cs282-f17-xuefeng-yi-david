{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import autograd.numpy as np\n",
    "from autograd import grad \n",
    "# from rl_functions import off_policy_per_decision_weighted_doubly_robust as WDR\n",
    "from rl_functions import value_iteration\n",
    "from rl_functions import learn_rewards_function\n",
    "from rl_functions import learn_transition_function\n",
    "from rl_functions import turn_policy_to_stochastic_policy\n",
    "from autograd.misc.optimizers import adam\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "origin_train_set = pd.read_csv('../../data/train_scaled.csv')\n",
    "origin_test_set = pd.read_csv('../../data/test_scaled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('../../data/train_scaled_encoded.csv')\n",
    "test_set = pd.read_csv('../../data/test_scaled_encoded.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1053,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "non_int_reward = test_set['reward']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_input = pd.read_csv('../../data/train_input_features.csv')\n",
    "test_input = pd.read_csv('../../data/test_input_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del train_input['intermediate_reward']\n",
    "del test_input['intermediate_reward']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(fields, df):\n",
    "    for item in fields:\n",
    "        av = df[item].mean()\n",
    "        std = df[item].std()\n",
    "        df[item] = (df[item] - av) / std\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_state_list = pkl.load(open('../../data/classify_state/train_states.pkl', 'rb'), encoding='latin1')\n",
    "test_state_list = pkl.load(open('../../data/classify_state/test_states.pkl', 'rb'), encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "action_map = {}\n",
    "count = 0\n",
    "for iv in range(5):\n",
    "    for vaso in range(5):\n",
    "        action_map[(iv, vaso)] = count\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get test set intermediate rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_rewards = test_input['intermediate_reward']\n",
    "train_rewards = train_input['intermediate_reward']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x14e366c50>"
      ]
     },
     "execution_count": 1199,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14da86320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(test_rewards).hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute pi action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# physician pi action\n",
    "def get_pi(state_list, actions):\n",
    "    pi = np.zeros((750, 25))\n",
    "    for i, s in enumerate(state_list):\n",
    "        if i == state_list.shape[0] - 1:\n",
    "            break\n",
    "        pi[s, int(actions[i])] += 1\n",
    "    pi = pi / np.sum(pi, axis=1, keepdims=True)\n",
    "    return np.nan_to_num(pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get physician actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_phy_actions(df):\n",
    "    phy_actions = []\n",
    "    vasos = df['vaso_input'].values\n",
    "    ivs = df['iv_input'].values\n",
    "    for i, iv in enumerate(ivs):\n",
    "        phy_actions += [ action_map[ (iv, vasos[i]) ] ]\n",
    "    return phy_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_phy_actions = get_phy_actions(train_set)\n",
    "test_phy_actions = get_phy_actions(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x148629ef0>"
      ]
     },
     "execution_count": 1175,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFThJREFUeJzt3X+QXfV53/H3UxRsBTlIhPgOI6mVWmvcwahp7B2g40xm\nZVoQkInojMPAMLHkqlVnilO3VaeIdDLy2GYqt1aoTWN31EiNSBTLlDiVxiIhGszWzUzBIJth+RHC\nFougHSEllpCzNrFnnad/3K/SK313Je25K93de9+vmZ0997nfc+730Vn2s+fHvURmIklSp7/R6wlI\nkuYew0GSVDEcJEkVw0GSVDEcJEkVw0GSVDEcJEkVw0GSVDEcJEmVBb2eQFNXX311rlixotG63/ve\n97jiiitmd0LzxCD3DoPd/yD3DoPdf2fvhw4d+vPM/KnzrTNvw2HFihU8++yzjdYdGRlheHh4dic0\nTwxy7zDY/Q9y7zDY/Xf2HhGvX8g6nlaSJFUMB0lSxXCQJFUMB0lSxXCQJFUMB0lSxXCQJFUMB0lS\nxXCQJFXm7TukuzE6fooNWw5U9cPbbu/BbCRp7vHIQZJUMRwkSRXDQZJUOW84RMSuiDgeES901P5T\nRPxxRDwfEb8XEYs7nrs/IsYi4pWIuKWjvrbUxiJiS0d9ZUQ8XepfjojLZ7NBSdLMXciRw28Ca8+q\nHQSuy8y/B/wJcD9ARFwL3AW8r6zzhYi4LCIuA34duBW4Fri7jAX4DPBgZr4HOAls7KojSVLXzhsO\nmfl14MRZtT/MzMny8ClgWVleB+zNzB9k5reBMeD68jWWma9l5g+BvcC6iAjgQ8CjZf3dwB1d9iRJ\n6tJs3Mr6T4Avl+WltMPitCOlBvDGWfUbgJ8E3uoIms7xlYjYBGwCaLVajIyMNJpwayFsXj1Z1Ztu\nbz6ZmJgYiD6nM8j9D3LvMNj9N+m9q3CIiH8PTAJ7utnOhcrMHcAOgKGhoWz6f3V6aM8+to/WrR++\np9n25pNB/r9hwWD3P8i9w2D336T3xuEQERuAnwduysws5XFgecewZaXGNPXvAIsjYkE5eugcL0nq\nkUa3skbEWuDfAb+Qmd/veGo/cFdEvCMiVgKrgG8AzwCryp1Jl9O+aL2/hMqTwIfL+uuBfc1akSTN\nlgu5lfVLwP8B3hsRRyJiI/BfgHcBByPiuYj4rwCZ+SLwCPAS8AfAvZn5o3JU8DHgceBl4JEyFuA+\n4N9ExBjtaxA7Z7VDSdKMnfe0UmbePUV52l/gmfkA8MAU9ceAx6aov0b7biZJ0hzhO6QlSRXDQZJU\nMRwkSRXDQZJUMRwkSRXDQZJUMRwkSRXDQZJUMRwkSRXDQZJUMRwkSRXDQZJUMRwkSRXDQZJUMRwk\nSRXDQZJUMRwkSRXDQZJUMRwkSRXDQZJUMRwkSRXDQZJUMRwkSRXDQZJUOW84RMSuiDgeES901K6K\niIMR8Wr5vqTUIyI+HxFjEfF8RLy/Y531ZfyrEbG+o/6BiBgt63w+ImK2m5QkzcyFHDn8JrD2rNoW\n4InMXAU8UR4D3AqsKl+bgC9CO0yArcANwPXA1tOBUsb8s471zn4tSdIldt5wyMyvAyfOKq8Ddpfl\n3cAdHfWHs+0pYHFEXAPcAhzMzBOZeRI4CKwtz/1EZj6VmQk83LEtSVKPNL3m0MrMo2X5TaBVlpcC\nb3SMO1Jq56ofmaIuSeqhBd1uIDMzInI2JnM+EbGJ9ukqWq0WIyMjjbbTWgibV09W9abbm08mJiYG\nos/pDHL/g9w7DHb/TXpvGg7HIuKazDxaTg0dL/VxYHnHuGWlNg4Mn1UfKfVlU4yfUmbuAHYADA0N\n5fDw8HRDz+mhPfvYPlq3fvieZtubT0ZGRmj679YPBrn/Qe4dBrv/Jr03Pa20Hzh9x9F6YF9H/SPl\nrqUbgVPl9NPjwM0RsaRciL4ZeLw8992IuLHcpfSRjm1JknrkvEcOEfEl2n/1Xx0RR2jfdbQNeCQi\nNgKvA3eW4Y8BtwFjwPeBjwJk5omI+BTwTBn3ycw8fZH7X9C+I2oh8PvlS5LUQ+cNh8y8e5qnbppi\nbAL3TrOdXcCuKerPAtedbx6SpEvHd0hLkiqGgySpYjhIkiqGgySpYjhIkipdv0Na88OKLQeA9jvD\nN5RlgMPbbu/VlCTNYR45SJIqhoMkqWI4SJIqhoMkqWI4SJIqhoMkqWI4SJIqhoMkqWI4SJIqhoMk\nqWI4SJIqhoMkqWI4SJIqhoMkqWI4SJIqhoMkqWI4SJIqhoMkqdJVOETEv46IFyPihYj4UkS8MyJW\nRsTTETEWEV+OiMvL2HeUx2Pl+RUd27m/1F+JiFu6a0mS1K3G4RARS4F/CQxl5nXAZcBdwGeABzPz\nPcBJYGNZZSNwstQfLOOIiGvLeu8D1gJfiIjLms5LktS9bk8rLQAWRsQC4MeBo8CHgEfL87uBO8ry\nuvKY8vxNERGlvjczf5CZ3wbGgOu7nJckqQuNwyEzx4HPAn9KOxROAYeAtzJzsgw7Aiwty0uBN8q6\nk2X8T3bWp1hHktQDC5quGBFLaP/VvxJ4C/gftE8LXTQRsQnYBNBqtRgZGWm0ndZC2Lx6sqo33d58\ncLrfs3vv556nMjExMXA9nzbIvcNg99+k98bhAPxD4NuZ+WcAEfEV4IPA4ohYUI4OlgHjZfw4sBw4\nUk5DXQl8p6N+Wuc6Z8jMHcAOgKGhoRweHm408Yf27GP7aN364XuabW8+2LDlANAOhs7e+7nnqYyM\njND052a+G+TeYbD7b9J7N9cc/hS4MSJ+vFw7uAl4CXgS+HAZsx7YV5b3l8eU57+WmVnqd5W7mVYC\nq4BvdDEvSVKXGh85ZObTEfEo8E1gEvgW7b/qDwB7I+LTpbazrLIT+K2IGANO0L5Dicx8MSIeoR0s\nk8C9mfmjpvOSJHWvm9NKZOZWYOtZ5deY4m6jzPxL4Ben2c4DwAPdzEWSNHt8h7QkqdLVkYOk+WHF\nlgNsXj351zcmnHZ42+09mpHmOo8cJEkVw0GSVDEcJEkVw0GSVDEcJEkVw0GSVDEcJEkVw0GSVDEc\nJEkVw0GSVDEcJEkVw0GSVDEcJEkVw0GSVDEcJEkVw0GSVDEcJEkVw0GSVDEcJEkVw0GSVFnQ6wlI\nF8uKLQeq2ubVkwxf+qlI845HDpKkSlfhEBGLI+LRiPjjiHg5Iv5BRFwVEQcj4tXyfUkZGxHx+YgY\ni4jnI+L9HdtZX8a/GhHru21KktSdbo8cPgf8QWb+XeCngZeBLcATmbkKeKI8BrgVWFW+NgFfBIiI\nq4CtwA3A9cDW04EiSeqNxuEQEVcCPwfsBMjMH2bmW8A6YHcZthu4oyyvAx7OtqeAxRFxDXALcDAz\nT2TmSeAgsLbpvCRJ3evmgvRK4M+A/x4RPw0cAj4OtDLzaBnzJtAqy0uBNzrWP1Jq09UlqZHpbkbY\nsOUAh7fd3oMZzT+Rmc1WjBgCngI+mJlPR8TngO8Cv5yZizvGnczMJRHxVWBbZv5RqT8B3AcMA+/M\nzE+X+q8Cb2fmZ6d4zU20T0nRarU+sHfv3kZzP37iFMferuurl17ZaHvzwej4KQBaCzmj90HouVNr\nIbz7qv7teTqj46eqfQ/9u/+n2/fH3u7fns9lYmKCRYsWAbBmzZpDmTl0vnW6OXI4AhzJzKfL40dp\nX184FhHXZObRctroeHl+HFjesf6yUhuHM+4uXAaMTPWCmbkD2AEwNDSUw8PDUw07r4f27GP7aN36\n4XuabW8+2FD+ktq8evKM3geh506bV09yZ8Ofm/lsw5YD1b6H/t3/0+377aML+rbncxkZGWGmvy8b\nX3PIzDeBNyLivaV0E/ASsB84fcfRemBfWd4PfKTctXQjcKqcfnocuDkilpQL0TeXmiSpR7p9E9wv\nA3si4nLgNeCjtAPnkYjYCLwO3FnGPgbcBowB3y9jycwTEfEp4Jky7pOZeaLLeUmSutBVOGTmc8BU\n565ummJsAvdOs51dwK5u5iJJmj2+Q1qSVDEcJEkVw0GSVDEcJEkVw0GSVDEcJEkVw0GSVDEcJEkV\nw0GSVDEcJEkVw0GSVDEcJEkVw0GSVDEcJEkVw0GSVDEcJEkVw0GSVDEcJEkVw0GSVDEcJEkVw0GS\nVDEcJEkVw0GSVDEcJEkVw0GSVOk6HCLisoj4VkR8tTxeGRFPR8RYRHw5Ii4v9XeUx2Pl+RUd27i/\n1F+JiFu6nZMkqTuzceTwceDljsefAR7MzPcAJ4GNpb4ROFnqD5ZxRMS1wF3A+4C1wBci4rJZmJck\nqaGuwiEilgG3A79RHgfwIeDRMmQ3cEdZXlceU56/qYxfB+zNzB9k5reBMeD6buYlSepOZGbzlSMe\nBf4D8C7g3wIbgKfK0QERsRz4/cy8LiJeANZm5pHy3P8FbgA+Udb57VLfWdZ59KyXIyI2AZsAWq3W\nB/bu3dto3sdPnOLY23V99dIrG21vPhgdPwVAayFn9D4IPXdqLYR3X9W/PU9ndPxUte+hf/f/dPv+\n2Nv92/O5TExMsGjRIgDWrFlzKDOHzrfOgqYvFhE/DxzPzEMRMdx0OzORmTuAHQBDQ0M5PNzsZR/a\ns4/to3Xrh+9ptr35YMOWAwBsXj15Ru+D0HOnzasnubPhz818tmHLgWrfQ//u/+n2/fbRBX3b87mM\njIww09+XjcMB+CDwCxFxG/BO4CeAzwGLI2JBZk4Cy4DxMn4cWA4ciYgFwJXAdzrqp3WuI0nqgcbX\nHDLz/sxclpkraF9Q/lpm3gM8CXy4DFsP7CvL+8tjyvNfy/Y5rf3AXeVuppXAKuAbTeclSepeN0cO\n07kP2BsRnwa+Bews9Z3Ab0XEGHCCdqCQmS9GxCPAS8AkcG9m/ugizEuSdIFmJRwycwQYKcuvMcXd\nRpn5l8AvTrP+A8ADszEXSVL3fIe0JKliOEiSKoaDJKliOEiSKoaDJKliOEiSKoaDJKliOEiSKoaD\nJKliOEiSKoaDJKliOEiSKoaDJKliOEiSKoaDJKliOEiSKoaDJKliOEiSKoaDJKliOEiSKoaDJKli\nOEiSKoaDJKliOEiSKo3DISKWR8STEfFSRLwYER8v9asi4mBEvFq+Lyn1iIjPR8RYRDwfEe/v2Nb6\nMv7ViFjffVuSpG50c+QwCWzOzGuBG4F7I+JaYAvwRGauAp4ojwFuBVaVr03AF6EdJsBW4AbgemDr\n6UCRJPVG43DIzKOZ+c2y/BfAy8BSYB2wuwzbDdxRltcBD2fbU8DiiLgGuAU4mJknMvMkcBBY23Re\nkqTuzco1h4hYAfwM8DTQysyj5ak3gVZZXgq80bHakVKbri5J6pHIzO42ELEI+F/AA5n5lYh4KzMX\ndzx/MjOXRMRXgW2Z+Uel/gRwHzAMvDMzP13qvwq8nZmfneK1NtE+JUWr1frA3r17G835+IlTHHu7\nrq9eemWj7c0Ho+OnAGgt5IzeB6HnTq2F8O6r+rfn6YyOn6r2PfTv/p9u3x97u397PpeJiQkWLVoE\nwJo1aw5l5tD51lnQzQtGxI8BvwvsycyvlPKxiLgmM4+W00bHS30cWN6x+rJSG6cdEJ31kaleLzN3\nADsAhoaGcnh4eKph5/XQnn1sH61bP3xPs+3NBxu2HABg8+rJM3ofhJ47bV49yZ0Nf27msw1bDlT7\nHvp3/0+377ePLujbns9lZGSEmf6+7OZupQB2Ai9n5q91PLUfOH3H0XpgX0f9I+WupRuBU+X00+PA\nzRGxpFyIvrnUJEk90s2RwweBXwJGI+K5UvsVYBvwSERsBF4H7izPPQbcBowB3wc+CpCZJyLiU8Az\nZdwnM/NEF/OSJHWpcTiUawcxzdM3TTE+gXun2dYuYFfTuUiSZpfvkJYkVQwHSVLFcJAkVQwHSVLF\ncJAkVQwHSVLFcJAkVQwHSVLFcJAkVbr64D1J0sWxYooPDwQ4vO32S/L6HjlIkiqGgySpYjhIkipe\nc5CkS6DX1xBmyiMHSVLFIwdJamC+HQnMlEcOkqSK4SBJqnhaSSr6/TSBzs39fyaPHCRJFY8cNCX/\nimquH/7tZtrDXBuv7hkOUo/5i09zkeGgWeEvOKm/GA7qCcOkuen+7cB/P82eORMOEbEW+BxwGfAb\nmbmtx1PSHOIvROnSmhPhEBGXAb8O/CPgCPBMROzPzJd6O7O2ufhX7lyck6T+MSfCAbgeGMvM1wAi\nYi+wDpgT4TBTs3UnxrnWkaSLaa68z2Ep8EbH4yOlJknqgcjMXs+BiPgwsDYz/2l5/EvADZn5sbPG\nbQI2lYfvBV5p+JJXA3/ecN35bpB7h8Huf5B7h8Huv7P3v5WZP3W+FebKaaVxYHnH42WldobM3AHs\n6PbFIuLZzBzqdjvz0SD3DoPd/yD3DoPdf5Pe58pppWeAVRGxMiIuB+4C9vd4TpI0sObEkUNmTkbE\nx4DHad/KuiszX+zxtCRpYM2JcADIzMeAxy7Ry3V9amoeG+TeYbD7H+TeYbD7n3Hvc+KCtCRpbpkr\n1xwkSXPIQIVDRKyNiFciYiwitvR6PpdaRByOiNGIeC4inu31fC62iNgVEccj4oWO2lURcTAiXi3f\nl/RyjhfLNL1/IiLGy/5/LiJu6+UcL5aIWB4RT0bESxHxYkR8vNT7ft+fo/cZ7/uBOa1UPqLjT+j4\niA7g7rnyER2XQkQcBoYycyDu9Y6InwMmgIcz87pS+4/AiczcVv5AWJKZ9/VynhfDNL1/ApjIzM/2\ncm4XW0RcA1yTmd+MiHcBh4A7gA30+b4/R+93MsN9P0hHDn/9ER2Z+UPg9Ed0qE9l5teBE2eV1wG7\ny/Ju2v/h9J1peh8ImXk0M79Zlv8CeJn2Jy70/b4/R+8zNkjh4Ed0QAJ/GBGHyrvNB1ErM4+W5TeB\nVi8n0wMfi4jny2mnvjutcraIWAH8DPA0A7bvz+odZrjvBykcBD+bme8HbgXuLaceBla2z6kOxnnV\nti8Cfwf4+8BRYHtvp3NxRcQi4HeBf5WZ3+18rt/3/RS9z3jfD1I4XNBHdPSzzBwv348Dv0f7VNug\nOVbOy54+P3u8x/O5ZDLzWGb+KDP/Cvhv9PH+j4gfo/3LcU9mfqWUB2LfT9V7k30/SOEw0B/RERFX\nlAtURMQVwM3AC+deqy/tB9aX5fXAvh7O5ZI6/Yux+Mf06f6PiAB2Ai9n5q91PNX3+3663pvs+4G5\nWwmg3L71n/n/H9HxQI+ndMlExN+mfbQA7XfG/06/9x8RXwKGaX8i5TFgK/A/gUeAvwm8DtyZmX13\n4Xaa3odpn1ZI4DDwzzvOwfeNiPhZ4H8Do8BflfKv0D733tf7/hy9380M9/1AhYMk6cIM0mklSdIF\nMhwkSRXDQZJUMRwkSRXDQZJUMRwkSRXDQZJUMRwkSZX/B9NlJavtBaBsAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x137131fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(test_phy_actions).hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel based expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kernel_based = pkl.load(open('test_kernel_policy_transformed.pkl', 'rb'), encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expert_k = kernel_based[:,3]\n",
    "dist = kernel_based[:,4]\n",
    "#num_states = kernel_based[:,-1]\n",
    "#num_states = (num_states - np.mean(num_states)) / np.std(num_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#num_bloc = ( test_input['num_bloc'] - np.mean(test_input['num_bloc']) ) / np.std(test_input['num_bloc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_input['dist'] = dist\n",
    "#test_input['num_states'] = num_states\n",
    "#test_input['num_bloc'] = num_bloc\n",
    "# test_input['intercept'] = [1.] * test_input.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x16ace1a90>"
      ]
     },
     "execution_count": 1140,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPx9NOJbD7WRRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13262e780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "% matplotlib inline\n",
    "pd.Series(expert_k).hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN based expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expert_d = pkl.load(open('../../../code/results/with_end_state/test_agent_actions.pkl', 'rb'), encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1543ef588>"
      ]
     },
     "execution_count": 1142,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxuFgZmYZh4OZmWUcDmZmlnE4mJlZ5v8DZiyhZpNNOZcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19714e2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "% matplotlib inline\n",
    "pd.Series(expert_d).hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encode expert actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_action(action_seq):\n",
    "    encoded_expert = np.zeros((action_seq.shape[0], 25))\n",
    "    for i, a in enumerate(action_seq):\n",
    "        encoded_expert[i, int(a)] = 1\n",
    "    return encoded_expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoded_expert_k, encoded_expert_d = one_hot_action(expert_k), one_hot_action(expert_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn train set T, R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_bloc = train_input['num_bloc'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in true_divide\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "trasition = np.zeros((750, 25, 750))\n",
    "for i, s in enumerate(train_state_list):\n",
    "    if i == train_state_list.shape[0] - 1:\n",
    "        break\n",
    "    if train_bloc[i + 1] == 1:\n",
    "        continue\n",
    "    else:\n",
    "        trasition[s, train_phy_actions[i], train_state_list[i + 1]] += 1\n",
    "\n",
    "for s in range(750):\n",
    "    trasition[s] /= np.sum(trasition[s], axis=1, keepdims=True)\n",
    "trasition = np.nan_to_num(trasition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in true_divide\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "reward_table = np.zeros((750, 25, 750))\n",
    "count = np.zeros((750, 25, 750))\n",
    "for i, s in enumerate(train_state_list):\n",
    "    if i == train_state_list.shape[0] - 1:\n",
    "        break\n",
    "    if train_bloc[i + 1] == 1:\n",
    "        continue\n",
    "    else:\n",
    "        reward_table[s, train_phy_actions[i], train_state_list[i + 1]] += train_rewards[i]\n",
    "        count[s, train_phy_actions[i], train_state_list[i + 1]] += 1\n",
    "reward_table = np.nan_to_num(reward_table / count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment building MDP for MOE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_table = np.zeros((750, 25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, state in enumerate(train_state_list):\n",
    "    t_table[state, expert1[i]] += probs[i]\n",
    "    t_table[state, expert2[i]] += (1 - probs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_table = t_table / np.sum(t_table, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MDP, WDR, and IS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def policy_eval(MDP, prob_e, gamma=.99):\n",
    "\t# solve by value iteration\n",
    "\t(transition_matrix, reward_table) = MDP\n",
    "\t# print MDP\n",
    "\tV = np.zeros((transition_matrix.shape[0]))\n",
    "\t# compute V table\n",
    "\twhile 1:\n",
    "\t\tdelta = 0.\n",
    "\t\tfor s in range(transition_matrix.shape[0]):\n",
    "\t\t\tv = np.sum(prob_e[s] * np.sum(transition_matrix[s] * (reward_table[s] + gamma * V), axis = 1))\n",
    "\t\t\tdelta = max(delta, abs(v - V[s]))\n",
    "\t\t\tV[s] = v\n",
    "\n",
    "\t\tif delta < 0.0001:\n",
    "\t\t\tbreak\n",
    "\t\t\t\n",
    "\t# build Q_table\n",
    "\tQ = np.zeros((transition_matrix.shape[0], transition_matrix.shape[1]))\n",
    "\tfor s in range(transition_matrix.shape[0]):\n",
    "\t\tQ[s] = np.sum(transition_matrix[s] * (reward_table[s] + gamma * V), axis = 1)\n",
    "\treturn V, Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# physician pi_b\n",
    "def get_pi_b(state_list, phy_actions):\n",
    "    pi_b = np.zeros((750, 25))\n",
    "    for i, s in enumerate(state_list):\n",
    "        if i == state_list.shape[0] - 1:\n",
    "            break\n",
    "        pi_b[s, phy_actions[i]] += 1\n",
    "    pi_b = pi_b / np.sum(pi_b, axis=1, keepdims=True)\n",
    "    return pi_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train_pi_b = get_pi_b(train_state_list, train_phy_actions)\n",
    "test_pi_b = np.nan_to_num(get_pi_b(test_state_list, test_phy_actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def WDR(\n",
    "    states_sequence, actions_sequence, rewards_sequence, fence_posts, gamma,\n",
    "    pi_evaluation, pi_behavior, V = None, Q = None, num_of_states = None, num_of_actions = None ):\n",
    "\n",
    "    num_of_trials = len( fence_posts )\n",
    "    individual_trial_estimators = []\n",
    "    pi_evaluation = turn_policy_to_stochastic_policy( \\\n",
    "        pi_evaluation, num_of_states = num_of_states, num_of_actions = num_of_actions )\n",
    "    pi_behavior = turn_policy_to_stochastic_policy( \\\n",
    "        pi_behavior, num_of_states = num_of_states, num_of_actions = num_of_actions )\n",
    "    # estimate V and Q if they are not passed as parameters\n",
    "    if V is None or Q is None:\n",
    "        # TODO : add part which calculate R and T from data if they are not given\n",
    "        V, Q = policy_evaluation( T , R , pi_evaluation , gamma )\n",
    "    # calculate the doubly robust estimator of the policy\n",
    "    fence_posts_with_length_appended = fence_posts + [ len( states_sequence ) ]\n",
    "    single_patient_sequences_length = [ fence_posts_with_length_appended[i+1] - \\\n",
    "        fence_posts_with_length_appended[i] for i in range(len(fence_posts)) ]\n",
    "    length_of_longest_patient_sequence = max( single_patient_sequences_length )\n",
    "    rho_array = np.nan * np.zeros( ( num_of_trials, length_of_longest_patient_sequence ) )\n",
    "#    rho_array = np.ones( ( num_of_trials, length_of_longest_patient_sequence ) )\n",
    "    for trial_i in range( num_of_trials ):\n",
    "        rho = 1\n",
    "        if trial_i < num_of_trials - 1:\n",
    "            steps_in_trial = fence_posts[ trial_i+1 ] -  fence_posts[ trial_i ]\n",
    "        else:\n",
    "            steps_in_trial = len( states_sequence) - fence_posts[-1]\n",
    "        t_within_trial = 0\n",
    "        for t in range(\n",
    "                fence_posts[ trial_i], fence_posts[ trial_i] + steps_in_trial ):\n",
    "            if(pi_behavior[ states_sequence[ t], actions_sequence[ t]]==0):\n",
    "                print(states_sequence[ t], actions_sequence[ t])\n",
    "            rho *= pi_evaluation[ states_sequence[ t], actions_sequence[ t]] / \\\n",
    "                pi_behavior[ states_sequence[ t], actions_sequence[ t]]\n",
    "            rho_array[ trial_i, t_within_trial ] = rho\n",
    "            t_within_trial += 1\n",
    "        rho_array[ trial_i, t_within_trial: ] = rho\n",
    "    weights_normalization = np.sum( rho_array, axis = 0 )\n",
    "    for trial_i in range( num_of_trials ):\n",
    "        current_trial_estimator = 0\n",
    "        rho = 1\n",
    "        w = 1 / num_of_trials\n",
    "        discount = 1/gamma\n",
    "        if trial_i < num_of_trials - 1:\n",
    "            steps_in_trial = fence_posts[ trial_i+1 ] -  fence_posts[ trial_i ]\n",
    "        else:\n",
    "            steps_in_trial = len( states_sequence) - fence_posts[-1]\n",
    "        t_within_trial = 0\n",
    "        for t in range(\n",
    "                fence_posts[ trial_i], fence_posts[ trial_i] + steps_in_trial ):\n",
    "            previous_w = w\n",
    "            rho *= pi_evaluation[ states_sequence[ t], actions_sequence[ t]] / \\\n",
    "                pi_behavior[ states_sequence[ t], actions_sequence[ t]]\n",
    "            w = rho / weights_normalization[ t_within_trial ]\n",
    "            discount *= gamma\n",
    "            current_trial_estimator += w * discount * rewards_sequence[ t ] - \\\n",
    "                discount * ( w * Q[ states_sequence[ t ], actions_sequence[ t ] ] - \\\n",
    "                             previous_w * V[ states_sequence[ t ] ] )\n",
    "            t_within_trial += 1\n",
    "        individual_trial_estimators += [ current_trial_estimator ]\n",
    "    estimator = np.sum( individual_trial_estimators )\n",
    "\n",
    "    return estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def IS(\n",
    "    states_sequence, actions_sequence, rewards_sequence, fence_posts, gamma,\n",
    "    pi_evaluation, pi_behavior, num_of_states = None, num_of_actions = None ):\n",
    "\n",
    "    num_of_trials = len( fence_posts )\n",
    "    individual_trial_estimators = 0\n",
    "    pi_evaluation = turn_policy_to_stochastic_policy( \\\n",
    "        pi_evaluation, num_of_states = num_of_states, num_of_actions = num_of_actions )\n",
    "    pi_behavior = turn_policy_to_stochastic_policy( \\\n",
    "        pi_behavior, num_of_states = num_of_states, num_of_actions = num_of_actions )\n",
    "    for trial_i in range( num_of_trials ):\n",
    "        rho = 1\n",
    "        discount = 1/gamma\n",
    "        trial_return = 0\n",
    "        if trial_i < num_of_trials - 1:\n",
    "            steps_in_trial = fence_posts[ trial_i+1 ] -  fence_posts[ trial_i ]\n",
    "        else:\n",
    "            steps_in_trial = len( states_sequence) - fence_posts[-1]\n",
    "        for t in range(\n",
    "                fence_posts[ trial_i], fence_posts[ trial_i] + steps_in_trial ):\n",
    "            rho *= pi_evaluation[ states_sequence[ t], actions_sequence[ t]] / \\\n",
    "                pi_behavior[ states_sequence[ t], actions_sequence[ t]]\n",
    "            discount *= gamma\n",
    "            trial_return += discount * rewards_sequence[ t ]\n",
    "        individual_trial_estimators += trial_return * rho \n",
    "   \n",
    "    return individual_trial_estimators / ( num_of_trials )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fence_posts = []\n",
    "test_bloc = test_input['num_bloc'].values\n",
    "for i, idx in enumerate(test_bloc):\n",
    "    if idx == 1:\n",
    "        fence_posts += [ i ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_expert_actions(w):\n",
    "    probs = get_experts_action_probs(w, test_input.values)\n",
    "    moe_actions = []\n",
    "    for prob in probs:\n",
    "        if prob > 0.5:\n",
    "            moe_actions += [0]\n",
    "        else:\n",
    "            moe_actions += [1]\n",
    "    return moe_actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifer Training -- autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def get_experts_action_probs(w, f):\n",
    "    p = sigmoid(np.sum(f * w, axis=1, keepdims=True))\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def objective(w):\n",
    "    \n",
    "    probs = get_experts_action_probs(w, test_input.values)\n",
    "    pi_e = probs * encoded_expert_k + (1 - probs) * encoded_expert_d\n",
    "    \n",
    "    return IS(test_state_list, test_phy_actions, test_rewards, fence_posts, 0.99, pi_e, test_pi_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1172,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:  0  objective:  -5.48430001071\n",
      "step:  1  objective:  -5.42577053215\n",
      "step:  2  objective:  -5.36713168971\n",
      "step:  3  objective:  -5.30838362386\n",
      "step:  4  objective:  -5.24952665514\n",
      "step:  5  objective:  -5.19056129531\n",
      "step:  6  objective:  -5.13148825877\n",
      "step:  7  objective:  -5.07230847416\n",
      "step:  8  objective:  -5.01302309613\n",
      "step:  9  objective:  -4.95363351725\n",
      "step:  10  objective:  -4.89414138008\n",
      "[    0  1371  1604  4381  7969  8930  9063 10343 12081 13859 14528 16075\n",
      " 16095 17666 19572 20855 21724 22448 22641 25205 30598 31571 32085 33935\n",
      " 37377 42004 44733 47811 48671 48872 49594 49826]\n",
      "0    50827\n",
      "1       32\n",
      "dtype: int64\n",
      "[[ 0.4859389  -0.13050772 -0.00331966  0.12379688 -0.23769095]]\n",
      "step:  11  objective:  -4.83454858918\n",
      "step:  12  objective:  -4.77485732329\n",
      "step:  13  objective:  -4.71507004736\n",
      "step:  14  objective:  -4.65518952461\n",
      "step:  15  objective:  -4.59521882837\n",
      "step:  16  objective:  -4.53516135376\n",
      "step:  17  objective:  -4.47502082921\n",
      "step:  18  objective:  -4.41480132746\n",
      "step:  19  objective:  -4.35450727643\n",
      "step:  20  objective:  -4.29414346942\n",
      "[    0  1371  1604  4381  7582  7969  8930 10343 12081 13859 14528 16075\n",
      " 16095 17666 19572 20855 21724 22448 22641 25205 30598 31571 32085 33935\n",
      " 37377 38271 42004 47811 48671 48872 49594 49826]\n",
      "0    50827\n",
      "1       32\n",
      "dtype: int64\n",
      "[[ 0.46604837 -0.12298819 -0.0153451   0.12514468 -0.23873751]]\n",
      "step:  21  objective:  -4.23371507486\n",
      "step:  22  objective:  -4.1732276455\n",
      "step:  23  objective:  -4.11268712683\n",
      "step:  24  objective:  -4.05209986476\n",
      "step:  25  objective:  -3.9914726124\n",
      "step:  26  objective:  -3.930812536\n",
      "step:  27  objective:  -3.87012721972\n",
      "step:  28  objective:  -3.80942466942\n",
      "step:  29  objective:  -3.74871331513\n",
      "step:  30  objective:  -3.6880020123\n",
      "[    0  1371  1604  4381  7582  7969  8298  8930  9063 10343 12081 13859\n",
      " 14528 16075 16095 17666 19572 20855 21724 22448 22641 22689 22828 25205\n",
      " 28380 30598 31571 32085 33935 37377 38271 39926 40163 40637 42004 45236\n",
      " 46385 47811 47842 48671 48872 49270 49594 49826 50793]\n",
      "0    50814\n",
      "1       45\n",
      "dtype: int64\n",
      "[[ 0.44569778 -0.11631679 -0.02735823  0.12644811 -0.23989018]]\n",
      "step:  31  objective:  -3.62730004166\n",
      "step:  32  objective:  -3.56661710766\n",
      "step:  33  objective:  -3.50596333534\n",
      "step:  34  objective:  -3.44534926565\n",
      "step:  35  objective:  -3.38478584903\n",
      "step:  36  objective:  -3.32428443742\n",
      "step:  37  objective:  -3.26385677433\n",
      "step:  38  objective:  -3.2035149832\n",
      "step:  39  objective:  -3.14327155389\n",
      "step:  40  objective:  -3.08313932727\n",
      "[    0    39  1371  1604  2018  2074  4381  4843  7091  7582  7969  8298\n",
      "  8583  8930  9063 10343 10610 11255 11825 12081 13374 13859 14528 15722\n",
      " 15811 16075 16095 16269 17666 19572 20855 21724 22448 22641 22689 22828\n",
      " 25205 27491 27719 28380 28709 29763 30598 31571 32085 33391 33935 34219\n",
      " 37377 38271 39926 40163 40637 40727 41752 41950 42004 43216 44733 44772\n",
      " 45236 45823 46385 47518 47811 47842 48671 48872 49270 49594 49826 50793]\n",
      "0    50787\n",
      "1       72\n",
      "dtype: int64\n",
      "[[ 0.42508087 -0.11041639 -0.03927299  0.12772091 -0.24112526]]\n",
      "step:  41  objective:  -3.02313147796\n",
      "step:  42  objective:  -2.96326149513\n",
      "step:  43  objective:  -2.9035431615\n",
      "step:  44  objective:  -2.84399053037\n",
      "step:  45  objective:  -2.78461790092\n",
      "step:  46  objective:  -2.72543979172\n",
      "step:  47  objective:  -2.66647091249\n",
      "step:  48  objective:  -2.60772613426\n",
      "step:  49  objective:  -2.54922045796\n",
      "step:  50  objective:  -2.49096898164\n",
      "[    0    39  1371  1604  1658  1776  2018  2074  2799  2969  3109  3171\n",
      "  3243  3570  4381  4526  4553  4843  5094  6330  6968  7091  7347  7582\n",
      "  7885  7969  8096  8298  8583  8930  9063  9744 10343 10610 11169 11255\n",
      " 11825 12081 12295 12420 12492 13177 13374 13608 13859 14528 14751 15722\n",
      " 15811 15917 16075 16095 16269 17666 17815 18078 19572 20201 20855 21343\n",
      " 21724 21963 22327 22448 22641 22689 22828 23519 25143 25205 25553 26072\n",
      " 26127 26707 26852 27190 27244 27491 27504 27719 27855 28380 28709 29063\n",
      " 29374 29423 29763 30114 30426 30598 31137 31556 31571 32085 32367 33391\n",
      " 33665 33935 34219 34280 34743 34977 35474 35749 36353 36824 37377 38271\n",
      " 39055 39926 40163 40637 40727 40891 41178 41452 41752 41888 41950 42004\n",
      " 42583 42808 43216 43293 44202 44422 44733 44772 45236 45823 46196 46385\n",
      " 47518 47811 47842 47915 48298 48414 48671 48872 49213 49270 49594 49826\n",
      " 50419 50480 50793]\n",
      "0    50712\n",
      "1      147\n",
      "dtype: int64\n",
      "[[ 0.40447867 -0.1051478  -0.05098544  0.12898361 -0.24240762]]\n",
      "step:  51  objective:  -2.43298686626\n",
      "step:  52  objective:  -2.37528930041\n",
      "step:  53  objective:  -2.31789146388\n",
      "step:  54  objective:  -2.26080849041\n",
      "step:  55  objective:  -2.20405542968\n",
      "step:  56  objective:  -2.14764720876\n",
      "step:  57  objective:  -2.09159859315\n",
      "step:  58  objective:  -2.03592414772\n",
      "step:  59  objective:  -1.98063819756\n",
      "step:  60  objective:  -1.92575478912\n",
      "[    0    39   605   809   843  1071  1124  1182  1371  1505  1513  1546\n",
      "  1604  1658  1776  1834  2018  2074  2198  2580  2691  2799  2956  2969\n",
      "  3109  3171  3243  3570  4153  4167  4381  4526  4553  4843  5094  5209\n",
      "  5732  6330  6968  7007  7091  7279  7347  7496  7582  7885  7969  7983\n",
      "  8096  8257  8298  8319  8583  8667  8895  8930  9063  9232  9744  9767\n",
      "  9957 10288 10343 10427 10610 10748 11019 11132 11169 11255 11825 12081\n",
      " 12162 12217 12295 12420 12492 12730 13177 13374 13608 13859 13884 13916\n",
      " 14528 14751 14844 15394 15722 15811 15917 15945 16075 16095 16156 16189\n",
      " 16232 16269 16477 17666 17815 18078 18150 18342 18426 18595 18762 19043\n",
      " 19572 20201 20855 20969 21343 21623 21724 21840 21946 21963 22327 22448\n",
      " 22641 22689 22800 22828 23295 23519 23616 23679 24344 24389 24998 25143\n",
      " 25205 25553 26072 26127 26260 26327 26545 26707 26852 27115 27190 27244\n",
      " 27491 27504 27719 27855 27926 28082 28133 28341 28380 28402 28699 28709\n",
      " 29063 29263 29305 29321 29374 29423 29532 29587 29645 29763 30046 30114\n",
      " 30426 30576 30598 31016 31063 31137 31556 31571 31751 31828 32085 32367\n",
      " 32375 33391 33665 33732 33788 33935 33977 34070 34219 34280 34743 34763\n",
      " 34920 34977 35474 35598 35621 35749 36353 36552 36824 37377 37526 37695\n",
      " 37723 38271 38543 38674 39055 39338 39475 39554 39926 40163 40574 40637\n",
      " 40727 40891 41125 41178 41452 41469 41689 41752 41825 41888 41950 42004\n",
      " 42583 42808 42869 43187 43216 43293 43413 44202 44257 44267 44355 44422\n",
      " 44539 44578 44733 44772 45013 45236 45408 45823 46196 46385 46443 47138\n",
      " 47140 47334 47443 47518 47811 47842 47915 48298 48356 48414 48671 48864\n",
      " 48872 49213 49270 49342 49594 49653 49826 50165 50419 50480 50793]\n",
      "0    50584\n",
      "1      275\n",
      "dtype: int64\n",
      "[[ 0.38424257 -0.10031702 -0.06238323  0.13026187 -0.24369311]]\n",
      "step:  61  objective:  -1.8712876517\n",
      "step:  62  objective:  -1.81725015955\n",
      "step:  63  objective:  -1.76365529483\n",
      "step:  64  objective:  -1.71051561149\n",
      "step:  65  objective:  -1.65784320035\n",
      "step:  66  objective:  -1.60564965558\n",
      "step:  67  objective:  -1.5539460427\n",
      "step:  68  objective:  -1.50274286827\n",
      "step:  69  objective:  -1.45205005141\n",
      "step:  70  objective:  -1.4018768974\n",
      "[    0    39   214   309   560   605   724   809   843  1071  1123  1124\n",
      "  1149  1182  1202  1371  1505  1513  1546  1604  1658  1765  1776  1790\n",
      "  1834  2018  2074  2198  2335  2454  2580  2629  2691  2799  2956  2969\n",
      "  2982  3109  3171  3243  3350  3560  3570  3593  3775  3836  4140  4153\n",
      "  4167  4381  4408  4526  4553  4763  4843  5050  5094  5095  5209  5620\n",
      "  5650  5732  5788  6260  6330  6410  6968  7007  7091  7198  7279  7347\n",
      "  7496  7582  7652  7885  7969  7983  8096  8257  8298  8319  8583  8667\n",
      "  8812  8895  8930  9063  9232  9300  9744  9767  9957 10288 10343 10427\n",
      " 10452 10555 10610 10748 10913 10977 11019 11117 11132 11169 11255 11554\n",
      " 11600 11825 11955 12081 12133 12162 12217 12295 12309 12331 12420 12474\n",
      " 12492 12730 13038 13177 13374 13570 13594 13608 13703 13859 13884 13916\n",
      " 14122 14528 14670 14751 14844 14890 15329 15394 15722 15811 15917 15945\n",
      " 16075 16095 16156 16189 16232 16269 16477 16529 17350 17394 17486 17620\n",
      " 17666 17815 18003 18078 18150 18177 18342 18412 18426 18595 18762 18851\n",
      " 19043 19447 19572 19691 20130 20201 20221 20234 20279 20308 20633 20855\n",
      " 20969 20983 21343 21623 21724 21830 21840 21946 21963 22327 22448 22495\n",
      " 22622 22641 22689 22800 22828 23006 23245 23295 23330 23519 23616 23679\n",
      " 23735 23800 24344 24369 24389 24590 24970 24998 25143 25205 25302 25337\n",
      " 25553 25654 25792 25953 26072 26127 26260 26327 26545 26691 26707 26825\n",
      " 26852 27115 27190 27244 27330 27434 27491 27504 27719 27855 27926 28082\n",
      " 28133 28169 28182 28332 28341 28380 28402 28444 28457 28553 28699 28709\n",
      " 28931 29063 29263 29305 29321 29374 29423 29532 29567 29587 29645 29763\n",
      " 29820 30046 30114 30161 30211 30426 30542 30576 30598 30986 31016 31063\n",
      " 31137 31556 31571 31751 31828 32085 32091 32144 32265 32367 32375 32533\n",
      " 33391 33632 33665 33732 33788 33812 33935 33977 34070 34219 34280 34615\n",
      " 34713 34743 34763 34920 34962 34977 35132 35184 35305 35474 35598 35621\n",
      " 35749 36297 36353 36552 36611 36714 36824 37200 37377 37467 37526 37695\n",
      " 37723 38028 38271 38543 38674 39055 39338 39461 39475 39554 39813 39926\n",
      " 40163 40215 40230 40574 40637 40727 40891 41125 41178 41272 41309 41452\n",
      " 41469 41689 41752 41825 41888 41950 42004 42057 42296 42395 42583 42808\n",
      " 42869 42885 43045 43187 43216 43227 43293 43324 43413 43950 44141 44202\n",
      " 44257 44267 44355 44422 44539 44567 44578 44646 44733 44772 45013 45236\n",
      " 45299 45408 45440 45485 45738 45823 45832 46174 46196 46385 46443 46969\n",
      " 47138 47140 47334 47443 47508 47518 47644 47811 47842 47915 48298 48304\n",
      " 48356 48414 48671 48841 48864 48872 49213 49270 49342 49594 49653 49826\n",
      " 49911 50165 50419 50480 50761 50793]\n",
      "0    50433\n",
      "1      426\n",
      "dtype: int64\n",
      "[[ 0.36475271 -0.09569685 -0.07336027  0.1315835  -0.24493365]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:  71  objective:  -1.35223207331\n",
      "step:  72  objective:  -1.30312358589\n",
      "step:  73  objective:  -1.25455876179\n",
      "step:  74  objective:  -1.20654423017\n",
      "step:  75  objective:  -1.15908590782\n",
      "step:  76  objective:  -1.1121889867\n",
      "step:  77  objective:  -1.06585792412\n",
      "step:  78  objective:  -1.02009643541\n",
      "step:  79  objective:  -0.974907489123\n",
      "step:  80  objective:  -0.930293304811\n",
      "[    0    39   214   292   309   322   560   588   605   724   795   809\n",
      "   843   877  1071  1123  1124  1135  1149  1182  1202  1310  1371  1409\n",
      "  1468  1505  1513  1546  1604  1638  1658  1765  1776  1790  1834  1927\n",
      "  1956  2018  2074  2183  2198  2335  2454  2580  2603  2629  2691  2799\n",
      "  2956  2969  2982  3109  3171  3243  3350  3394  3560  3570  3593  3686\n",
      "  3775  3836  4049  4069  4140  4153  4167  4230  4381  4408  4480  4526\n",
      "  4553  4630  4763  4843  5050  5094  5095  5175  5209  5482  5620  5650\n",
      "  5669  5732  5788  5939  5979  6094  6260  6330  6350  6410  6531  6676\n",
      "  6850  6968  7007  7082  7091  7198  7243  7279  7347  7360  7444  7496\n",
      "  7582  7652  7885  7969  7983  8096  8257  8284  8298  8319  8382  8424\n",
      "  8534  8583  8652  8667  8812  8895  8915  8930  9063  9204  9232  9300\n",
      "  9410  9744  9767  9957 10245 10288 10343 10427 10452 10555 10590 10610\n",
      " 10748 10785 10913 10935 10977 11019 11077 11117 11132 11169 11255 11460\n",
      " 11540 11554 11600 11825 11955 12081 12133 12162 12217 12232 12252 12295\n",
      " 12309 12331 12420 12474 12492 12730 13038 13177 13256 13304 13374 13396\n",
      " 13459 13570 13594 13608 13703 13731 13743 13859 13884 13916 14110 14122\n",
      " 14275 14361 14435 14528 14670 14751 14817 14844 14877 14890 14990 15062\n",
      " 15318 15329 15394 15507 15623 15659 15722 15811 15833 15917 15945 16075\n",
      " 16095 16156 16189 16232 16269 16444 16477 16529 16602 16973 17350 17394\n",
      " 17486 17620 17666 17815 18003 18031 18046 18078 18150 18163 18177 18235\n",
      " 18342 18412 18426 18595 18676 18762 18851 18879 18917 18981 18996 19043\n",
      " 19052 19094 19319 19447 19572 19691 20000 20008 20081 20130 20201 20221\n",
      " 20234 20264 20279 20308 20633 20723 20731 20855 20969 20983 21218 21343\n",
      " 21623 21724 21830 21840 21946 21963 22303 22327 22448 22462 22495 22550\n",
      " 22622 22641 22689 22800 22828 22939 23006 23192 23245 23295 23330 23404\n",
      " 23519 23555 23616 23679 23735 23800 24046 24344 24369 24389 24590 24675\n",
      " 24947 24967 24970 24998 25090 25104 25143 25205 25302 25329 25337 25353\n",
      " 25444 25553 25654 25792 25939 25953 26013 26032 26072 26127 26191 26260\n",
      " 26327 26545 26691 26707 26825 26852 26924 26958 27115 27190 27244 27268\n",
      " 27330 27377 27434 27491 27504 27596 27690 27719 27855 27926 27939 28082\n",
      " 28133 28169 28182 28229 28332 28341 28380 28391 28402 28444 28457 28553\n",
      " 28699 28709 28840 28931 29063 29263 29305 29321 29374 29423 29532 29567\n",
      " 29587 29637 29645 29763 29820 30046 30114 30161 30211 30426 30526 30542\n",
      " 30576 30598 30986 31006 31016 31063 31137 31167 31556 31571 31751 31828\n",
      " 32085 32091 32144 32165 32265 32348 32367 32375 32404 32441 32533 32548\n",
      " 32611 32763 32824 32929 33102 33287 33341 33391 33459 33632 33665 33732\n",
      " 33788 33803 33812 33935 33977 34070 34166 34219 34231 34280 34460 34496\n",
      " 34528 34615 34713 34743 34763 34886 34920 34962 34977 34983 35132 35144\n",
      " 35184 35305 35323 35442 35474 35598 35621 35749 36065 36194 36297 36353\n",
      " 36507 36552 36611 36714 36824 37139 37200 37377 37442 37467 37474 37526\n",
      " 37695 37723 38028 38054 38146 38271 38463 38543 38665 38674 38724 38784\n",
      " 38810 38853 38949 39055 39338 39461 39475 39488 39504 39554 39605 39813\n",
      " 39858 39926 40163 40215 40230 40302 40342 40353 40495 40574 40637 40727\n",
      " 40739 40768 40891 41113 41125 41178 41258 41272 41309 41452 41469 41509\n",
      " 41689 41752 41825 41888 41908 41950 42004 42057 42296 42395 42583 42630\n",
      " 42732 42771 42808 42869 42885 42897 42919 43008 43045 43148 43187 43216\n",
      " 43227 43293 43302 43324 43413 43544 43599 43950 43974 44141 44202 44257\n",
      " 44267 44276 44355 44422 44539 44567 44578 44646 44733 44772 45013 45029\n",
      " 45042 45236 45299 45408 45440 45459 45485 45682 45738 45823 45832 45858\n",
      " 46070 46174 46196 46385 46443 46700 46927 46969 47014 47095 47138 47140\n",
      " 47176 47273 47334 47443 47508 47518 47605 47644 47811 47842 47858 47915\n",
      " 48012 48298 48304 48356 48414 48671 48841 48864 48872 48887 49021 49085\n",
      " 49213 49270 49342 49362 49594 49605 49653 49715 49826 49911 49938 50143\n",
      " 50165 50205 50419 50480 50749 50761 50793]\n",
      "0    50216\n",
      "1      643\n",
      "dtype: int64\n",
      "[[ 0.34635755 -0.09105877 -0.08383285  0.13297469 -0.24608415]]\n",
      "step:  81  objective:  -0.886255353242\n",
      "step:  82  objective:  -0.842794359055\n",
      "step:  83  objective:  -0.799910305777\n",
      "step:  84  objective:  -0.757602443108\n",
      "step:  85  objective:  -0.715869296393\n",
      "step:  86  objective:  -0.674708678157\n",
      "step:  87  objective:  -0.634117701596\n",
      "step:  88  objective:  -0.594092795884\n",
      "step:  89  objective:  -0.554629723172\n",
      "step:  90  objective:  -0.515723597114\n",
      "[    0    39    65    77   135   214   292   309   322   560   588   605\n",
      "   715   724   795   809   843   877   943  1071  1123  1124  1135  1149\n",
      "  1182  1202  1310  1371  1409  1468  1497  1505  1513  1534  1546  1604\n",
      "  1638  1658  1737  1765  1776  1790  1834  1927  1956  2018  2074  2111\n",
      "  2183  2198  2227  2335  2454  2528  2580  2603  2615  2629  2691  2799\n",
      "  2956  2969  2982  2989  3109  3171  3243  3350  3383  3394  3476  3494\n",
      "  3560  3570  3593  3686  3775  3836  4049  4069  4140  4153  4167  4230\n",
      "  4381  4408  4480  4526  4553  4613  4630  4763  4843  5050  5094  5095\n",
      "  5175  5209  5482  5620  5650  5669  5722  5732  5765  5788  5910  5939\n",
      "  5979  6094  6171  6212  6260  6330  6350  6403  6410  6531  6676  6716\n",
      "  6850  6968  7007  7082  7091  7198  7243  7279  7302  7320  7347  7360\n",
      "  7444  7496  7582  7602  7652  7764  7885  7902  7969  7983  8096  8257\n",
      "  8284  8298  8319  8382  8424  8475  8534  8583  8652  8667  8736  8812\n",
      "  8895  8915  8930  9063  9112  9149  9174  9204  9232  9300  9410  9656\n",
      "  9744  9767  9903  9919  9957 10083 10176 10216 10245 10288 10343 10427\n",
      " 10452 10555 10590 10610 10748 10785 10896 10913 10935 10977 11019 11077\n",
      " 11117 11132 11169 11255 11320 11364 11401 11460 11540 11554 11600 11741\n",
      " 11825 11955 12081 12133 12150 12162 12217 12232 12252 12295 12309 12331\n",
      " 12420 12474 12492 12543 12730 12996 13038 13177 13185 13192 13256 13304\n",
      " 13340 13374 13388 13396 13459 13467 13570 13594 13608 13703 13731 13743\n",
      " 13859 13884 13916 14027 14110 14122 14155 14225 14275 14361 14382 14435\n",
      " 14528 14586 14670 14736 14751 14817 14844 14877 14890 14990 15021 15062\n",
      " 15318 15329 15394 15507 15609 15623 15659 15722 15811 15833 15865 15917\n",
      " 15945 16075 16095 16156 16189 16212 16232 16269 16372 16444 16477 16529\n",
      " 16602 16779 16801 16933 16973 17350 17394 17486 17620 17666 17765 17815\n",
      " 17945 18003 18031 18046 18063 18078 18093 18150 18163 18177 18235 18342\n",
      " 18412 18426 18560 18595 18676 18762 18851 18879 18917 18981 18996 19043\n",
      " 19052 19094 19224 19319 19366 19447 19538 19572 19691 19705 19731 20000\n",
      " 20008 20081 20130 20201 20221 20234 20264 20279 20308 20368 20633 20673\n",
      " 20723 20731 20855 20969 20983 21180 21218 21343 21565 21623 21724 21830\n",
      " 21840 21946 21963 22120 22208 22303 22315 22327 22448 22462 22495 22513\n",
      " 22550 22622 22641 22689 22800 22828 22939 23006 23060 23192 23207 23245\n",
      " 23280 23295 23330 23404 23519 23555 23616 23640 23679 23735 23800 24046\n",
      " 24245 24344 24369 24389 24590 24675 24947 24967 24970 24998 25090 25104\n",
      " 25124 25143 25205 25302 25329 25337 25353 25444 25451 25479 25553 25654\n",
      " 25792 25919 25939 25953 26013 26032 26052 26072 26080 26127 26191 26260\n",
      " 26327 26545 26691 26707 26721 26825 26852 26924 26944 26958 27115 27190\n",
      " 27244 27268 27330 27377 27434 27491 27504 27596 27616 27690 27719 27855\n",
      " 27910 27926 27939 28082 28108 28133 28169 28182 28229 28325 28332 28341\n",
      " 28380 28391 28402 28444 28457 28553 28652 28699 28709 28742 28840 28931\n",
      " 29063 29085 29218 29263 29305 29321 29374 29408 29423 29532 29567 29587\n",
      " 29637 29645 29763 29803 29820 29939 29969 30046 30114 30161 30211 30231\n",
      " 30347 30426 30526 30542 30576 30598 30851 30865 30986 31006 31016 31042\n",
      " 31043 31063 31137 31167 31325 31498 31556 31571 31597 31751 31828 31854\n",
      " 31874 31937 32062 32085 32091 32144 32165 32222 32265 32348 32367 32375\n",
      " 32404 32441 32533 32548 32611 32763 32824 32929 33102 33287 33341 33391\n",
      " 33459 33542 33632 33665 33732 33788 33803 33812 33935 33977 34070 34166\n",
      " 34187 34219 34231 34280 34323 34365 34460 34496 34528 34572 34615 34648\n",
      " 34713 34743 34763 34886 34920 34956 34962 34977 34983 35072 35132 35144\n",
      " 35184 35305 35323 35362 35442 35474 35561 35598 35621 35680 35714 35734\n",
      " 35749 35805 36065 36166 36194 36297 36353 36397 36507 36552 36611 36714\n",
      " 36824 36946 36966 37069 37113 37139 37200 37220 37377 37442 37467 37474\n",
      " 37526 37670 37695 37723 37968 38011 38028 38054 38132 38146 38271 38382\n",
      " 38463 38543 38665 38670 38674 38724 38784 38810 38853 38940 38949 39043\n",
      " 39055 39113 39338 39461 39475 39488 39504 39554 39605 39783 39813 39858\n",
      " 39926 40163 40215 40230 40302 40342 40353 40475 40495 40574 40637 40727\n",
      " 40739 40768 40832 40891 40953 41113 41125 41178 41258 41272 41309 41452\n",
      " 41469 41509 41689 41752 41825 41888 41908 41950 42004 42057 42091 42296\n",
      " 42395 42455 42524 42583 42630 42732 42771 42808 42869 42885 42897 42919\n",
      " 43008 43045 43148 43187 43216 43227 43267 43293 43302 43324 43413 43544\n",
      " 43599 43885 43950 43961 43974 44085 44141 44202 44257 44267 44276 44311\n",
      " 44355 44422 44482 44539 44567 44578 44610 44646 44719 44733 44772 45013\n",
      " 45029 45042 45236 45299 45408 45440 45459 45485 45566 45626 45682 45738\n",
      " 45790 45823 45832 45858 46070 46104 46138 46174 46196 46385 46443 46700\n",
      " 46801 46916 46927 46969 47014 47059 47088 47095 47138 47140 47176 47273\n",
      " 47334 47443 47508 47518 47605 47644 47811 47826 47842 47858 47878 47915\n",
      " 48012 48043 48298 48304 48356 48414 48558 48671 48829 48841 48864 48872\n",
      " 48887 49021 49085 49213 49270 49296 49342 49362 49379 49451 49594 49605\n",
      " 49653 49715 49749 49826 49911 49938 50143 50165 50205 50418 50419 50432\n",
      " 50480 50749 50761 50793]\n",
      "0    50027\n",
      "1      832\n",
      "dtype: int64\n",
      "[[ 0.32931035 -0.08620552 -0.09375161  0.13445704 -0.2471088 ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:  91  objective:  -0.477368902784\n",
      "step:  92  objective:  -0.439559517808\n",
      "step:  93  objective:  -0.402288734566\n",
      "step:  94  objective:  -0.365549283279\n",
      "step:  95  objective:  -0.329333355816\n",
      "step:  96  objective:  -0.293632630056\n",
      "step:  97  objective:  -0.258438294611\n",
      "step:  98  objective:  -0.223741073759\n",
      "step:  99  objective:  -0.189531252384\n",
      "step:  100  objective:  -0.155798700774\n",
      "[    0    39    65    77   135   214   292   309   322   399   560   588\n",
      "   605   715   724   795   809   828   843   877   943  1071  1123  1124\n",
      "  1135  1149  1182  1202  1310  1371  1409  1448  1468  1497  1505  1513\n",
      "  1534  1546  1604  1638  1658  1695  1737  1765  1776  1790  1834  1927\n",
      "  1956  2018  2074  2094  2111  2156  2183  2198  2227  2335  2454  2528\n",
      "  2580  2603  2615  2629  2691  2715  2799  2956  2969  2982  2989  3109\n",
      "  3171  3243  3263  3265  3350  3383  3394  3476  3494  3560  3570  3593\n",
      "  3686  3775  3809  3836  4049  4069  4140  4153  4167  4230  4381  4408\n",
      "  4480  4526  4553  4573  4613  4630  4763  4843  4860  4937  5043  5050\n",
      "  5094  5095  5175  5209  5251  5439  5482  5620  5650  5669  5722  5732\n",
      "  5765  5788  5910  5939  5979  6034  6094  6171  6212  6260  6330  6350\n",
      "  6393  6403  6410  6531  6567  6615  6676  6716  6850  6968  7007  7082\n",
      "  7091  7130  7198  7243  7279  7302  7320  7347  7360  7374  7444  7456\n",
      "  7496  7582  7602  7652  7764  7885  7902  7969  7983  8096  8136  8257\n",
      "  8284  8298  8319  8366  8382  8424  8475  8534  8583  8652  8667  8736\n",
      "  8760  8802  8812  8858  8895  8915  8930  9043  9063  9112  9149  9174\n",
      "  9204  9232  9286  9300  9410  9656  9682  9736  9744  9767  9826  9903\n",
      "  9919  9957 10083 10176 10216 10245 10288 10343 10427 10452 10555 10590\n",
      " 10610 10741 10748 10785 10896 10913 10935 10977 11019 11077 11117 11132\n",
      " 11169 11226 11255 11320 11364 11401 11451 11460 11540 11554 11600 11741\n",
      " 11825 11955 12081 12133 12150 12162 12217 12232 12252 12295 12309 12331\n",
      " 12420 12474 12492 12543 12730 12996 13038 13177 13185 13192 13256 13276\n",
      " 13304 13340 13374 13388 13396 13459 13467 13522 13570 13594 13608 13703\n",
      " 13731 13743 13859 13884 13916 14027 14110 14122 14155 14225 14275 14361\n",
      " 14382 14435 14528 14586 14670 14736 14751 14817 14844 14877 14890 14990\n",
      " 15021 15050 15062 15256 15318 15329 15367 15394 15507 15609 15623 15659\n",
      " 15722 15811 15833 15865 15917 15945 16075 16095 16156 16189 16212 16232\n",
      " 16269 16372 16444 16477 16529 16602 16779 16801 16933 16973 17350 17394\n",
      " 17486 17620 17666 17765 17815 17945 18003 18031 18046 18063 18078 18093\n",
      " 18150 18163 18177 18235 18342 18412 18426 18560 18595 18676 18762 18851\n",
      " 18879 18917 18981 18996 19023 19043 19052 19094 19122 19224 19319 19366\n",
      " 19447 19538 19572 19691 19705 19731 19986 20000 20008 20062 20081 20130\n",
      " 20201 20221 20234 20264 20279 20308 20368 20633 20673 20723 20731 20791\n",
      " 20855 20869 20969 20983 21092 21165 21180 21218 21343 21565 21623 21724\n",
      " 21830 21840 21946 21963 22087 22120 22208 22303 22315 22327 22421 22448\n",
      " 22462 22495 22513 22550 22622 22641 22689 22714 22800 22828 22939 23006\n",
      " 23060 23192 23207 23236 23245 23280 23295 23330 23372 23391 23404 23519\n",
      " 23555 23616 23640 23679 23735 23800 23825 23870 24046 24130 24144 24245\n",
      " 24304 24344 24369 24389 24590 24604 24675 24715 24947 24967 24970 24998\n",
      " 25090 25104 25124 25143 25205 25302 25329 25337 25353 25444 25451 25479\n",
      " 25553 25615 25654 25706 25755 25792 25828 25919 25939 25953 25968 26013\n",
      " 26032 26052 26072 26080 26118 26127 26191 26260 26327 26429 26545 26691\n",
      " 26707 26721 26825 26852 26924 26944 26958 26964 27115 27190 27244 27268\n",
      " 27330 27377 27434 27471 27491 27504 27596 27616 27690 27709 27719 27855\n",
      " 27910 27926 27939 28082 28108 28133 28169 28182 28229 28325 28332 28341\n",
      " 28380 28391 28402 28444 28457 28495 28553 28652 28699 28709 28742 28840\n",
      " 28931 29063 29085 29129 29218 29263 29305 29321 29374 29408 29423 29532\n",
      " 29567 29587 29637 29645 29763 29803 29820 29939 29969 30046 30114 30161\n",
      " 30191 30211 30231 30264 30331 30347 30426 30526 30542 30576 30598 30851\n",
      " 30865 30922 30986 31006 31016 31032 31042 31043 31063 31137 31167 31325\n",
      " 31498 31556 31571 31597 31751 31828 31854 31874 31937 32062 32085 32091\n",
      " 32144 32165 32222 32265 32348 32367 32375 32404 32441 32503 32533 32548\n",
      " 32611 32628 32763 32779 32824 32833 32929 33102 33287 33341 33391 33422\n",
      " 33459 33542 33632 33665 33732 33788 33803 33812 33935 33977 34070 34166\n",
      " 34187 34219 34231 34260 34280 34323 34365 34460 34496 34528 34572 34615\n",
      " 34648 34702 34713 34743 34763 34886 34920 34956 34962 34977 34983 35072\n",
      " 35132 35144 35184 35190 35213 35264 35305 35323 35362 35442 35474 35500\n",
      " 35561 35598 35621 35660 35680 35714 35734 35749 35805 36065 36166 36194\n",
      " 36297 36353 36397 36428 36474 36507 36552 36611 36659 36714 36813 36824\n",
      " 36848 36946 36966 37069 37084 37113 37139 37200 37220 37377 37442 37467\n",
      " 37474 37526 37670 37695 37723 37913 37941 37968 38011 38028 38054 38132\n",
      " 38146 38271 38382 38463 38473 38543 38665 38670 38674 38724 38784 38810\n",
      " 38853 38940 38949 38965 39043 39055 39113 39338 39390 39461 39475 39488\n",
      " 39504 39554 39605 39677 39718 39783 39813 39858 39926 40091 40163 40215\n",
      " 40230 40302 40342 40353 40475 40495 40551 40574 40637 40727 40739 40768\n",
      " 40832 40891 40953 41113 41125 41178 41258 41272 41309 41452 41469 41509\n",
      " 41689 41752 41825 41888 41908 41943 41950 42004 42057 42091 42296 42395\n",
      " 42455 42524 42583 42630 42732 42771 42808 42869 42885 42897 42919 43008\n",
      " 43045 43148 43187 43216 43227 43267 43293 43302 43324 43333 43358 43413\n",
      " 43455 43544 43599 43885 43950 43961 43974 44072 44085 44141 44202 44257\n",
      " 44267 44276 44311 44355 44422 44482 44522 44539 44567 44578 44610 44646\n",
      " 44719 44733 44772 45013 45029 45042 45112 45131 45236 45299 45408 45440\n",
      " 45459 45485 45514 45566 45626 45682 45738 45790 45823 45832 45858 46070\n",
      " 46104 46138 46174 46196 46249 46385 46397 46443 46569 46700 46801 46884\n",
      " 46916 46927 46969 47014 47059 47070 47088 47095 47138 47140 47176 47273\n",
      " 47317 47334 47443 47508 47518 47605 47615 47644 47696 47811 47826 47842\n",
      " 47858 47878 47915 48012 48043 48238 48298 48304 48356 48414 48530 48556\n",
      " 48558 48671 48829 48841 48864 48872 48887 48902 48953 49021 49085 49213\n",
      " 49270 49296 49342 49362 49379 49451 49594 49605 49653 49715 49749 49826\n",
      " 49911 49938 50143 50165 50205 50418 50419 50432 50480 50629 50749 50761\n",
      " 50793]\n",
      "0    49898\n",
      "1      961\n",
      "dtype: int64\n",
      "[[ 0.31371997 -0.08099454 -0.10310479  0.13604638 -0.24798496]]\n",
      "step:  101  objective:  -0.122532899081\n",
      "step:  102  objective:  -0.0897229612809\n",
      "step:  103  objective:  -0.0573576584496\n",
      "step:  104  objective:  -0.0254254411941\n",
      "step:  105  objective:  0.0060855389451\n",
      "step:  106  objective:  0.0371874092884\n",
      "step:  107  objective:  0.0678925571835\n",
      "step:  108  objective:  0.0982136127199\n",
      "step:  109  objective:  0.128163433172\n",
      "step:  110  objective:  0.157755089352\n",
      "[    0    39    77 ..., 50749 50761 50793]\n",
      "0    49821\n",
      "1     1038\n",
      "dtype: int64\n",
      "[[ 0.2995249  -0.0753474  -0.11191206  0.13775346 -0.24870359]]\n",
      "step:  111  objective:  0.187001854073\n",
      "step:  112  objective:  0.215917192909\n",
      "step:  113  objective:  0.244514757484\n",
      "step:  114  objective:  0.2728083815\n",
      "step:  115  objective:  0.300812079772\n",
      "step:  116  objective:  0.328540050542\n",
      "step:  117  objective:  0.356006681371\n",
      "step:  118  objective:  0.383226558972\n",
      "step:  119  objective:  0.410214483374\n",
      "step:  120  objective:  0.436985486877\n",
      "[    0    39    77 ..., 50749 50761 50793]\n",
      "0    49807\n",
      "1     1052\n",
      "dtype: int64\n",
      "[[ 0.28648503 -0.06924818 -0.12021171  0.13958586 -0.24926708]]\n",
      "step:  121  objective:  0.463554858328\n",
      "step:  122  objective:  0.489938173336\n",
      "step:  123  objective:  0.516151331163\n",
      "step:  124  objective:  0.542210599142\n",
      "step:  125  objective:  0.568132665659\n",
      "step:  126  objective:  0.593934702901\n",
      "step:  127  objective:  0.619634440869\n",
      "step:  128  objective:  0.645250254387\n",
      "step:  129  objective:  0.670801265279\n",
      "step:  130  objective:  0.696307462281\n",
      "[    0    39    77 ..., 50749 50761 50793]\n",
      "0    49821\n",
      "1     1038\n",
      "dtype: int64\n",
      "[[ 0.27416435 -0.06273922 -0.12804527  0.14155062 -0.24968619]]\n",
      "step:  131  objective:  0.7217898419\n",
      "step:  132  objective:  0.747270574072\n",
      "step:  133  objective:  0.772773197454\n",
      "step:  134  objective:  0.798322850285\n",
      "step:  135  objective:  0.823946544235\n",
      "step:  136  objective:  0.84967349053\n",
      "step:  137  objective:  0.875535490099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:  138  objective:  0.90156740261\n",
      "step:  139  objective:  0.927807713455\n",
      "step:  140  objective:  0.954299223211\n",
      "[    0    39    77 ..., 50749 50761 50793]\n",
      "0    49845\n",
      "1     1014\n",
      "dtype: int64\n",
      "[[ 0.26183244 -0.05593105 -0.13544109  0.14365823 -0.24997858]]\n",
      "step:  141  objective:  0.981089891449\n",
      "step:  142  objective:  1.00823387666\n",
      "step:  143  objective:  1.03579282749\n",
      "step:  144  objective:  1.06383749909\n",
      "step:  145  objective:  1.09244979409\n",
      "step:  146  objective:  1.12172536408\n",
      "step:  147  objective:  1.15177695961\n",
      "step:  148  objective:  1.18273879193\n",
      "step:  149  objective:  1.21477228065\n",
      "step:  150  objective:  1.24807372793\n",
      "[    0    39    77 ..., 50749 50761 50793]\n",
      "0    49858\n",
      "1     1001\n",
      "dtype: int64\n",
      "[[ 0.24802174 -0.04907467 -0.14239159  0.14593168 -0.25017466]]\n",
      "step:  151  objective:  1.28288471336\n",
      "step:  152  objective:  1.31950639912\n",
      "step:  153  objective:  1.35831956432\n",
      "step:  154  objective:  1.39981321582\n",
      "step:  155  objective:  1.4446263481\n",
      "step:  156  objective:  1.49361041189\n",
      "step:  157  objective:  1.54792540398\n",
      "step:  158  objective:  1.60919246692\n",
      "step:  159  objective:  1.67974533623\n",
      "step:  160  objective:  1.7630629061\n",
      "[    0    39    77 ..., 50749 50761 50793]\n",
      "0    49763\n",
      "1     1096\n",
      "dtype: int64\n",
      "[[ 0.22792604 -0.043015   -0.14878969  0.14844492 -0.25037038]]\n",
      "step:  161  objective:  1.86455230344\n",
      "step:  162  objective:  1.99305605518\n",
      "step:  163  objective:  2.16397868032\n",
      "step:  164  objective:  2.40640987139\n",
      "step:  165  objective:  2.78142604201\n",
      "step:  166  objective:  3.4372120166\n",
      "step:  167  objective:  4.81497965115\n",
      "step:  168  objective:  8.65860388872\n",
      "step:  169  objective:  19.6945767346\n",
      "step:  170  objective:  22.5751761233\n",
      "[    0     1    39 ..., 50794 50824 50844]\n",
      "0    48116\n",
      "1     2743\n",
      "dtype: int64\n",
      "[[ 0.14031035 -0.05233169 -0.13989529  0.16194421 -0.2523908 ]]\n",
      "step:  171  objective:  25.7836492233\n",
      "step:  172  objective:  11.3676918526\n",
      "step:  173  objective:  27.4252581264\n",
      "step:  174  objective:  -0.00809383078657\n",
      "step:  175  objective:  0.0311107753981\n",
      "step:  176  objective:  0.0699171725871\n",
      "step:  177  objective:  0.10833453258\n",
      "step:  178  objective:  0.146372731566\n",
      "step:  179  objective:  0.184042351694\n",
      "step:  180  objective:  0.221354684862\n",
      "[16075 16095 17666 19572]\n",
      "0    50855\n",
      "1        4\n",
      "dtype: int64\n",
      "[[ 0.2926058  -0.03875832 -0.06623306  0.22285848 -0.25109814]]\n",
      "step:  181  objective:  0.258321739334\n",
      "step:  182  objective:  0.294956249835\n",
      "step:  183  objective:  0.33127169189\n",
      "step:  184  objective:  0.367282301266\n",
      "step:  185  objective:  0.403003099491\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1172-3d165c702533>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mw\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mobjs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/autograd/wrap_util.py\u001b[0m in \u001b[0;36mnary_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0munary_operator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munary_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mnary_op_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnary_op_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnary_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnary_operator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/autograd/differential_operators.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(fun, x)\u001b[0m\n\u001b[1;32m     26\u001b[0m         raise TypeError(\"Grad only applies to real scalar-output functions. \"\n\u001b[1;32m     27\u001b[0m                         \"Try jacobian or elementwise_grad.\")\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0munary_to_nary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/autograd/core.py\u001b[0m in \u001b[0;36mvjp\u001b[0;34m(g)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mvspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mdef\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mbackward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/autograd/core.py\u001b[0m in \u001b[0;36mbackward_pass\u001b[0;34m(g, end_node)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtoposort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0moutgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutgrads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mingrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mingrad\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mingrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0moutgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_outgrads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutgrads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mingrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/autograd/core.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(g)\u001b[0m\n\u001b[1;32m     59\u001b[0m                     \"VJP of {} wrt argnum 0 not defined\".format(fun.__name__))\n\u001b[1;32m     60\u001b[0m             \u001b[0mvjp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvjpfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mL\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0margnum_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margnum_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margnums\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/autograd/numpy/numpy_vjps.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(g)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mSparseObject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmut_add\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m \u001b[0mdefvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mArrayBox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0muntake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0mdefvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muntake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/autograd/core.py\u001b[0m in \u001b[0;36mvspace\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0mVSpace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmappings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalue_type\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mvspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mVSpace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmappings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.random.seed(7)\n",
    "lr = 0.0001\n",
    "w = np.random.normal(scale=0.3, size=(1, 5))\n",
    "grad_obj = grad(objective)\n",
    "objs = []\n",
    "\n",
    "for i in range(1000):\n",
    "    gradient = grad_obj(w)\n",
    "    w += lr * gradient\n",
    "    objs += [ objective(w) ]\n",
    "    print ('step: ', i, ' objective: ', objs[-1])\n",
    "    if i % 10 == 0 and i > 0:\n",
    "        actions = get_expert_actions(w)\n",
    "        print (np.where(np.array(actions) == 1)[0])\n",
    "        print ( pd.Series(actions).value_counts() )\n",
    "        print (w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probs = get_experts_action_probs(w, test_input.values)\n",
    "pi_e = probs * encoded_expert_k + (1 - probs) * encoded_expert_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3236,)"
      ]
     },
     "execution_count": 1117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where( probs < 0.5 )[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x14d937e10>]"
      ]
     },
     "execution_count": 1196,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xd4VGXC/vHvAyEBEnonhRB6lTIUBXtD1l2airoqCBL7\n7r66upZdt7iuLupafroqNgQREURwEQso1lVIAULonSQQkghJaCFlnt8fGffN8tLCnMyZmdyf68pl\npnDO7ZPkzuSZ55xjrLWIiEj4qON2ABERcZaKXUQkzKjYRUTCjIpdRCTMqNhFRMKMil1EJMyo2EVE\nwoyKXUQkzKjYRUTCTIS/GzDGxAMzgDaABaZZa5872b9p2bKlTUxM9HfXIiK1SlpaWoG1ttWpnud3\nsQPlwL3W2nRjTCMgzRizxFq77kT/IDExkdTUVAd2LSJSexhjdp7O8/yeirHW7rHWpvs+PwCsB2L9\n3a6IiJwZR+fYjTGJQH9guZPbFRGR0+dYsRtjYoD3gd9Ya4uP83iyMSbVGJOan5/v1G5FROQYjhS7\nMaYelaU+y1o7/3jPsdZOs9Z6rLWeVq1OOfcvIiJnyO9iN8YY4HVgvbX2H/5HEhERfzjxin0YcCNw\nkTFmle9jpAPbFRGRM+D3ckdr7beAcSCLiIg4QEeeiogEwJHSCv704Vr2Hyqt8X2p2EVEapjXa/nt\n3NW89f0OVmcX1vj+VOwiIjXsuc8389GaPTwwojsXdGtd4/tTsYuI1KAZ3+/guc83c/XAOJLPSwrI\nPlXsIiI15O0fdvLIwrVc2rMNj43pQ+Xq8JrnxEnARESkCmstL3yxhaeXbOLi7q158foBREYE7nW0\nil1ExEFHyyt4ZMFa5qRmMaZ/LH8f1zegpQ4qdhERx+QUHuGOWemszirkrgs7c+9lXQM2/VKVil1E\nxAGL1+zhwflrqPBaXr5hACN6t3Mti4pdRMQPBQeP8tdF61iwajdnxTfl2fH96Ngy2tVMKnYRkTPg\n9VrmpGbxxMcbOFxazq8v7sJdF3WmXl33Fxuq2EVEqikzp4hHFmaSvquQIR2b89iYPnRuHeN2rP9Q\nsYuInKZdPx7m6SUbWbhqN82jI3nq6rMYNyDWlTdIT0bFLiJyCnkHSvjnsq3MWr6TunUMd1zQidsu\n6ETj+vXcjnZcKnYRkRPI3n+YV77axpzULMorvIwfFM+vL+5K2yb13Y52Uip2EZFjbM0/yEtfbmXB\nyhyMgXED4rjt/E4kurza5XSp2EVEqDwNQPqu/bz+7XY+zswlKqION57dgeTzkmjXpIHb8apFxS4i\ntdrR8goWrd7D9H/vYE1OEY3rR3D7+Z2YNLwjLWOi3I53RhwpdmPMG8CVQJ61trcT2xQRqUl5xSW8\nvXwX7yzfScHBUjq3juGvo3szdkAsDSND+zWvU+mnAy8AMxzanoiI4yq8lq835TN7xS4+35CH11ou\n6taaicMSGd65ZdAtWzxTjhS7tfZrY0yiE9sSEXHa7sIjvJeaxXspWewuKqFFdCS3nNuR6wYlhMwb\notUR2n9viIicQHmFl2UbK1+df7kxD6+Fc7u05PdX9uSSHm0CfirdQApYsRtjkoFkgISEhEDtVkRq\nmR0Fh5iXls3ctCz2Fh+ldaMobr+gE+M9CSS0aOh2vIAIWLFba6cB0wA8Ho8N1H5FJPwVl5TxUcYe\n3k/LJnXnfoyBC7q24tFRCVzUvTURQXBirkDSVIyIhKTyCi/fbCng/bRslqzby9FyL51aRXP/iG6M\n6R8bcmvPneTUcsfZwAVAS2NMNvBHa+3rTmxbRKSqjbkHeD89mw9W5pB/4ChNG9Zj/KB4xg2Io29c\nk7BZ2eIPp1bFXOfEdkREjufHg0dZuGo381dmk5lTTEQdwwXdWnPVwFgu7N6aqIi6bkcMKpqKEZGg\ndLS8gmUb8piXlsOXG/Mo91p6xzbmjz/vyS/Oak+LED0qNBBU7CISNKy1ZGQX8X56Nh+u3k3h4TJa\nN4pi8vCOjB0QR7e2jdyOGBJU7CLiuj1FR/hgZQ7z03PYkneQqIg6XNarLeMGxDK8c8tat6rFXyp2\nEXHF4dJyPsnMZX56Dt9tLcBaGJTYjMfH9uFnfdsF7UUsQoGKXUQCxuu1/LD9R95Py+HjzD0cLq0g\nvnkDfnVRF8YOiKVDi/A7vN8NKnYRqXHb8g8yPz2HD1bmkFN4hJioCH7etz3jBsbh6dCMOnW0RNFJ\nKnYRqRFFh8v4V8Zu3k/PZuWuQuoYGN6lFfeP6MZlPdvSIFJLFGuKil1EHFNW4eWrjfnMX5nN0nV5\nlFZ46domhgev6M7o/rG0aRzc1woNFyp2EfHbpr0HeC8liwWrcig4WErz6EiuH5LAVQPj6NW+sY4G\nDTAVu4ickQMlZSzK2MOclCxWZRUSUcdwcY/WXDUwnvO7tgrr0+IGOxW7iJw2ay0pO/YzJyWLxWv2\ncKSsgi6tY/j9z3owun9syF4jNNyo2EXklPKKS5iXns3c1Gy2FxwiJiqC0f3bc40nnn7xTTXVEmRU\n7CJyXD9dgWhOyi6WbcynwmsZnNicOy/szMg+bUP+gs/hTF8ZEfkvuUUlvJuyi3dXZJFbXEKrRlFM\nOTeJazxxJLWKcTuenAYVu4jg9Vq+2VLArB928vmGPCq8lvO6tuLPo3pxcS28AlGoU7GL1GIFB48y\nNzWbd1bsJGvfEVpER5J8XhLXDao91wcNRyp2kVrGWkvqzv3M+H4nn2TuoazCMjSpOfdf3p3LerXR\nRSvCgIpdpJYoKavgX6t3M/3fO1i7u5jG9SO4cWgi1w9JoHNrzZ2HExW7SJjLLSrh7R928s6KXew7\nVEq3No14fGwfRveL1flawpRTF7MeATwH1AVes9Y+4cR2ReTMWGtJ37WfN7/bwceZuXit5ZIebbh5\nWCJnJ7XQuvMw53exG2PqAi8ClwLZQIox5kNr7Tp/ty0i1VNa7v3PdMuanCIa1Y9g0rBEbjo7kfjm\nejO0tnDiFftgYIu1dhuAMeZdYBSgYhcJkAMlZcxesYs3vt1BbnEJnVvH8NfRvRk7IFYHEtVCTnzF\nY4GsKrezgSHHPskYkwwkAyQkJDiwWxHJLSrhze+2887yXRw4Ws7ZSS14fFwfLujaStMttVjAfpVb\na6cB0wA8Ho8N1H5FwtGmvQeY9vU2Fq7KocJrGdmnHcnnJdE3rqnb0SQIOFHsOUB8ldtxvvtExEHW\nWpZv38crX21l2cZ8GtSryy+HdGDy8I6aP5f/4kSxpwBdjDEdqSz0a4HrHdiuiFBZ6F9uzOf5Lzaz\nclchLaIjuefSrtw4tAPNoiPdjidByO9it9aWG2PuAj6lcrnjG9batX4nE6nlvF7LkvV7eeGLLazJ\nKSK2aQMeHd2bqwfGUb+e1p/LiTkyx26tXQwsdmJbIrVdhdeyeM0eXly2hQ25B+jQoiFTx/VlzIBY\n6ulkXHIatA5KJEhUeC0LV+XwwrItbMs/ROfWMTw7vh9X9m2nsytKtajYRVzm9Vo+WrOHZ5duYmv+\nIXq0a8w/fzmAEb3aUqeOlixK9anYRVxirWXJur38Y8kmNuQeoGubGF6+YQCX92qrNejiFxW7SIBZ\na/l6cwFPf7aRjOwiOraM5rlr+3Fl3/bU1St0cYCKXSSAVmzfx5OfbiBlx35imzZg6lV9Gds/VnPo\n4igVu0gAbMk7wBMfb2Tp+r20aRzFo6N7M94TT2SECl2cp2IXqUF7i0t4dukm5qRkER0Zwf0junHz\nOR11HnSpUSp2kRpw8Gg5077ayqvfbKfc62XCOYncfVEXmutIUQkAFbuIg8oqvLy7YhfPLt3Mj4dK\nubJvO+67vBsdWkS7HU1qERW7iEO+3pTPXxatY0veQYZ0bM4bI3twVrzOtiiBp2IX8dP2gkM89tE6\nlq7Po0OLhky7cSCX9myjtejiGhW7yBk6UFLGC19s4Y3vthNZtw4PXNGdm4clEhWhN0bFXSp2kWry\nei3z0rKZ+ukGCg6WcvXAOO4b0Y3Wjeq7HU0EULGLVMvqrEL+sDCTjOwiBiQ05fUJgzSPLkFHxS5y\nGooOl/HkZxuYtXwXLWOieHZ8P0b1a695dAlKKnaRk7DW8sHKHP62eD37DpUy4exE7rmsK43r13M7\nmsgJqdhFTmDz3gP8fkEmy7fvo198U6bfPJjesU3cjiVySip2kWMcLi3n+c+38No324iOiuBvY/pw\n7aB4nRtdQoZfxW6MuRr4E9ADGGytTXUilIhbvt1cwIMfZJC17whXDYzjwSu60yImyu1YItXi7yv2\nTGAs8IoDWURcU3i4lL9+tJ55adl0bBnNu8lDGZrUwu1YImfEr2K31q4HtDJAQpa1lsVrcvnjh2vZ\nf7iUOy7oxK8u7kL9ejrISEKX5til1sotKuEPCzNZsm4vfWKbMGPSYHq2b+x2LBG/nbLYjTFLgbbH\neehha+3C092RMSYZSAZISEg47YAiTrPWMntFFo8vXk+Z18tDI7szaVhHXcVIwsYpi91ae4kTO7LW\nTgOmAXg8HuvENkWqK6fwCL+bl8G3Wwo4p1MLHh/bR6fUlbCjqRipFay1zE3N5tFF66iwlsfG9Ob6\nwQl6f0jCkr/LHccA/w9oBXxkjFllrb3ckWQiDskrLuGB+Wv4YkMeQzo258mrziKhRUO3Y4nUGH9X\nxXwAfOBQFhFHWWv5cPVuHlm4lqPlFTxyZU8mnpOoA40k7GkqRsJSwcGj/P6DTD5Zm0v/hKY8ffVZ\nJLWKcTuWSECo2CXsLNuQx33zVlN8pJwHrujOlHOTqKtX6VKLqNglbBwpreBvi9cz84eddG/biLdv\nGUL3tlqXLrWPil3CQmZOEb+Zs4oteQeZPLwj913eTUePSq2lYpeQ5vVaXv1mG099tpFmDSOZOXkw\n53Zp5XYsEVep2CVk7S48wr3vreb7bT8yoldbHh/bh2bRkW7HEnGdil1C0ieZufzu/QzKKrxMHdeX\nqz1xOthIxEfFLiGlpKyCxxev563vd9I3rgnPX9ufxJY6JYBIVSp2CRnbCw5x1zvprN1dzC3DO3L/\niO5ERujEXSLHUrFLSFi4KoeH5q+hXkQdXp/g4eIebdyOJBK0VOwS1I6UVvCnD9cyJzWLQYnNeO7a\n/rRv2sDtWCJBTcUuQWvT3gPcOSudLfkHuevCzvzmki46Z7rIaVCxS9Cx1vJeahZ//HAtMVERzJik\nteki1aFil6ByuLSch+avYcGq3Qzr3IJnxvejdaP6bscSCSkqdgkaW/MPcvvbaWzJO8i9l3bljgs7\n6+RdImdAxS5BYfGaPdw3dzVR9eoyY9IQhndp6XYkkZClYhdXlVV4mfrJBl79Zjv9E5ry4vUDtOpF\nxE8qdnFNXnEJd72zkhU79jHh7A48/LOeOuBIxAH+XvP0SeDnQCmwFbjZWlvoRDAJb8u3/chds1dy\nsKScZ8f3Y3T/WLcjiYQNf18eLQF6W2v7ApuAB/2PJOHMWsurX2/j+teW0ygqggV3DlOpizjM34tZ\nf1bl5g/AVf7FkXB28Gg5981dzceZuYzo1ZYnr+5Lo/r13I4lEnacnGOfBMxxcHsSRrblHyR5Zhrb\nCw7x8Mge3HJuR51mV6SGnLLYjTFLgbbHeehha+1C33MeBsqBWSfZTjKQDJCQkHBGYSU0LduYx69m\nrySijmHm5MGc00lLGUVq0imL3Vp7yckeN8ZMBK4ELrbW2pNsZxowDcDj8ZzweRI+rLW89NVWnvx0\nIz3aNuaVGwcS37yh27FEwp6/q2JGAPcD51trDzsTScLB4dJy7puXwUcZe/j5We2ZOq4vDSJ1cWmR\nQPB3jv0FIApY4psv/cFae5vfqSSkZe07zJQZqWzce4AHrujOreclaT5dJID8XRXT2akgEh6+21LA\nne+k4/Va3pw4iAu6tXY7kkitoyNPxRHWWt74bgd/W7yeTq2imXajR9ciFXGJil38VlJWwUPz1zB/\nZQ6X92rD09f0IyZK31oibtFPn/hld+ERbns7jYzsIu65tCt3XdiZOjrVroirVOxyxtJ37Sd5Rhol\nZRW8epOHS3vqAtMiwUDFLmdk4aoc7puXQdvG9Zk9ZQhd2jRyO5KI+KjYpVq8XsvTSzby4rKtDOnY\nnJduGEjz6Ei3Y4lIFSp2OW2HS8u5Z85qPlmby7WD4vnLqN46f7pIEFKxy2nZXXiEKTNSWb+nmD9c\n2ZNJwxJ10JFIkFKxyymt3LWf5JlpHCmt4PUJg7iwuw46EglmKnY5qZ/eJG3TOIpZtwyhq94kFQl6\nKnY5Lq/X8uzSTTz/xRYGJzbn5Rv1JqlIqFCxy/9xpLSCe+euYvGaXK4eGMdjY/roTVKREKJil/+S\nW1TClBmpZO4u0pWOREKUil3+Y3VWIVNmpHLoaDmv3eTh4h46klQkFKnYBYBPMvfw63dX0apRFDMn\nD6NbW71JKhKqVOy1nLWW177Zzt8+Xk+/+Ka8epOHljFRbscSET+o2Gux8govf/7XOmb+sJORfdry\nj2v6Ub+eLl8nEupU7LXUoaPl3D17JV9syOPW85P43eXddbpdkTDh78WsHwVGAV4gD5hord3tRDCp\nOXuLS5g0PYUNuQd4bExvfjmkg9uRRMRB/i5OftJa29da2w9YBDziQCapQRtyixn94nfsKDjEaxM8\nKnWRMOTvxayLq9yMBqx/caQmfb0pnztmpRMTFcHc286hZ/vGbkcSkRrg9xy7MeYx4CagCLjQ70RS\nI2av2MXvF2TStU0j3pjooV2TBm5HEpEacsqpGGPMUmNM5nE+RgFYax+21sYDs4C7TrKdZGNMqjEm\nNT8/37n/Azkpr9fy90828OD8NQzv3JK5t52tUhcJc8ZaZ2ZPjDEJwGJrbe9TPdfj8djU1FRH9isn\nVlJWwW/nrmZRxh6uH5LAX37Ri4i6OueLSKgyxqRZaz2nep6/q2K6WGs3+26OAjb4sz1xzr5DpSTP\nSCV1534evKI7yecl6ZwvIrWEv3PsTxhjulG53HEncJv/kcRf2wsOcfObK9hdVMKL1w/gZ33buR1J\nRALI31Ux45wKIs5I2bGP5BmpGGOYPWUIAzs0dzuSiASYjjwNIx+u3s1v31tNXLMGvHnzIDq0iHY7\nkoi4QMUeBqy1/PPLrTz56UYGJzbnlRsH0kxXOxKptVTsIa6swsvvP8hkTmoWo/q1Z+pVfYmK0Im8\nRGozFXsIKy4p485Z6XyzuYC7L+rMPZd21coXEVGxh6qcwiNMejOFrfkHmTquL9cMinc7kogECRV7\nCMrMKWLS9BSOlFYw/ebBDO/S0u1IIhJEVOwh5vP1e7l79kqaNYxk5u1DdAk7Efk/VOwhZMb3O/jT\nh2vp1b4Jr0/w0LpxfbcjiUgQUrGHgAqv5W+L1/P6t9u5pEdrnr+uPw0j9aUTkeNTOwS5I6UV/GbO\nSj5du5eJ5yTyhyt7UleXsBORk1CxB7H8A0e5ZUYqGdmFPHJlTyYN7+h2JBEJASr2ILUl7wAT30yh\n4OBRXrlhIJf1aut2JBEJESr2IPTvrQXcNjONyIi6zEk+m7Pim7odSURCiIo9yLyfls0D8zPo0CKa\nNycOIr55Q7cjiUiIUbEHCWstz32+mWeXbuacTi146YaBNGlQz+1YIhKCVOxBoLTcywPzM5ifnsO4\nAXE8PrYPkRG6hJ2InBkVu8uKDpdx29tpfL/tR+65tCt3X9RZJ/ISEb+o2F2Ute8wE99cwa59h3lm\n/FmM6R/ndiQRCQMqdpesyirklrdSKKuwzJw8hKFJLdyOJCJhwpGJXGPMvcYYa4zRaQZPwyeZuVw7\n7XsaRNbl/dvPUamLiKP8fsVujIkHLgN2+R8nvFlref3b7Ty2eD1nxTXltQkeWsZEuR1LRMKME1Mx\nzwD3Awsd2FbYKq/w8pdF65jx/U6u6N2WZ8b3o349XcJORJznV7EbY0YBOdba1adayWGMSQaSARIS\nEvzZbcg5dLScX81eyecb8kg+L4kHRnSnjk7kJSI15JTFboxZChzvRCUPAw9ROQ1zStbaacA0AI/H\nY6uRMaTtLS5h0vQU1u8p5tHRvblxaAe3I4lImDtlsVtrLzne/caYPkBH4KdX63FAujFmsLU219GU\nIWpDbjGT3kyh8EgZr08YxIXdW7sdSURqgTOeirHWrgH+01TGmB2Ax1pb4ECukPf1pnzumJVOdFRd\n3rv1bHrHNnE7kojUElrHXgPeXbGLhxdk0qV1DG/ePIh2TRq4HUlEahHHit1am+jUtkKV12t56rON\n/PPLrZzXtRUvXt+fRvV1Ii8RCSy9YndISVkF983L4F+rd3Pd4AT+MqoX9erqRF4iEngqdgfsO1TK\nlBmppO3cz+9GdOe285N0Ii8RcY2K3U/b8g9y8/QU9hSV8OL1A/hZ33ZuRxKRWk7F7ofl234keWYa\nEXUMs6cMZWCHZm5HEhFRsZ+pBStzuH9eBnHNGzB94mASWugSdiISHFTs1WSt5fnPt/DM0k0MTWrO\nKzd4aNJQK19EJHio2Kuh6iXsxg6I5YmxfXUJOxEJOir201R4uJTb3k7jh237+J9LuvKri3UJOxEJ\nTir207Dzx0PcPD2F7H1HdAk7EQl6KvZTSNu5nykzUvFay8zJgxmiqx2JSJBTsZ/Eoozd3PPeato3\nqc8bEweR1CrG7UgiIqekYj8Oay0vfbWVqZ9sxNOhGdNu8tA8OtLtWCIip0XFfoyyCi9/WJDJuylZ\n/Pys9jx5VV9dwk5EQoqKvYrikjLunJXON5sLuOvCztxzaVddwk5EQo6K3Sd7/2EmTU9hW/4hpl7V\nl2s88W5HEhE5Iyp2ICO7kMlvpVJSVsFbkwYzrHNLtyOJiJyxWl/sn67N5dfvrqRlTBTv3DKELm0a\nuR1JRMQvtbbYrbW8/u12Hlu8nr5xTXntJg+tGkW5HUtExG9+nejEGPMnY0yOMWaV72OkU8FqUnmF\nl0cWruWvH63n8p5teXfKUJW6iIQNJ16xP2OtfcqB7QRE1ZUvyecl8cCI7lr5IiJhpVZNxez68TCT\n30phe8Ehnhjbh2sHJ7gdSUTEcU6cc/YuY0yGMeYNY0zQXkIodcc+Rv/zO/YWlzBj0mCVuoiErVMW\nuzFmqTEm8zgfo4CXgE5AP2AP8PRJtpNsjEk1xqTm5+c79j9wOhaszOH6V5fTuH4EC+4cxjlazigi\nYcxYa53ZkDGJwCJrbe9TPdfj8djU1FRH9nsy1lqeWbKJ57/YwpCOzXn5hoE00zlfRCREGWPSrLWe\nUz3Przl2Y0w7a+0e380xQKY/23NSSVkFv527mkUZe7h6YByPjemjqx2JSK3g75unU40x/QAL7ABu\n9TuRA/IPHGXKjFRWZRXyuxHdue38JF3tSERqDb+K3Vp7o1NBnLIht5jJ01P58dBRXr5hACN6t3M7\nkohIQIXVcsdlG/K46510oqMimHvrOfSJa+J2JBGRgAuLYrfWMv3fO3h00Tp6tGvMaxM8tGvSwO1Y\nIiKuCPliL6/w8ud/rWPmDzu5tGcbnh3fj+iokP/fEhE5YyHdgFVPD3DreUncP6I7dXV6ABGp5UK2\n2KueHuDv4/owfpCOJBURgRAt9tQd+0iemUaF1zJj8mDO6aQjSUVEfhJyxb5gZQ73z8ugfdP6vDFx\nEEmtYtyOJCISVEKq2F/4YjNPfbZJpwcQETmJkCr2pFYxXOOJ46+jdXoAEZETCaliH9mnHSP76EhS\nEZGT0cteEZEwo2IXEQkzKnYRkTCjYhcRCTMqdhGRMKNiFxEJMyp2EZEwo2IXEQkzxlob+J0akw/s\nPMN/3hIocDCOU5SrepSrepSreoI1F/iXrYO1ttWpnuRKsfvDGJNqrfW4neNYylU9ylU9ylU9wZoL\nApNNUzEiImFGxS4iEmZCsdinuR3gBJSrepSrepSreoI1FwQgW8jNsYuIyMmF4it2ERE5iZAqdmPM\nCGPMRmPMFmPMAy7miDfGLDPGrDPGrDXG/Np3f3NjzBJjzGbff5u5kK2uMWalMWaR73ZHY8xy35jN\nMca4ctkpY0xTY8w8Y8wGY8x6Y8zZQTJe/+P7GmYaY2YbY+q7MWbGmDeMMXnGmMwq9x13fEyl5335\nMowxAwKc60nf1zHDGPOBMaZplcce9OXaaIy5PJC5qjx2rzHGGmNa+m67Ol6+++/2jdlaY8zUKvfX\nzHhZa0PiA6gLbAWSgEhgNdDTpSztgAG+zxsBm4CewFTgAd/9DwB/dyHbPcA7wCLf7feAa32fvwzc\n7tKYvQXc4vs8Emjq9ngBscB2oEGVsZroxpgB5wEDgMwq9x13fICRwMeAAYYCywOc6zIgwvf536vk\n6un7uYwCOvp+XusGKpfv/njgUyqPk2kZJON1IbAUiPLdbl3T41Wj36wOD9jZwKdVbj8IPOh2Ll+W\nhcClwEagne++dsDGAOeIAz4HLgIW+b6RC6r8EP7XGAYwVxNfgZpj7nd7vGKBLKA5lVcTWwRc7taY\nAYnHFMJxxwd4BbjueM8LRK5jHhsDzPJ9/l8/k76CPTuQuYB5wFnAjirF7up4UflC4ZLjPK/GxiuU\npmJ++iH8SbbvPlcZYxKB/sByoI21do/voVygTYDjPAvcD3h9t1sAhdbact9tt8asI5APvOmbJnrN\nGBONy+Nlrc0BngJ2AXuAIiCN4BgzOPH4BNPPwiQqXw2Dy7mMMaOAHGvt6mMecnu8ugLn+qb3vjLG\nDKrpXKFU7EHHGBMDvA/8xlpbXPUxW/krOGBLjowxVwJ51tq0QO2zGiKo/PP0JWttf+AQlVML/xHo\n8QLwzVmPovIXT3sgGhgRyAyny43xORVjzMNAOTArCLI0BB4CHnE7y3FEUPlX4VDgPuA9Y4ypyR2G\nUrHnUDl/9pM4332uMMbUo7LUZ1lr5/vu3muMaed7vB2QF8BIw4BfGGN2AO9SOR3zHNDUGPPTRcvd\nGrNsINtau9x3ex6VRe/meAFcAmy31uZba8uA+VSOYzCMGZx4fFz/WTDGTASuBH7p+6Xjdq5OVP6C\nXu37GYgD0o0xbV3OBZXf//NtpRVU/kXdsiZzhVKxpwBdfCsWIoFrgQ/dCOL7bfs6sN5a+48qD30I\nTPB9PoGP6hfnAAABXUlEQVTKufeAsNY+aK2Ns9YmUjk2X1hrfwksA65yI1OVbLlAljGmm++ui4F1\nuDhePruAocaYhr6v6U+5XB8znxONz4fATb7VHkOBoipTNjXOGDOCyim/X1hrDx+T91pjTJQxpiPQ\nBVgRiEzW2jXW2tbW2kTfz0A2lQsccnF5vIAFVL6BijGmK5WLBwqoyfGqqTcQauhNiZFUrkDZCjzs\nYo7hVP5ZnAGs8n2MpHJO+3NgM5Xvgjd3Kd8F/O+qmCTfN8sWYC6+d+ZdyNQPSPWN2QKgWTCMF/Bn\nYAOQCcykcoVCwMcMmE3lPH8ZlaU0+UTjQ+Wb4i/6fg7WAJ4A59pC5dzwT9/7L1d5/sO+XBuBKwKZ\n65jHd/C/b566PV6RwNu+77F04KKaHi8deSoiEmZCaSpGREROg4pdRCTMqNhFRMKMil1EJMyo2EVE\nwoyKXUQkzKjYRUTCjIpdRCTM/H+W1QxGYmcwZAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14d65ee10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(len(objs[:161])), objs[:161])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IS on Kernel and DQN individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1206,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "pi_k = get_pi(test_state_list, expert_k)\n",
    "pi_d = get_pi(test_state_list, expert_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2157.7660566352924"
      ]
     },
     "execution_count": 1209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IS(test_state_list, test_phy_actions, test_rewards, fence_posts, 0.99, pi_k, test_pi_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5536570.7034089863"
      ]
     },
     "execution_count": 1210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IS(test_state_list, test_phy_actions, test_rewards, fence_posts, 0.99, pi_d, test_pi_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.12021211754131815"
      ]
     },
     "execution_count": 1211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IS(test_state_list, test_phy_actions, test_rewards, fence_posts, 0.99, test_pi_b, test_pi_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1185,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.array([[ 0.22792604, -0.043015,   -0.14878969,  0.14844492, -0.25037038]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1186,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = get_experts_action_probs(w, test_input.values)\n",
    "pi_e = probs * encoded_expert_k + (1 - probs) * encoded_expert_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1213,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-2330.6020917428623"
      ]
     },
     "execution_count": 1213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi_moe = get_pi(test_state_list, moe_actions)\n",
    "IS(test_state_list, test_phy_actions, test_rewards, fence_posts, 0.99, pi_moe, test_pi_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1096"
      ]
     },
     "execution_count": 1188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.where(probs < 0.5)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1190,
   "metadata": {},
   "outputs": [],
   "source": [
    "experts = get_expert_actions(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "moe_actions = []\n",
    "for i, expert in enumerate(experts):\n",
    "    if expert == 0:\n",
    "        moe_actions += [ expert_k[i] ]\n",
    "    else:\n",
    "        moe_actions += [ expert_d[i] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1198,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(np.array(moe_actions), open('moe_actions.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_bloc</th>\n",
       "      <th>dist</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>Weight_kg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.909478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.377900</td>\n",
       "      <td>0.926956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.113299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.377900</td>\n",
       "      <td>0.926956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.565387</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.377900</td>\n",
       "      <td>0.926956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.410762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.377900</td>\n",
       "      <td>0.926956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.388182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.377900</td>\n",
       "      <td>0.926956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.348360</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.377900</td>\n",
       "      <td>0.926956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2.289565</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.377900</td>\n",
       "      <td>0.926956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>2.232181</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.377900</td>\n",
       "      <td>0.926956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>2.218849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.377900</td>\n",
       "      <td>0.926956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>2.183757</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.377900</td>\n",
       "      <td>0.926956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.0</td>\n",
       "      <td>2.163029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.377900</td>\n",
       "      <td>0.926956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.0</td>\n",
       "      <td>2.130495</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.377900</td>\n",
       "      <td>0.926956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.0</td>\n",
       "      <td>2.110087</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.377900</td>\n",
       "      <td>0.926956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.937556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.643291</td>\n",
       "      <td>0.265109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.152585</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.643291</td>\n",
       "      <td>0.265109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.375349</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.643291</td>\n",
       "      <td>0.265109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.159283</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.643291</td>\n",
       "      <td>0.265109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.042176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.643291</td>\n",
       "      <td>0.265109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.897766</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.643291</td>\n",
       "      <td>0.265109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.941871</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730297</td>\n",
       "      <td>0.290835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.159270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730297</td>\n",
       "      <td>0.307290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.403606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730297</td>\n",
       "      <td>0.323746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.187633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730297</td>\n",
       "      <td>0.340202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.097042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730297</td>\n",
       "      <td>0.356657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.969982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730297</td>\n",
       "      <td>0.373113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1.894045</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730297</td>\n",
       "      <td>0.389569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.875136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730297</td>\n",
       "      <td>0.406024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1.842446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730297</td>\n",
       "      <td>0.422480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.817579</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730297</td>\n",
       "      <td>0.438936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>11.0</td>\n",
       "      <td>1.788049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730297</td>\n",
       "      <td>0.455391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50829</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.059604</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.829547</td>\n",
       "      <td>0.301446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50830</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1.993836</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.829547</td>\n",
       "      <td>0.301446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50831</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.942219</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.829547</td>\n",
       "      <td>0.301446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50832</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1.935050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.829547</td>\n",
       "      <td>0.301764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50833</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.903803</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.829547</td>\n",
       "      <td>0.302558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50834</th>\n",
       "      <td>11.0</td>\n",
       "      <td>1.864399</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.829547</td>\n",
       "      <td>0.302558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50835</th>\n",
       "      <td>12.0</td>\n",
       "      <td>1.823142</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.829547</td>\n",
       "      <td>0.302558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50836</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1.811370</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.829547</td>\n",
       "      <td>0.302558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50837</th>\n",
       "      <td>14.0</td>\n",
       "      <td>1.822965</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.829547</td>\n",
       "      <td>0.247979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50838</th>\n",
       "      <td>15.0</td>\n",
       "      <td>1.866910</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.829547</td>\n",
       "      <td>0.220690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50839</th>\n",
       "      <td>16.0</td>\n",
       "      <td>1.929148</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.829547</td>\n",
       "      <td>0.247979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50840</th>\n",
       "      <td>17.0</td>\n",
       "      <td>1.998233</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.829547</td>\n",
       "      <td>0.302558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50841</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2.055998</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.829547</td>\n",
       "      <td>0.302558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50842</th>\n",
       "      <td>19.0</td>\n",
       "      <td>2.096436</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.829547</td>\n",
       "      <td>0.302558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50843</th>\n",
       "      <td>20.0</td>\n",
       "      <td>2.141616</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.829547</td>\n",
       "      <td>0.302558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50844</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.962180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.321232</td>\n",
       "      <td>0.333704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50845</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.139144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.321232</td>\n",
       "      <td>0.333704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50846</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.352853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.321232</td>\n",
       "      <td>0.278424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50847</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.182755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.321232</td>\n",
       "      <td>0.257694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50848</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.109334</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.321232</td>\n",
       "      <td>0.207020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50849</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.014580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.321232</td>\n",
       "      <td>0.278424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50850</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1.941724</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.321232</td>\n",
       "      <td>0.333704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50851</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.887312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.321232</td>\n",
       "      <td>0.333704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50852</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1.848065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.321232</td>\n",
       "      <td>0.333704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50853</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.810281</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.321232</td>\n",
       "      <td>0.333704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50854</th>\n",
       "      <td>11.0</td>\n",
       "      <td>1.772499</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.321232</td>\n",
       "      <td>0.333704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50855</th>\n",
       "      <td>12.0</td>\n",
       "      <td>1.726403</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.321232</td>\n",
       "      <td>0.333704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50856</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1.681422</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.321232</td>\n",
       "      <td>0.333704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50857</th>\n",
       "      <td>14.0</td>\n",
       "      <td>1.660654</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.321232</td>\n",
       "      <td>0.333704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50858</th>\n",
       "      <td>15.0</td>\n",
       "      <td>1.690007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.321232</td>\n",
       "      <td>0.333704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50859 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_bloc      dist  gender       age  Weight_kg\n",
       "0           1.0  2.909478     0.0  0.377900   0.926956\n",
       "1           2.0  2.113299     0.0  0.377900   0.926956\n",
       "2           3.0  2.565387     0.0  0.377900   0.926956\n",
       "3           4.0  2.410762     0.0  0.377900   0.926956\n",
       "4           5.0  2.388182     0.0  0.377900   0.926956\n",
       "5           6.0  2.348360     0.0  0.377900   0.926956\n",
       "6           7.0  2.289565     0.0  0.377900   0.926956\n",
       "7           8.0  2.232181     0.0  0.377900   0.926956\n",
       "8           9.0  2.218849     0.0  0.377900   0.926956\n",
       "9          10.0  2.183757     0.0  0.377900   0.926956\n",
       "10         11.0  2.163029     0.0  0.377900   0.926956\n",
       "11         12.0  2.130495     0.0  0.377900   0.926956\n",
       "12         13.0  2.110087     0.0  0.377900   0.926956\n",
       "13          1.0  2.937556     0.0  0.643291   0.265109\n",
       "14          2.0  2.152585     0.0  0.643291   0.265109\n",
       "15          3.0  2.375349     0.0  0.643291   0.265109\n",
       "16          4.0  2.159283     0.0  0.643291   0.265109\n",
       "17          5.0  2.042176     0.0  0.643291   0.265109\n",
       "18          6.0  1.897766     0.0  0.643291   0.265109\n",
       "19          1.0  2.941871     0.0  0.730297   0.290835\n",
       "20          2.0  2.159270     0.0  0.730297   0.307290\n",
       "21          3.0  2.403606     0.0  0.730297   0.323746\n",
       "22          4.0  2.187633     0.0  0.730297   0.340202\n",
       "23          5.0  2.097042     0.0  0.730297   0.356657\n",
       "24          6.0  1.969982     0.0  0.730297   0.373113\n",
       "25          7.0  1.894045     0.0  0.730297   0.389569\n",
       "26          8.0  1.875136     0.0  0.730297   0.406024\n",
       "27          9.0  1.842446     0.0  0.730297   0.422480\n",
       "28         10.0  1.817579     0.0  0.730297   0.438936\n",
       "29         11.0  1.788049     0.0  0.730297   0.455391\n",
       "...         ...       ...     ...       ...        ...\n",
       "50829       6.0  2.059604     1.0  0.829547   0.301446\n",
       "50830       7.0  1.993836     1.0  0.829547   0.301446\n",
       "50831       8.0  1.942219     1.0  0.829547   0.301446\n",
       "50832       9.0  1.935050     1.0  0.829547   0.301764\n",
       "50833      10.0  1.903803     1.0  0.829547   0.302558\n",
       "50834      11.0  1.864399     1.0  0.829547   0.302558\n",
       "50835      12.0  1.823142     1.0  0.829547   0.302558\n",
       "50836      13.0  1.811370     1.0  0.829547   0.302558\n",
       "50837      14.0  1.822965     1.0  0.829547   0.247979\n",
       "50838      15.0  1.866910     1.0  0.829547   0.220690\n",
       "50839      16.0  1.929148     1.0  0.829547   0.247979\n",
       "50840      17.0  1.998233     1.0  0.829547   0.302558\n",
       "50841      18.0  2.055998     1.0  0.829547   0.302558\n",
       "50842      19.0  2.096436     1.0  0.829547   0.302558\n",
       "50843      20.0  2.141616     1.0  0.829547   0.302558\n",
       "50844       1.0  2.962180     0.0  0.321232   0.333704\n",
       "50845       2.0  2.139144     0.0  0.321232   0.333704\n",
       "50846       3.0  2.352853     0.0  0.321232   0.278424\n",
       "50847       4.0  2.182755     0.0  0.321232   0.257694\n",
       "50848       5.0  2.109334     0.0  0.321232   0.207020\n",
       "50849       6.0  2.014580     0.0  0.321232   0.278424\n",
       "50850       7.0  1.941724     0.0  0.321232   0.333704\n",
       "50851       8.0  1.887312     0.0  0.321232   0.333704\n",
       "50852       9.0  1.848065     0.0  0.321232   0.333704\n",
       "50853      10.0  1.810281     0.0  0.321232   0.333704\n",
       "50854      11.0  1.772499     0.0  0.321232   0.333704\n",
       "50855      12.0  1.726403     0.0  0.321232   0.333704\n",
       "50856      13.0  1.681422     0.0  0.321232   0.333704\n",
       "50857      14.0  1.660654     0.0  0.321232   0.333704\n",
       "50858      15.0  1.690007     0.0  0.321232   0.333704\n",
       "\n",
       "[50859 rows x 5 columns]"
      ]
     },
     "execution_count": 1214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
