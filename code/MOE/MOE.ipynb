{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import autograd.numpy as np\n",
    "from autograd import grad \n",
    "# from rl_functions import off_policy_per_decision_weighted_doubly_robust as WDR\n",
    "from rl_functions import value_iteration\n",
    "from rl_functions import learn_rewards_function\n",
    "from rl_functions import learn_transition_function\n",
    "from rl_functions import turn_policy_to_stochastic_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('../../data/train_scaled_encoded.csv')\n",
    "test_set = pd.read_csv('../../data/test_scaled_encoded.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_input = pd.read_csv('../../data/train_input_features.csv')\n",
    "test_input = pd.read_csv('../../data/test_input_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'off_policy_per_decision_weighted_doubly_robust(\\n    states_sequence, actions_sequence, rewards_sequence, fence_posts, gamma,\\n    pi_evaluation, pi_behavior, V = None, Q = None, num_of_states = None, num_of_actions = None )'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"off_policy_per_decision_weighted_doubly_robust(\n",
    "    states_sequence, actions_sequence, rewards_sequence, fence_posts, gamma,\n",
    "    pi_evaluation, pi_behavior, V = None, Q = None, num_of_states = None, num_of_actions = None )\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_state_list = pkl.load(open('../../data/classify_state/train_states.pkl', 'rb'), encoding='latin1')\n",
    "test_state_list = pkl.load(open('../../data/classify_state/test_states.pkl', 'rb'), encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "action_map = {}\n",
    "count = 0\n",
    "for iv in range(5):\n",
    "    for vaso in range(5):\n",
    "        action_map[(iv, vaso)] = count\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel based expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_based = pkl.load(open('test_kernel_policy_transformed.pkl', 'rb'), encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_k = kernel_based[:,3]\n",
    "dist = kernel_based[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_bloc</th>\n",
       "      <th>delta_sofa</th>\n",
       "      <th>delta_lactate</th>\n",
       "      <th>intermediate_reward</th>\n",
       "      <th>dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.909478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>2.113299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>-0.035000</td>\n",
       "      <td>2.565387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.115000</td>\n",
       "      <td>2.410762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>-0.035000</td>\n",
       "      <td>2.388182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>-0.035000</td>\n",
       "      <td>2.348360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>-0.035000</td>\n",
       "      <td>2.289565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>-0.035000</td>\n",
       "      <td>2.232181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>-0.135000</td>\n",
       "      <td>2.218849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>-0.035000</td>\n",
       "      <td>2.183757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>-0.035000</td>\n",
       "      <td>2.163029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>-0.035000</td>\n",
       "      <td>2.130495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>-0.035000</td>\n",
       "      <td>2.110087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.937556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.064286</td>\n",
       "      <td>-0.003395</td>\n",
       "      <td>2.152585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.064286</td>\n",
       "      <td>-0.003395</td>\n",
       "      <td>2.375349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.064286</td>\n",
       "      <td>-0.003395</td>\n",
       "      <td>2.159283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.064286</td>\n",
       "      <td>-0.003395</td>\n",
       "      <td>2.042176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.064286</td>\n",
       "      <td>-0.003395</td>\n",
       "      <td>1.897766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.941871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>2.159270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.025000</td>\n",
       "      <td>2.403606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>2.187633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>2.097042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.025000</td>\n",
       "      <td>1.969982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-0.006667</td>\n",
       "      <td>0.388333</td>\n",
       "      <td>1.894045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>8.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-0.006667</td>\n",
       "      <td>0.263333</td>\n",
       "      <td>1.875136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>9.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.006667</td>\n",
       "      <td>0.138333</td>\n",
       "      <td>1.842446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.006667</td>\n",
       "      <td>-0.111667</td>\n",
       "      <td>1.817579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.006667</td>\n",
       "      <td>-0.111667</td>\n",
       "      <td>1.788049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50829</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.025000</td>\n",
       "      <td>2.059604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50830</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>1.993836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50831</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.025000</td>\n",
       "      <td>1.942219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50832</th>\n",
       "      <td>9.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.935050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50833</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.025000</td>\n",
       "      <td>1.903803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50834</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.025000</td>\n",
       "      <td>1.864399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50835</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.025000</td>\n",
       "      <td>1.823142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50836</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.025000</td>\n",
       "      <td>1.811370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50837</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.025000</td>\n",
       "      <td>1.822965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50838</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.025000</td>\n",
       "      <td>1.866910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50839</th>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.025000</td>\n",
       "      <td>1.929148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50840</th>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>1.998233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50841</th>\n",
       "      <td>18.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>2.055998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50842</th>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.025000</td>\n",
       "      <td>2.096436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50843</th>\n",
       "      <td>20.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>2.141616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50844</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.962180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50845</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>-0.196010</td>\n",
       "      <td>2.139144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50846</th>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4.090909</td>\n",
       "      <td>-1.873882</td>\n",
       "      <td>2.352853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50847</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.590909</td>\n",
       "      <td>1.974944</td>\n",
       "      <td>2.182755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50848</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.200000</td>\n",
       "      <td>1.542309</td>\n",
       "      <td>2.109334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50849</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.727273</td>\n",
       "      <td>1.217788</td>\n",
       "      <td>2.014580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50850</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.272727</td>\n",
       "      <td>0.507321</td>\n",
       "      <td>1.941724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50851</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>1.887312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50852</th>\n",
       "      <td>9.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>-0.378242</td>\n",
       "      <td>1.848065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50853</th>\n",
       "      <td>10.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.042857</td>\n",
       "      <td>0.039338</td>\n",
       "      <td>1.810281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50854</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.025000</td>\n",
       "      <td>1.772499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50855</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.140000</td>\n",
       "      <td>0.253185</td>\n",
       "      <td>1.726403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50856</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.140000</td>\n",
       "      <td>0.153185</td>\n",
       "      <td>1.681422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50857</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.140000</td>\n",
       "      <td>0.253185</td>\n",
       "      <td>1.660654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50858</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.140000</td>\n",
       "      <td>0.253185</td>\n",
       "      <td>1.690007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50859 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_bloc  delta_sofa  delta_lactate  intermediate_reward      dist\n",
       "0           1.0         0.0       0.000000             0.000000  2.909478\n",
       "1           2.0        -4.0       0.005000             0.490000  2.113299\n",
       "2           3.0         0.0       0.005000            -0.035000  2.565387\n",
       "3           4.0        -1.0       0.005000             0.115000  2.410762\n",
       "4           5.0         0.0       0.005000            -0.035000  2.388182\n",
       "5           6.0         0.0       0.005000            -0.035000  2.348360\n",
       "6           7.0         0.0       0.005000            -0.035000  2.289565\n",
       "7           8.0         0.0       0.005000            -0.035000  2.232181\n",
       "8           9.0         1.0       0.005000            -0.135000  2.218849\n",
       "9          10.0         0.0       0.005000            -0.035000  2.183757\n",
       "10         11.0         0.0       0.005000            -0.035000  2.163029\n",
       "11         12.0         0.0       0.005000            -0.035000  2.130495\n",
       "12         13.0         0.0       0.005000            -0.035000  2.110087\n",
       "13          1.0         0.0       0.000000             0.000000  2.937556\n",
       "14          2.0        -1.0       0.064286            -0.003395  2.152585\n",
       "15          3.0        -1.0       0.064286            -0.003395  2.375349\n",
       "16          4.0        -1.0       0.064286            -0.003395  2.159283\n",
       "17          5.0        -1.0       0.064286            -0.003395  2.042176\n",
       "18          6.0        -1.0       0.064286            -0.003395  1.897766\n",
       "19          1.0         0.0       0.000000             0.000000  2.941871\n",
       "20          2.0        -2.0       0.000000             0.250000  2.159270\n",
       "21          3.0         0.0       0.000000            -0.025000  2.403606\n",
       "22          4.0         4.0       0.000000            -0.500000  2.187633\n",
       "23          5.0         1.0       0.000000            -0.125000  2.097042\n",
       "24          6.0         0.0       0.000000            -0.025000  1.969982\n",
       "25          7.0        -3.0      -0.006667             0.388333  1.894045\n",
       "26          8.0        -2.0      -0.006667             0.263333  1.875136\n",
       "27          9.0        -1.0      -0.006667             0.138333  1.842446\n",
       "28         10.0         1.0      -0.006667            -0.111667  1.817579\n",
       "29         11.0         1.0      -0.006667            -0.111667  1.788049\n",
       "...         ...         ...            ...                  ...       ...\n",
       "50829       6.0         0.0       0.000000            -0.025000  2.059604\n",
       "50830       7.0         1.0       0.000000            -0.125000  1.993836\n",
       "50831       8.0         0.0       0.000000            -0.025000  1.942219\n",
       "50832       9.0        -1.0       0.000000             0.125000  1.935050\n",
       "50833      10.0         0.0       0.000000            -0.025000  1.903803\n",
       "50834      11.0         0.0       0.000000            -0.025000  1.864399\n",
       "50835      12.0         0.0       0.000000            -0.025000  1.823142\n",
       "50836      13.0         0.0       0.000000            -0.025000  1.811370\n",
       "50837      14.0         0.0       0.000000            -0.025000  1.822965\n",
       "50838      15.0         0.0       0.000000            -0.025000  1.866910\n",
       "50839      16.0         0.0       0.000000            -0.025000  1.929148\n",
       "50840      17.0         1.0       0.000000            -0.125000  1.998233\n",
       "50841      18.0        -1.0       0.000000             0.125000  2.055998\n",
       "50842      19.0         0.0       0.000000            -0.025000  2.096436\n",
       "50843      20.0        -1.0       0.000000             0.125000  2.141616\n",
       "50844       1.0         0.0       0.000000             0.000000  2.962180\n",
       "50845       2.0         0.0       0.085714            -0.196010  2.139144\n",
       "50846       3.0        -1.0       4.090909            -1.873882  2.352853\n",
       "50847       4.0         0.0      -5.590909             1.974944  2.182755\n",
       "50848       5.0         1.0      -1.200000             1.542309  2.109334\n",
       "50849       6.0         0.0      -0.727273             1.217788  2.014580\n",
       "50850       7.0         0.0      -0.272727             0.507321  1.941724\n",
       "50851       8.0         1.0       0.000000            -0.125000  1.887312\n",
       "50852       9.0        -1.0       0.257143            -0.378242  1.848065\n",
       "50853      10.0        -1.0       0.042857             0.039338  1.810281\n",
       "50854      11.0         0.0       0.000000            -0.025000  1.772499\n",
       "50855      12.0         0.0      -0.140000             0.253185  1.726403\n",
       "50856      13.0         1.0      -0.140000             0.153185  1.681422\n",
       "50857      14.0         0.0      -0.140000             0.253185  1.660654\n",
       "50858      15.0         0.0      -0.140000             0.253185  1.690007\n",
       "\n",
       "[50859 rows x 5 columns]"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_input['dist'] = dist\n",
    "# test_input\n",
    "test_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN based expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encode expert actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_expert1 = np.zeros((expert1.shape[0], 25))\n",
    "encoded_expert2 = np.zeros((expert2.shape[0], 25))\n",
    "for i, e1a in enumerate(expert1):\n",
    "    encoded_expert1[i, e1a[0]] = 1\n",
    "    encoded_expert2[i, expert2[i][0]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_experts_action_probs(w, f):\n",
    "    p = sigmoid(np.sum(f * w, axis=1, keepdims=True))\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = train_input['intermediate_reward'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = np.random.rand(1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = get_experts_action_probs(w, train_input.values[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = []\n",
    "vasos = train_set['vaso_input'].values\n",
    "ivs = train_set['iv_input'].values\n",
    "for i, iv in enumerate(ivs):\n",
    "    actions += [ action_map[ (vasos[i], iv) ] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn T, R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in true_divide\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "bloc = train_input['num_bloc'].values\n",
    "trasition = np.zeros((750, 25, 750))\n",
    "for i, s in enumerate(train_state_list):\n",
    "    if i == train_state_list.shape[0] - 1:\n",
    "        break\n",
    "    if bloc[i + 1] == 1:\n",
    "        continue\n",
    "    else:\n",
    "        trasition[s, actions[i], train_state_list[i + 1]] += 1\n",
    "\n",
    "for s in range(750):\n",
    "    trasition[s] /= np.sum(trasition[s], axis=1, keepdims=True)\n",
    "trasition = np.nan_to_num(trasition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in true_divide\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "reward_table = np.zeros((750, 25, 750))\n",
    "count = np.zeros((750, 25, 750))\n",
    "for i, s in enumerate(train_state_list):\n",
    "    if i == train_state_list.shape[0] - 1:\n",
    "        break\n",
    "    if bloc[i + 1] == 1:\n",
    "        continue\n",
    "    else:\n",
    "        reward_table[s, actions[i], train_state_list[i + 1]] += rewards[i]\n",
    "        count[s, actions[i], train_state_list[i + 1]] += 1\n",
    "reward_table = np.nan_to_num(reward_table / count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_table = np.zeros((750, 25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, state in enumerate(train_state_list):\n",
    "    t_table[state, expert1[i]] += probs[i]\n",
    "    t_table[state, expert2[i]] += (1 - probs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_table = t_table / np.sum(t_table, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MDP, WDR, and IS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def policy_eval(MDP, prob_e, gamma=.99):\n",
    "\t# solve by value iteration\n",
    "\t(transition_matrix, reward_table) = MDP\n",
    "\t# print MDP\n",
    "\tV = np.zeros((transition_matrix.shape[0]))\n",
    "\t# compute V table\n",
    "\twhile 1:\n",
    "\t\tdelta = 0.\n",
    "\t\tfor s in range(transition_matrix.shape[0]):\n",
    "\t\t\tv = np.sum(prob_e[s] * np.sum(transition_matrix[s] * (reward_table[s] + gamma * V), axis = 1))\n",
    "\t\t\tdelta = max(delta, abs(v - V[s]))\n",
    "\t\t\tV[s] = v\n",
    "\n",
    "\t\tif delta < 0.001:\n",
    "\t\t\tbreak\n",
    "\t\t\t\n",
    "\t# build Q_table\n",
    "\tQ = np.zeros((transition_matrix.shape[0], transition_matrix.shape[1]))\n",
    "\tfor s in range(transition_matrix.shape[0]):\n",
    "\t\tQ[s] = np.sum(transition_matrix[s] * (reward_table[s] + gamma * V), axis = 1)\n",
    "\treturn V, Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "V, Q = policy_eval((trasition, reward_table), t_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_b = np.zeros((750, 25))\n",
    "for i, s in enumerate(train_state_list):\n",
    "    if i == train_state_list.shape[0] - 1:\n",
    "        break\n",
    "    pi_b[s, actions[i]] += 1\n",
    "pi_b = pi_b / np.sum(pi_b, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "fence_posts = []\n",
    "for i, idx in enumerate(bloc):\n",
    "    if idx == 1:\n",
    "        fence_posts += [ i ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "moe_actions = []\n",
    "for i, prob in enumerate(probs):\n",
    "    if prob >= 0.5:\n",
    "        moe_actions += [ expert1[i][0] ]\n",
    "    else:\n",
    "        moe_actions += [ expert2[i][0] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def WDR(\n",
    "    states_sequence, actions_sequence, rewards_sequence, fence_posts, gamma,\n",
    "    pi_evaluation, pi_behavior, V = None, Q = None, num_of_states = None, num_of_actions = None ):\n",
    "\n",
    "    num_of_trials = len( fence_posts )\n",
    "    individual_trial_estimators = []\n",
    "    pi_evaluation = turn_policy_to_stochastic_policy( \\\n",
    "        pi_evaluation, num_of_states = num_of_states, num_of_actions = num_of_actions )\n",
    "    pi_behavior = turn_policy_to_stochastic_policy( \\\n",
    "        pi_behavior, num_of_states = num_of_states, num_of_actions = num_of_actions )\n",
    "    # estimate V and Q if they are not passed as parameters\n",
    "    if V is None or Q is None:\n",
    "        # TODO : add part which calculate R and T from data if they are not given\n",
    "        V, Q = policy_evaluation( T , R , pi_evaluation , gamma )\n",
    "    # calculate the doubly robust estimator of the policy\n",
    "    fence_posts_with_length_appended = fence_posts + [ len( states_sequence ) ]\n",
    "    single_patient_sequences_length = [ fence_posts_with_length_appended[i+1] - \\\n",
    "        fence_posts_with_length_appended[i] for i in range(len(fence_posts)) ]\n",
    "    length_of_longest_patient_sequence = max( single_patient_sequences_length )\n",
    "    rho_array = np.nan * np.zeros( ( num_of_trials, length_of_longest_patient_sequence ) )\n",
    "#    rho_array = np.ones( ( num_of_trials, length_of_longest_patient_sequence ) )\n",
    "    for trial_i in range( num_of_trials ):\n",
    "        rho = 1\n",
    "        if trial_i < num_of_trials - 1:\n",
    "            steps_in_trial = fence_posts[ trial_i+1 ] -  fence_posts[ trial_i ]\n",
    "        else:\n",
    "            steps_in_trial = len( states_sequence) - fence_posts[-1]\n",
    "        t_within_trial = 0\n",
    "        for t in range(\n",
    "                fence_posts[ trial_i], fence_posts[ trial_i] + steps_in_trial ):\n",
    "            if(pi_behavior[ states_sequence[ t], actions_sequence[ t]]==0):\n",
    "                print(states_sequence[ t], actions_sequence[ t])\n",
    "            rho *= pi_evaluation[ states_sequence[ t], actions_sequence[ t]] / \\\n",
    "                pi_behavior[ states_sequence[ t], actions_sequence[ t]]\n",
    "            rho_array[ trial_i, t_within_trial ] = rho\n",
    "            t_within_trial += 1\n",
    "        rho_array[ trial_i, t_within_trial: ] = rho\n",
    "    weights_normalization = np.sum( rho_array, axis = 0 )\n",
    "    for trial_i in range( num_of_trials ):\n",
    "        current_trial_estimator = 0\n",
    "        rho = 1\n",
    "        w = 1 / num_of_trials\n",
    "        discount = 1/gamma\n",
    "        if trial_i < num_of_trials - 1:\n",
    "            steps_in_trial = fence_posts[ trial_i+1 ] -  fence_posts[ trial_i ]\n",
    "        else:\n",
    "            steps_in_trial = len( states_sequence) - fence_posts[-1]\n",
    "        t_within_trial = 0\n",
    "        for t in range(\n",
    "                fence_posts[ trial_i], fence_posts[ trial_i] + steps_in_trial ):\n",
    "            previous_w = w\n",
    "            rho *= pi_evaluation[ states_sequence[ t], actions_sequence[ t]] / \\\n",
    "                pi_behavior[ states_sequence[ t], actions_sequence[ t]]\n",
    "            w = rho / weights_normalization[ t_within_trial ]\n",
    "            discount *= gamma\n",
    "            current_trial_estimator += w * discount * rewards_sequence[ t ] - \\\n",
    "                discount * ( w * Q[ states_sequence[ t ], actions_sequence[ t ] ] - \\\n",
    "                             previous_w * V[ states_sequence[ t ] ] )\n",
    "            t_within_trial += 1\n",
    "        individual_trial_estimators += [ current_trial_estimator ]\n",
    "    estimator = np.sum( individual_trial_estimators )\n",
    "\n",
    "    return estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def IS(\n",
    "    states_sequence, actions_sequence, rewards_sequence, fence_posts, gamma,\n",
    "    pi_evaluation, pi_behavior, num_of_states = None, num_of_actions = None ):\n",
    "\n",
    "    num_of_trials = len( fence_posts )\n",
    "    individual_trial_estimators = 0\n",
    "    pi_evaluation = turn_policy_to_stochastic_policy( \\\n",
    "        pi_evaluation, num_of_states = num_of_states, num_of_actions = num_of_actions )\n",
    "    pi_behavior = turn_policy_to_stochastic_policy( \\\n",
    "        pi_behavior, num_of_states = num_of_states, num_of_actions = num_of_actions )\n",
    "    for trial_i in range( num_of_trials ):\n",
    "        rho = 1\n",
    "        discount = 1/gamma\n",
    "        trial_return = 0\n",
    "        if trial_i < num_of_trials - 1:\n",
    "            steps_in_trial = fence_posts[ trial_i+1 ] -  fence_posts[ trial_i ]\n",
    "        else:\n",
    "            steps_in_trial = len( states_sequence) - fence_posts[-1]\n",
    "        for t in range(\n",
    "                fence_posts[ trial_i], fence_posts[ trial_i] + steps_in_trial ):\n",
    "            rho *= pi_evaluation[ t, actions_sequence[ t]] / \\\n",
    "                pi_behavior[ states_sequence[ t], actions_sequence[ t]]\n",
    "            discount *= gamma\n",
    "            trial_return += discount * rewards_sequence[ t ]\n",
    "        individual_trial_estimators += trial_return * rho \n",
    "   \n",
    "    return individual_trial_estimators/num_of_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-70.631292302678901"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WDR(train_state_list, actions, rewards, fence_posts, 0.99, t_table, pi_b, V=V, Q=Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifer Training -- autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss(w):\n",
    "    \n",
    "    probs = get_experts_action_probs(w, train_input.values[:,:-1])\n",
    "    pi_e = probs * encoded_expert1 + (1 - probs) * encoded_expert2\n",
    "    \n",
    "    return IS(train_state_list, actions, rewards, fence_posts, 0.99, pi_e, pi_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -2.84277585e+36   3.46442327e+35  -2.42336258e+34]]\n",
      "[[ 0.68092459  0.98688324  0.45203845]]\n",
      "loss: -3.52625434905e+36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/autograd/tracer.py:48: RuntimeWarning: overflow encountered in exp\n",
      "  return f_raw(*args, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/autograd/numpy/numpy_vjps.py:73: RuntimeWarning: invalid value encountered in multiply\n",
      "  defvjp(anp.exp,    lambda ans, x : lambda g: ans * g)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ nan  nan  nan]]\n",
      "[[  1.42138793e+35  -1.73221163e+34   1.21168129e+33]]\n",
      "loss: nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-316-2bbb58cbab84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgrad_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/autograd/wrap_util.py\u001b[0m in \u001b[0;36mnary_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0munary_operator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munary_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mnary_op_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnary_op_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnary_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnary_operator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/autograd/differential_operators.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(fun, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0marguments\u001b[0m \u001b[0;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbut\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgradient\u001b[0m \u001b[0minstead\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     should be scalar-valued. The gradient has the same type as the argument.\"\"\"\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mvjp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_vjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         raise TypeError(\"Grad only applies to real scalar-output functions. \"\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/autograd/core.py\u001b[0m in \u001b[0;36mmake_vjp\u001b[0;34m(fun, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_vjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mstart_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVJPNode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_root\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mend_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_node\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mend_node\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mvspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/autograd/tracer.py\u001b[0m in \u001b[0;36mtrace\u001b[0;34m(start_node, fun, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mstart_box\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mend_box\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_box\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_box\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mend_box\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trace\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mstart_box\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mend_box\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_box\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/autograd/wrap_util.py\u001b[0m in \u001b[0;36munary_f\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0msubargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubvals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msubargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margnum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-315-c6156b791d6c>\u001b[0m in \u001b[0;36mloss\u001b[0;34m(w)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpi_e\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobs\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mencoded_expert1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mencoded_expert2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mIS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_state_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfence_posts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.99\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpi_e\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpi_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-285-c6b0130b7fb2>\u001b[0m in \u001b[0;36mIS\u001b[0;34m(states_sequence, actions_sequence, rewards_sequence, fence_posts, gamma, pi_evaluation, pi_behavior, num_of_states, num_of_actions)\u001b[0m\n\u001b[1;32m     17\u001b[0m         for t in range(\n\u001b[1;32m     18\u001b[0m                 fence_posts[ trial_i], fence_posts[ trial_i] + steps_in_trial ):\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mrho\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mpi_evaluation\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions_sequence\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m                 \u001b[0mpi_behavior\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mstates_sequence\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions_sequence\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mdiscount\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mtrial_return\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdiscount\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrewards_sequence\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/autograd/numpy/numpy_boxes.py\u001b[0m in \u001b[0;36m__truediv__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__div__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0manp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdivide\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__mod__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0manp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m(\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__truediv__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0manp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrue_divide\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__matmul__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0manp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__radd__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0manp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m     \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/autograd/tracer.py\u001b[0m in \u001b[0;36mf_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0margnums\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margnum\u001b[0m    \u001b[0;32mfor\u001b[0m \u001b[0margnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m   \u001b[0;32min\u001b[0m \u001b[0mboxed_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_wrapped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margnums\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/autograd/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, value, fun, args, kwargs, parent_argnums, parents)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent_argnums\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvjp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprimitive_vjps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_argnums\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minitialize_root\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/autograd/core.py\u001b[0m in \u001b[0;36mvjp_argnums\u001b[0;34m(argnums, ans, args, kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m                 raise NotImplementedError(\n\u001b[1;32m     59\u001b[0m                     \"VJP of {} wrt argnum 0 not defined\".format(fun.__name__))\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mvjp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvjpfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mL\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/autograd/numpy/numpy_vjps.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(ans, x, y)\u001b[0m\n\u001b[1;32m     50\u001b[0m defvjp(anp.logaddexp2,  lambda ans, x, y : unbroadcast_f(x, lambda g: g * 2**(x-ans)),\n\u001b[1;32m     51\u001b[0m                         lambda ans, x, y : unbroadcast_f(y, lambda g: g * 2**(y-ans)))\n\u001b[0;32m---> 52\u001b[0;31m defvjp(anp.true_divide, lambda ans, x, y : unbroadcast_f(x, lambda g: g / y),\n\u001b[0m\u001b[1;32m     53\u001b[0m                         lambda ans, x, y : unbroadcast_f(y, lambda g: - g * x / y**2))\n\u001b[1;32m     54\u001b[0m defvjp(anp.mod,         lambda ans, x, y : unbroadcast_f(x, lambda g: g),\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/autograd/numpy/numpy_vjps.py\u001b[0m in \u001b[0;36munbroadcast_f\u001b[0;34m(target, f)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0munbroadcast_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m     \u001b[0mtarget_meta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0munbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/autograd/tracer.py\u001b[0m in \u001b[0;36mf_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mf_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0margvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mf_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mf_wrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_primitive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grad_loss = grad(loss)\n",
    "for i in range(3):\n",
    "    gradient = grad_loss(w)\n",
    "    print (gradient)\n",
    "    print (w)\n",
    "    w -= 0.05 * gradient\n",
    "    print ('loss:', loss(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
