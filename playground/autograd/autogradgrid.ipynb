{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "from autograd import grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels: [ 0.5]\n",
      "probs: 0.69314718056\n",
      "Initial loss: 0.69314718056\n",
      "labels: Autograd ArrayNode with value [ 0.5] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.69314718056 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.52] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.653162963103 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.54] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.616372393474 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.56] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.582509095259 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.58] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.551322533237 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.59] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.52257922512 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.61] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.496063205428 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.62] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.471575920967 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.64] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.44893571458 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.65] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.42797702761 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.66] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.408549425366 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.68] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.39051652608 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.69] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.373754893259 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.7] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.358152934459 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.71] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.343609835965 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.72] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.330034552524 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.73] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.31734486339 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.74] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.305466500267 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.75] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.294332348684 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.75] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.283881721536 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.76] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.274059701752 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.77] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.264816549915 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.77] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.256107172075 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.78] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.24789064277 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.79] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.240129778266 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.79] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.232790755178 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.8] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.225842769942 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.8] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.219257734874 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.81] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.213010006956 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.81] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.207076145776 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.82] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.201434697456 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.82] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.196066001676 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.83] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.190952019225 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.83] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.186076177802 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.83] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.181423234009 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.84] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.176979149742 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.84] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.17273098137 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.84] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.16866678028 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.85] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.164775503528 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.85] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.161046933502 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.85] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.15747160558 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.86] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.154040742946 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.86] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.150746197769 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.86] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.147580398075 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.87] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.144536299708 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.87] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.14160734283 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.87] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.138787412511 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.87] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.136070802955 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.88] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.133452185021 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.88] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.130926576675 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.88] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.128489316101 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.88] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.12613603719 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.88] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.123862647181 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.89] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.121665306244 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.89] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.119540408807 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.89] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.117484566476 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.89] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.11549459238 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.89] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.113567486821 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.89] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.1117004241 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.9] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.109890740406 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.9] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.108135922694 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.9] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.106433598424 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.9] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.104781526129 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.9] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.103177586697 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.9] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.101619775337 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.9] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.100106194153 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.91] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.0986350452679 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.91] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.0972046244767 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.91] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.0958133153527 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.91] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.0944595837921 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.91] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.0931419729494 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.91] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.0918590985364 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.91] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.0906096444523 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.91] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.0893923587218 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.92] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.0882060497132 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.92] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.0870495826174 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.92] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.0859218761654 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.92] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.0848218995678 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.92] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.0837486696569 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.92] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.0827012482193 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.92] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.081678739501 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.92] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.0806802878757 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.92] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.0797050756616 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.92] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.0787523210777 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.93] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.0778212763279 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.93] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.0769112258056 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.93] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.0760214844087 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.93] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.0751513959575 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.93] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.0743003317094 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.93] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.0734676889621 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.93] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.0726528897406 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.93] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.0718553795616 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.93] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.0710746262704 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.93] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.0703101189444 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.93] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.0695613668614 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.93] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.0688278985248 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.93] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.0681092607455 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.93] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.0674050177746 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.94] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.0667147504839 and 1 progenitors(s)\n",
      "labels: Autograd ArrayNode with value [ 0.94] and 1 progenitors(s)\n",
      "probs: Autograd ArrayNode with value 0.0660380555924 and 1 progenitors(s)\n",
      "labels: [ 0.94]\n",
      "probs: 0.0653745449347\n",
      "Trained loss: 0.0653745449347\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 0.5*(np.tanh(x) + 1)\n",
    "\n",
    "def logistic_predictions(weights, inputs):\n",
    "    # Outputs probability of a label being true according to logistic model.\n",
    "    return sigmoid(np.dot(inputs, weights))\n",
    "\n",
    "def training_loss(weights):\n",
    "    # Training loss is the negative log-likelihood of the training labels.\n",
    "    preds = logistic_predictions(weights, inputs)\n",
    "    label_probabilities = preds * targets + (1 - preds) * (1 - targets)\n",
    "    print (\"labels:\",label_probabilities)\n",
    "    print (\"probs:\",-np.sum(np.log(label_probabilities)))\n",
    "    return -np.sum(np.log(label_probabilities))\n",
    "\n",
    "# Build a toy dataset.\n",
    "# inputs = np.array([[0.52, 1.12,  0.77],\n",
    "#                    [0.88, -1.08, 0.15],\n",
    "#                    [0.52, 0.06, -1.30],\n",
    "#                    [0.74, -2.49, 1.39]])\n",
    "\n",
    "inputs = np.array([[0.52, 1.12,  0.77,0.52, 0.06, -1.30]])\n",
    "targets = np.array([True])\n",
    "\n",
    "# Define a function that returns gradients of training loss using Autograd.\n",
    "training_gradient_fun = grad(training_loss)\n",
    "\n",
    "# Optimize weights using gradient descent.\n",
    "weights = np.array([0.0, 0.0, 0.0,0.0,0.0,0.0])\n",
    "print (\"Initial loss:\", training_loss(weights))\n",
    "for i in range(100):\n",
    "    weights -= training_gradient_fun(weights) * 0.01\n",
    "    #print (logistic_predictions(weights,inputs) > 0.5,\"\\n\", logistic_predictions(weights,inputs))\n",
    "\n",
    "print  (\"Trained loss:\", training_loss(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.17  0.37  0.25  0.17  0.02 -0.43]\n"
     ]
    }
   ],
   "source": [
    "print (weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# general imports \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib \n",
    "\n",
    "import mymacore as ma\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUgAAAEICAYAAAA9TG1fAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110742908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAAEICAYAAADm98d9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nREQF/x+Znzs4fQLGRAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111163f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0\n",
      "PDWDR= 27.4416717948\n",
      "5 1\n",
      "PDWDR= 23.7666357314\n",
      "5 2\n",
      "PDWDR= nan\n",
      "5 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:92: RuntimeWarning: invalid value encountered in true_divide\n",
      "/Users/wihl/Projects/Courses/17Fall/CS282/cs282-f17-xuefeng-yi-david/playground/autograd/rl_functions.py:468: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  w = rho / weights_normalization[ t_within_trial ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDWDR= 24.8648955681\n",
      "5 4\n",
      "PDWDR= 27.2372073094\n",
      "5 5\n",
      "PDWDR= 28.3698437059\n",
      "5 6\n",
      "PDWDR= 28.1849920555\n",
      "5 7\n",
      "PDWDR= 16.7596824779\n",
      "5 8\n",
      "PDWDR= 22.3704738865\n",
      "5 9\n",
      "PDWDR= nan\n",
      "5 10\n",
      "PDWDR= 22.1377042382\n",
      "5 11\n",
      "PDWDR= nan\n",
      "5 12\n",
      "PDWDR= 24.8058868026\n",
      "5 13\n",
      "PDWDR= nan\n",
      "5 14\n",
      "PDWDR= 11.2252065475\n",
      "5 15\n",
      "PDWDR= 24.9098838443\n",
      "5 16\n",
      "PDWDR= 35.0705477169\n",
      "5 17\n",
      "PDWDR= 4.59413251026\n",
      "5 18\n",
      "PDWDR= 28.4655636678\n",
      "5 19\n",
      "PDWDR= 23.1484714158\n",
      "10 0\n",
      "PDWDR= 6.94913541496\n",
      "10 1\n",
      "PDWDR= -46.7013272431\n",
      "10 2\n",
      "PDWDR= 27.3492363993\n",
      "10 3\n",
      "PDWDR= 28.742494274\n",
      "10 4\n",
      "PDWDR= 27.7892287912\n",
      "10 5\n",
      "PDWDR= 25.9611360516\n",
      "10 6\n",
      "PDWDR= 20.7283990999\n",
      "10 7\n",
      "PDWDR= 23.7979996739\n",
      "10 8\n",
      "PDWDR= 26.323229518\n",
      "10 9\n",
      "PDWDR= 21.4158828721\n",
      "10 10\n",
      "PDWDR= 26.6055676444\n",
      "10 11\n",
      "PDWDR= 25.0279162749\n",
      "10 12\n",
      "PDWDR= 25.3315647163\n",
      "10 13\n",
      "PDWDR= 18.8478715694\n",
      "10 14\n",
      "PDWDR= 21.0191539318\n",
      "10 15\n",
      "PDWDR= 28.6827503871\n",
      "10 16\n",
      "PDWDR= nan\n",
      "10 17\n",
      "PDWDR= 14.04868487\n",
      "10 18\n",
      "PDWDR= 32.2600593572\n",
      "10 19\n",
      "PDWDR= 17.9532834665\n",
      "20 0\n",
      "PDWDR= 21.0095681969\n",
      "20 1\n",
      "PDWDR= 23.1387219988\n",
      "20 2\n",
      "PDWDR= 23.0075600674\n",
      "20 3\n",
      "PDWDR= 25.1450168085\n",
      "20 4\n",
      "PDWDR= 20.6968814729\n",
      "20 5\n",
      "PDWDR= 20.7641331904\n",
      "20 6\n",
      "PDWDR= 25.6171514576\n",
      "20 7\n",
      "PDWDR= 23.0150723029\n",
      "20 8\n",
      "PDWDR= 19.9288018212\n",
      "20 9\n",
      "PDWDR= 16.8067073116\n",
      "20 10\n",
      "PDWDR= 26.5314225626\n",
      "20 11\n",
      "PDWDR= 23.9482749458\n",
      "20 12\n",
      "PDWDR= 23.4108667277\n",
      "20 13\n",
      "PDWDR= 20.5186054628\n",
      "20 14\n",
      "PDWDR= 25.9008212928\n",
      "20 15\n",
      "PDWDR= 22.9781134983\n",
      "20 16\n",
      "PDWDR= 24.0946331215\n",
      "20 17\n",
      "PDWDR= 22.4123569992\n",
      "20 18\n",
      "PDWDR= 15.2134506981\n",
      "20 19\n",
      "PDWDR= 30.1399912266\n",
      "40 0\n",
      "PDWDR= 25.4584405118\n",
      "40 1\n",
      "PDWDR= 24.0615586373\n",
      "40 2\n",
      "PDWDR= 24.6523944931\n",
      "40 3\n",
      "PDWDR= 14.4676467727\n",
      "40 4\n",
      "PDWDR= 23.4073568118\n",
      "40 5\n",
      "PDWDR= 22.6353634313\n",
      "40 6\n",
      "PDWDR= 22.6385832807\n",
      "40 7\n",
      "PDWDR= 25.741339357\n",
      "40 8\n",
      "PDWDR= 23.9616874255\n",
      "40 9\n",
      "PDWDR= 19.4746089782\n",
      "40 10\n",
      "PDWDR= 25.1065836354\n",
      "40 11\n",
      "PDWDR= 24.161015071\n",
      "40 12\n",
      "PDWDR= 25.7746081801\n",
      "40 13\n",
      "PDWDR= 23.3519725034\n",
      "40 14\n",
      "PDWDR= 24.7255246294\n",
      "40 15\n",
      "PDWDR= 23.9449012825\n",
      "40 16\n",
      "PDWDR= 24.555386352\n",
      "40 17\n",
      "PDWDR= 21.6635372172\n",
      "40 18\n",
      "PDWDR= 20.160441088\n",
      "40 19\n",
      "PDWDR= 23.6727664648\n",
      "80 0\n",
      "PDWDR= 23.8889389839\n",
      "80 1\n",
      "PDWDR= 17.9930110208\n",
      "80 2\n",
      "PDWDR= 17.6032381384\n",
      "80 3\n",
      "PDWDR= 22.5598813434\n",
      "80 4\n",
      "PDWDR= 24.7102857177\n",
      "80 5\n",
      "PDWDR= 25.6337454987\n",
      "80 6\n",
      "PDWDR= 22.0960018137\n",
      "80 7\n",
      "PDWDR= 22.0829094566\n",
      "80 8\n",
      "PDWDR= 21.3909119126\n",
      "80 9\n",
      "PDWDR= 22.7098241017\n",
      "80 10\n",
      "PDWDR= 24.1738311133\n",
      "80 11\n",
      "PDWDR= 20.4842951103\n",
      "80 12\n",
      "PDWDR= 24.7838023743\n",
      "80 13\n",
      "PDWDR= 19.8036161664\n",
      "80 14\n",
      "PDWDR= 21.0556903489\n",
      "80 15\n",
      "PDWDR= 21.8707502897\n",
      "80 16\n",
      "PDWDR= 19.257478537\n",
      "80 17\n",
      "PDWDR= 22.3973677393\n",
      "80 18\n",
      "PDWDR= 22.7234930585\n",
      "80 19\n",
      "PDWDR= 20.6660117018\n",
      "160 0\n",
      "PDWDR= 22.2931263637\n",
      "160 1\n",
      "PDWDR= 20.6268100737\n",
      "160 2\n",
      "PDWDR= 21.721190071\n",
      "160 3\n",
      "PDWDR= 23.0454977577\n",
      "160 4\n",
      "PDWDR= 21.9657553515\n",
      "160 5\n",
      "PDWDR= 20.7762479843\n",
      "160 6\n",
      "PDWDR= 19.2716576256\n",
      "160 7\n",
      "PDWDR= 18.3474247474\n",
      "160 8\n",
      "PDWDR= 23.6503008059\n",
      "160 9\n",
      "PDWDR= 23.6518673708\n",
      "160 10\n",
      "PDWDR= 22.7208191247\n",
      "160 11\n",
      "PDWDR= 21.2003932339\n",
      "160 12\n",
      "PDWDR= 23.9640112285\n",
      "160 13\n",
      "PDWDR= 22.9439475782\n",
      "160 14\n",
      "PDWDR= 22.0627093905\n",
      "160 15\n",
      "PDWDR= 22.8619842804\n",
      "160 16\n",
      "PDWDR= 23.8046428297\n",
      "160 17\n",
      "PDWDR= 20.9863276487\n",
      "160 18\n",
      "PDWDR= 23.0310555787\n",
      "160 19\n",
      "PDWDR= 23.4597314205\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1118a3ba8>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEOCAYAAACEiBAqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHPFJREFUeJzt3XucVXXd9vHPNQwwIDAMMByFGc+KoiKjiWjepplaqall\nVmZpopWm6V2Zdj6pHczs6bmTssInLC1I7c4TmbdGmTkgyknz8IAHBkWBYVAGmZnv/cde4DgBs2ec\ntffMrOv9eu2Xe6+111rfzbjXtddv/db6KSIwM7PsKil2AWZmVlwOAjOzjHMQmJllnIPAzCzjHARm\nZhnnIDAzyzgHgZlZxjkIzMwyzkFgZpZxDgIzs4wrLXYB+RgxYkRUV1cXuwwzsx5l/vz5L0dEZXvv\n6xFBUF1dTW1tbbHLMDPrUSStyOd9bhoyM8s4B4GZWcY5CMzMMi61IJA0XtJ9kpZKWiLpolbzLpT0\neDL9u2nVYGZm7UvzZHETcGlELJA0GJgvaS4wCjgJOCAiNkkamWINZmbWjtSCICLqgLrkeYOkZcA4\n4FzgqojYlMx7Ka0azMysfQU5RyCpGpgMPATsCRwh6SFJ90s6uBA1mJnZtqV+HYGkQcBs4OKIWC+p\nFBgGHAocDNwiaddoM3iypOnAdIAJEyakXab1YKdf/yAAN583tciVmPVMqR4RSOpLLgRmRcScZPLz\nwJzI+SfQAoxou2xEzIiImoioqaxs98I4MzPrpDR7DQm4AVgWEde0mnUrcFTynj2BfsDLadVhZmY7\nlmbT0DTgTGCRpIXJtMuBXwC/kLQYeB04q22zkJmZFU6avYbmAdrO7I+ktV0zM+sYX1lsZpZxDgIz\ns4xzEJj1QKdf/+DWbrNmb5WDwMws4xwEZmYZ5yAwM8s4B4GZWcY5CMzMMs5BYGaWcQ4CM7OMcxCY\nmWWcg8DMLOMcBGZmGecgMDPLOAeBmVnGOQjMzDLOQWBmlnEOAjOzjHMQmJllnIPAzCzjHARmZhmX\nWhBIGi/pPklLJS2RdFEy/WuSXpC0MHmckFYNZmbWvtIU190EXBoRCyQNBuZLmpvM+2FEfD/FbZuZ\nWZ5SC4KIqAPqkucNkpYB49LanpmZdU5BzhFIqgYmAw8lky6U9JikX0iqKEQNZma2bakHgaRBwGzg\n4ohYD/wXsCtwILkjhh9sZ7npkmol1a5evTrtMs3MMivVIJDUl1wIzIqIOQAR8WJENEdEC/Az4JBt\nLRsRMyKiJiJqKisr0yzTzCzT0uw1JOAGYFlEXNNq+phWb3sfsDitGszMrH1p9hqaBpwJLJK0MJl2\nOXCGpAOBAJYD56VYg5mZtSPNXkPzAG1j1h1pbdPMzDrOVxabmWWcg8DMLOMcBGZmGecgMDPLOAeB\nmVnGOQjMzDLOQWBmlnEOAjOzjHMQmJllnIPAzCzjHARmZhnnIDAzyzgHgZlZxjkIzMwyzkFgZpZx\nDgIzs4xzEJiZZZyDwMws4xwEZmYZ5yAwM8s4B4GZWcalFgSSxku6T9JSSUskXdRm/qWSQtKItGow\nM7P2laa47ibg0ohYIGkwMF/S3IhYKmk8cCzwbIrbNzOzPKR2RBARdRGxIHneACwDxiWzfwh8Hoi0\ntm9mZvkpyDkCSdXAZOAhSScBL0TEo4XYtpmZ7ViaTUMASBoEzAYuJtdcdDm5ZqH2lpsOTAeYMGFC\nmiWaWQ9w+vUPAnDzeVOLXEnvk+oRgaS+5EJgVkTMAXYDdgEelbQc2BlYIGl022UjYkZE1ERETWVl\nZZplmpllWrtBIGmUpBsk3Zm8nijpnDyWE3ADsCwirgGIiEURMTIiqiOiGngeOCgiVr2lT2FmZp2W\nzxHBr4C7gbHJ63+Ra+ZpzzTgTOAdkhYmjxM6VaWZmaUmn3MEIyLiFklfBIiIJknN7S0UEfMAtfOe\n6ryqNDOz1ORzRPCqpOEkXT0lHQrUp1qVmZkVTD5HBJcAtwO7SfobUAmclmpVZmZWMO0GQXJl8JHA\nXuSaep6IiM2pV2ZmZgXRbhBI+mibSQdJIiJuTKkmMzMroHyahg5u9bwMOBpYADgIzMx6gXyahi5s\n/VrSUOC3qVVkZmYF1Zkri18ld3WwmZn1AvmcI/gjb9wltASYCNySZlFmZla4+yvlc47g+62eNwEr\nIuL5lOoxM7MCy+ccwf2FKMTMzIpju0EgqYFtDxwjICJiSGpVmZlZwWw3CCJicCELMTOz4sh7YBpJ\nI8ldRwBARHi8YTOzXiCf8QhOlPQk8P+B+4HlwJ0p12VmZgWSz3UE3wQOBf4VEbuQu7L4H6lWZWZm\nBZNPEGyOiFeAEkklEXEfUJNyXWZmViD5nCNYlwxA/wAwS9JL5K4uNjOzXiCfI4KTgNeAzwJ3AU8D\n702zKDMzK5x8jgjOA26OiBeAmSnXY2ZmBZZPEAwG7pG0BrgZ+F1EvJhuWWa2LS+tb6R2xVqeXfMa\nQ8ry7v1ttkP53GLi68DXJe0PnA7cL+n5iDgm9erMMqylJXhq9QYeXr6G+cvX8vCKNTy3ZuPW+XX1\ncOFvHuGr753IiEH9i1ip9XQd+UnxErAKeAUYmU45ZtnVuLmZR59bR+2KtcxPHvUbc6PCjhjUn5qq\nCs6aWk1N9TC+9d9Lqatv5O7Fq/jrk6v50rsncupB45BU5E9hPVE+t6H+FPABcoPW/w44NyKW5rHc\neHKjmI0id8+iGRHxI0nfJHcCuoVcuHwsIlZ2/iOY9UyvbNi0daf/8PI1LH6hns3Nudt77T5yEMfv\nN5qa6mHUVFVQNXzgm3byfUrEzhUDmHn2wVw2exH/+btHufWRF/jO+yYxYfjAYn0k66HyOSIYD1wc\nEQs7uO4m4NKIWCBpMDBf0lzgexHxZQBJnwG+ApzfwXWb9SgRwTMvv8r85WupXbGG2uVreeblXC/s\nfn1K2H/ncs45fFdqqiqYUlVBxU798lrv7iMHc8t5U5n1z2e5+s7HOfba+7nknXty9rRdKO3TmXGn\nLIvyOUfwxc6sOCLqgLrkeYOkZcC4NkcTO7HtO5ya9WivN7Ww6IV65q9Yw8PL17JgxVpeefV1AIYO\n7EtNVQUfOHg8NVUV7DeunLK+fTq9rZISceahVRyzz0i+fOsSvnPH49z+6EquOmV/9htX3lUfyXqx\ngnQ7kFQNTAYeSl5/G/goUA8cVYgazNJU/9pm5j+b+6Vfu3wtjz6/jk1NLQBUDx/IUXuPpKaqgprq\nCnYdMYiSkq5vyx9TPoCffXQKdy5exVduW8JJP/kb5x6xKxcfs8dbChrr/VIPguSq5NnkmpfWA0TE\nFcAVkr4IXAB8dRvLTQemA0yYMCHtMs3yFhE8t2Yjtcmv/fkr1vCvFzcAUFoi9h1XzpmHVlFTXcGU\nqmFUDi5cjx5JnDBpDNN2G8F37ljGT+9/mjsX13Hl+yZx2O4jClaH9Sw7DAJJfYA/R0SnfrVL6ksu\nBGZFxJxtvGUWcAfbCIKImAHMAKipqXHzkRVNU3MLS+vWb93p1y5fy0sNmwAYXFbKlKoKTjxgLFOq\nhnHg+KEM6Ff8X9/lA/ty9Wn7c9LksVw+ZxEf+vlDfKBmZ644YSLlA/sWuzzrZnYYBBHRLKlFUnlE\n1Hdkxcp1cbgBWBYR17SavkdEPJm8PAl4vKNFm6WpoXEzjzy7jtrla6hdsZZHnl3Hxs3NAIwbOoDD\ndhvOlOphHFxdwZ4jB6fSzNNVDtttBHdd/HZ+dO+TzHjgGf7y+Gq+fuK+nDBptLua2lb5NA1tABYl\nPX623mwuIj7TznLTgDOTZbf0OLocOEfSXuS6j67APYasyFau25i7aGtFrn3/8VXraQkoEewzZgin\nHzyeKUn7/pjyAcUut8PK+vbhC8ftzXv2H8Nlsxfx6ZsWcMw+I/nmyfv1yM9jXS+fIJiTPDokIuaR\nG9+4rTs6ui6zrtLcEjyxqmFrF87a5WtYWd8IwMB+fThoQgUXvmMPDq4exoEThjKof++5jcO+Y8v5\nw6cO45d/W84P5j7BO695gC8ctxcffltVtz6qsfTl0310pqR+wJ7JpCciYnO6ZZl1jddeb2Lhs7mr\ndWtXrOWRFWtp2NQEwKgh/ampHsa5VRUcXD2MvUcP7vV970v7lHDu23flXfuO5opbF/Hl25Zw68KV\nXHXKJPYY5WHKsyqfK4v/g9xdR5eT+4U/XtJZEfFAuqWZddyWm7LVJhduLVm5nuaWQIK9Rg3mxAPH\ncnD1MKZUVbBzxYDMtpNPGD6QG88+hDkLXuCbf1rKu6+bx6eO2o1P/sdu9C8t/sluK6x8jnt/ABwb\nEU8ASNoT+A0wJc3CzPL1UsMmGho38/bv3seza14DoH9pCQeOH8r5R+5KTfUwDppQQfkA95ZpTRKn\nTtmZI/eq5Bt/XMq1f36SPz1Wx1Wn7s+Uqopil2cFlE8Q9N0SAgAR8a+kW6hZt/Di+kZeb2phSlXF\n1v77+44tp19p727m6SojBvXnujMmc/LksXzpD4s57ad/56OHVvG54/buVedIbPvy+SvXSvo58Ovk\n9YeB2vRKMuuYvUcPprREXH+mh9J+K96x9yjuuWQ437/7CWY+uJx7lr7It07ej6P3GVXs0ixl+fxk\n+iSwFPhM8liKu3xaN9K3T0lm2/q72qD+pXztxH2Z/cnDGFxWyjkza7ngpgWsTi6gs94pnyA4PyKu\niYhTkscPyYWDmfVSB02o4L8vPIJL3rkn9yx5kWOuuZ/f1T5HhC/y743yCYKztjHtY11ch5l1M/1K\nS/jM0Xtwx0WHs+eoQXzu94/xkRseYsUrr7a/sPUo2w0CSWdI+iOwi6TbWz3uA9YUrkQzK6bdRw7m\n5ulT+dbJ+/Hoc/W869oHmPHA0zQ1txS7NOsiOzpZ/Hdy4wmMINeFdIsG4LE0izKz7qWkRHzk0CqO\n2WcUX75tscc86GW2GwQRsYLcvYCmFq4cM+vORpeXMePMKdy1eBVfuT035sEnjtiFi4/es1vcddU6\nR+2d/JF0KPBjYB+gH9AHeDUihqRfXk5NTU3U1naix+qdl8GqRV1fkHUrS+pyN8bdd0x2fpl2h89c\n39yfK1dP5bf1E6nqW8+Vo/6Hw3Z6IbXtdYfPXGhL6upZUbobJ3x+ZqeWlzQ/ItrtV53PyeL/A5wB\nPAkMAD4B/KRTVZlZr1HeZxNXjf4fbhp/KyL40PMn8flVR7GuuXAD8VjXyOuywYh4SlKfiGgGfinp\nEaBTYxkX1PFXFbsCK4BvXP8gADd/PDutmN3pMx8G3LW5ORnzQPyl+QC+duK+vHvSmC69vqM7feZC\n2fKZT0h5O/kcEbyW3H10oaTvSvpsnsuZWUZsGfPg9gumMaZ8ABfc9Ajn3ljLynUbi12a5SGfHfqZ\n5M4LXEBuYJrxwKlpFmVmPdOWMQ++9O59mPfUy7zzmvu58cHltLT4QrTurN0giIgVEbExItZHxNcj\n4pKIeKoQxZlZz1Pap4RPHLEr91x8JAdVVfCV25bw/usf5MkXG4pdmm1Hu0Eg6T2SHpG0RtJ6SQ2S\n1heiODPrubaMefCD9x/A06s3cMJ1f+XaP/+LTU3NxS7N2sinaehacreZGB4RQyJicCG7jppZz7Vl\nzIM/X3IkJ0waw7V/fpL3XDeP+St8c4LuJJ8geA5YHL7blJl10ohB/fnRByfzy48dzKubmjjtpw/y\nldsW09DoUW+7g3y6j34euEPS/cDWe9FGxDWpVWVmvdJRe4/knkuO3DrmwVyPefAmm5qaWVXfyMp1\njaxav5EX1m1kxE79Ut9uPkHwbWADUEbuyuK8SBoP3AiMAgKYERE/kvQ94L3A68DTwMcjYl1HCzez\nnmnLmAcnHjiWy2Y/xjkza3nP/mP46nv3pXJw770Y7fWmFl5c38jKdRtZtT63s6+r30hdffLfdY28\n8urr/7bcwALcuiOfIBgbEft1Yt1NwKURsUDSYGC+pLnAXOCLEdEk6WpyF6Z9oRPrN7MebMuYB9ff\n/zQ//stT/PXJl7ni3fvw/ik797iBhjY353bydfXJjr6+1fNkp//yhn8f3GdIWSljygcwZmgZk8aV\n556Xl22d9oXfP0afkvT/LfIJgjskHRsR93RkxRFRR+7upUREg6RlwLg26/kHcFpH1mtmvUe/0hIu\nPHoPjp80hsvnLOLzv3+M2xa+wHfeN4mq4TsVuzwAmppbeKlhE3X1G3NNNvWNrEx+wdetb6Ru3UZW\nb9hE27Oog/uXMrq8jDFDBzBxzBBGl5cxNtnBjykvY3T5gHbHhC5ECEB+QfBJ4D8lbQI2AwKiIz2H\nJFUDk4GH2sw6G7g53/WYWe+0+8hB/Hb6ofzm4We56o7Hede1D/DZY/bknMN3obRPejcyaG4JVjds\nemPH3rqppr6RunWNvNTQSNvr4Qb268OY8jLGDh3AXntVMrp8AGOTnX7uF30Zg8v6plZ3V2s3CCJi\n8FvZgKRBwGzg4ohY32r6FeSaj2ZtZ7npwHSACRMmvJUSzKwHKCkRH35bFUfvnRvz4Mo7c2MeXH1q\n58Y8aG4JXt6wKdmhb2RlfSOr6nP/rUuab15s2ERzm738gL59tv5qP3yPEYxNfr2PGZr7RT+6vIwh\nZaU9rvlqR7YbBJL2jojHJR20rfkRsaC9lUvqSy4EZkXEnFbTPwa8Bzh6e91SI2IGMANyt6Fub1tm\n1jtsc8yDw3ehuSW2NpW0tAQvv7ppaw+buvqNSZNNbidfV9/Ii+sbaWqzk+9fWsLY5Ff7obsN37pj\nHzu0bGv7fPmAvr1qJ5+PHR0RXELuF/kPtjEvgHfsaMXK/UveACxr3dVU0nHkuqQeGRGvdbhiM+v1\nJHH8pDEcttsIrrprGdc/8Az9S0vo16eEI777F1bVN7K5+c07+X6lJVubZQ7ZZVju+dABjBlStvXX\n/NCB2dvJ52NHI5RNT54eHxGNredJKstj3dPI3bBukaSFybTLgeuA/sDc5A/yj4g4v6OFm1nvVz6w\nL1eesj8nHjCO6TfWgmDKhIpcm/zQMkYPKdv6C3/YTv28k++kfE4W/x1o2zy0rWlvEhHzyJ1YbuuO\n/EozM8uZuttwJo7N9U+59oOTi1xN77OjcwSjgXHAAEmTeWOnPgQYWIDazMysAHZ0RPAu4GPAzuTO\nE2wJggZyTTxmZtYL7OgcwUxgpqRTI2J2AWsyM7MCyudKjZ0lDVHOzyUtkHRs6pWZmVlB5BMEZycX\ngh0LDCfXE8ijwpuZ9RL5BMGWcwMnADdGxBK23RvIzMx6oHyCYL6ke8gFwd3JnURb0i3LzMwKJZ/r\nCM4BDgSeiYjXJA0HPp5uWWZmVij5HBEEMBH4TPJ6J3KD1JiZWS+QTxD8X2AqcEbyugH4SWoVmZlZ\nQeXTNPS2iDhI0iMAEbFWUvqDaJqZWUHkc0SwWVIfck1ESKrEJ4vNzHqNfILgOuAPwEhJ3wbmAd9J\ntSozMyuYfEYomyVpPnA0uesHTo6IZalXZmZmBZHPOQIi4nHg8ZRrMTOzIkhvVGgzM+sRHARmZhnn\nIDAzyzgHgZlZxjkIzMwyzkFgZpZxqQWBpPGS7pO0VNISSRcl09+fvG6RVJPW9s3MLD95XUfQSU3A\npRGxIBnDYL6kucBi4BTg+hS3bWZmeUotCCKiDqhLnjdIWgaMi4i5AJIHOTMz6w4Kco5AUjUwGXio\nENszM7P8pR4EkgYBs4GLI2J9B5abLqlWUu3q1avTK9DMLONSDQJJfcmFwKyImNORZSNiRkTURERN\nZWVlOgWamVmqvYYE3AAsi4hr0tqOmZm9NWn2GpoGnAkskrQwmXY50B/4MVAJ/EnSwoh4V4p1mJnZ\nDqTZa2geufELtuUPaW3XzMw6xlcWm5llnIPAzCzjHARmZhnnIDAzyzgHgZlZxjkIzMwyzkFgZpZx\naV5QZmYpufm8qcUuwQqgUH9nHxGYmWWcg8DMLOMcBGZmGecgMDPLOAeBmVnGOQjMzDLOQWBmlnEO\nAjOzjHMQmJllnIPAzCzjHARmZhnnIDAzyzgHgZlZxjkIzMwyLrUgkDRe0n2SlkpaIumiZPowSXMl\nPZn8tyKtGszMrH1pHhE0AZdGxETgUODTkiYClwH3RsQewL3JazMzK5LUgiAi6iJiQfK8AVgGjANO\nAmYmb5sJnJxWDWZm1r6CnCOQVA1MBh4CRkVEXTJrFTBqO8tMl1QrqXb16tWFKNPMLJNSDwJJg4DZ\nwMURsb71vIgIILa1XETMiIiaiKiprKxMu0wzs8xKNQgk9SUXArMiYk4y+UVJY5L5Y4CX0qzBzMx2\nLM1eQwJuAJZFxDWtZt0OnJU8Pwu4La0azMysfaUprnsacCawSNLCZNrlwFXALZLOAVYAH0ixBjMz\na0dqQRAR8wBtZ/bRaW3XzMw6xlcWm5llnIPAzCzj0jxHYGbWZW4+b2qxS+i1fERgZpZxDgIzs4xz\nEJiZZZyDwMws4xwEZmYZ5yAwM8s4B4GZWcY5CMzMMs4XlFmP5wuNzN4aHxGYmWWcg8DMLOMcBGZm\nGecgMDPLOAeBmVnGOQjMzDLOQWBmlnEOAjOzjHMQmJllnCKi2DW0S9JqYEUnFy8H6t/C5ju7fEeW\n6+r3jgBeznN9vcVb/Tt3tULU05Xb6Anfk46839+TnKqIqGz3XRHRqx/AjGIs35Hluvq9QG2x/917\n2t+5J9bTldvoCd+Tjrzf35OOPbLQNPTHIi3fkeXSem+WdLd/l0LU05Xb6Anfk468v7v9/9Ct9Yim\nIesYSbURUVPsOsy6M39P3pCFI4IsmlHsAsx6AH9PEj4iMDPLOB8RmJllnIPAzCzjHARmZhnnIMgA\nSbtKukHS74tdi1l3JelkST+TdLOkY4tdTyE5CHooSb+Q9JKkxW2mHyfpCUlPSboMICKeiYhzilOp\nWfF08Htya0ScC5wPnF6MeovFQdBz/Qo4rvUESX2AnwDHAxOBMyRNLHxpZt3Gr+j49+RLyfzMcBD0\nUBHxALCmzeRDgKeSI4DXgd8CJxW8OLNuoiPfE+VcDdwZEQsKXWsxOQh6l3HAc61ePw+MkzRc0k+B\nyZK+WJzSzLqNbX5PgAuBY4DTJJ1fjMKKpbTYBVj6IuIVcu2eZrYdEXEdcF2x6ygGHxH0Li8A41u9\n3jmZZmZv8PekDQdB7/IwsIekXST1Az4I3F7kmsy6G39P2nAQ9FCSfgM8COwl6XlJ50REE3ABcDew\nDLglIpYUs06zYvL3JD++6ZyZWcb5iMDMLOMcBGZmGecgMDPLOAeBmVnGOQjMzDLOQWBmlnEOArPt\nkPQNScd0wXo2dEU9ZmnxdQRmKZO0ISIGFbsOs+3xEYFliqSPSPqnpIWSrpfUR9IGST+UtETSvZIq\nk/f+StJpyfOrJC2V9Jik7yfTqiX9JZl2r6QJyfRdJD0oaZGkb7XZ/uckPZws8/Vk2k6S/iTpUUmL\nJWVqUBQrPgeBZYakfciNPDUtIg4EmoEPAzsBtRGxL3A/8NU2yw0H3gfsGxH7A1t27j8GZibTZvHG\nnSt/BPxXREwC6lqt51hgD3L3wz8QmCLp7eQGTlkZEQdExH7AXV3+4c12wEFgWXI0MAV4WNLC5PWu\nQAtwc/KeXwOHt1muHmgEbpB0CvBaMn0qcFPy/P+1Wm4a8JtW07c4Nnk8AiwA9iYXDIuAd0q6WtIR\nEVH/Fj+nWYd4PALLEpH7Bf+mwXkkfbnN+9504iwimiQdQi44TiN3w7J3tLOtbZ18E3BlRFz/bzOk\ng4ATgG9JujcivtHO+s26jI8ILEvuJTf61EgAScMkVZH7HpyWvOdDwLzWC0kaBJRHxB3AZ4EDkll/\nJ3cLY8g1Mf01ef63NtO3uBs4O1kfksZJGilpLPBaRPwa+B5wUFd8WLN8+YjAMiMilkr6EnCPpBJg\nM/Bp4FXgkGTeS+TOI7Q2GLhNUhm5X/WXJNMvBH4p6XPAauDjyfSLgJskfQG4rdX270nOUzwoCWAD\n8BFgd+B7klqSmj7ZtZ/cbMfcfdQyz907LevcNGRmlnE+IjAzyzgfEZiZZZyDwMws4xwEZmYZ5yAw\nM8s4B4GZWcY5CMzMMu5/Aa7oLpapkvrVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110e72f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEOCAYAAACTqoDjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBYSIiAT1/wEAhV9UgMPPcgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111837c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# created by us \n",
    "import gridworld \n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "import rl_functions as rlfun\n",
    "from gridworld_generate_true_MDP import gridworld_true_MDP\n",
    "\n",
    "np.set_printoptions( precision = 2 )\n",
    "\n",
    "# ---------------------- #\n",
    "#   Different Domains    #\n",
    "# ---------------------- #\n",
    "# You can also create your own!  The interpretation of the different symbols is\n",
    "# the following:\n",
    "#\n",
    "# '#' = wall\n",
    "# 'o' = origin grid cell\n",
    "# '.' = empty grid cell\n",
    "# '*' = goal\n",
    "test_maze = [   # HERE: Make this one bigger, probably! \n",
    "    '#########',\n",
    "    '#..#....#',\n",
    "    '#..#..#.#',\n",
    "    '#..#..#.#',\n",
    "    '#..#.##.#',\n",
    "    '#....*#.#',\n",
    "    '#######.#',\n",
    "    '#o......#',\n",
    "    '#########']\n",
    "\n",
    "cliffworld = [\n",
    "    '#######', \n",
    "    '#.....#', \n",
    "    '#.##..#', \n",
    "    '#o...*#',\n",
    "    '#XXXXX#', \n",
    "    '#######']    \n",
    "\n",
    "short_hallway = [   \n",
    "    '###', # '#' = wall\n",
    "    '#o#', # 'o' = origin grid cell\n",
    "    '#.#', # '.' = empty grid cell\n",
    "    '#*#', # '*' = goal\n",
    "    '###']\n",
    "\n",
    "long_hallway = [   \n",
    "    '###', # '#' = wall\n",
    "    '#o#', # 'o' = origin grid cell\n",
    "    '#.#', # '.' = empty grid cell\n",
    "    '#.#', # '.' = empty grid cell\n",
    "    '#.#', # '.' = empty grid cell\n",
    "    '#.#', # '.' = empty grid cell\n",
    "    '#.#', # '.' = empty grid cell\n",
    "    '#.#', # '.' = empty grid cell\n",
    "    '#.#', # '.' = empty grid cell\n",
    "    '#*#', # '*' = goal\n",
    "    '###']\n",
    "\n",
    "simple_grid = [   \n",
    "    '#######', \n",
    "    '#o....#', \n",
    "    '#..X..#', \n",
    "    '#....*#', \n",
    "    '#######']    \n",
    "\n",
    "# ----------------- #\n",
    "#   Key Functions   # \n",
    "# ----------------- #\n",
    "# The policy outputs the action for each states \n",
    "#def policy( state , Q_table , action_count , epsilon ):\n",
    "#    if np.random.random() < epsilon:\n",
    "#        action = np.random.choice( action_count ) \n",
    "#    else: \n",
    "#        action = np.argmax( Q_table[ state , : ] ) \n",
    "#    return action \n",
    "\n",
    "# Takes in count table and updates it\n",
    "def update_count_table( transition_count_table , reward_value_table , state , action , new_state , reward ):\n",
    "    transition_count_table[ state, action, new_state ] += 1\n",
    "    reward_value_table[ state, action, new_state ] = reward\n",
    "    return transition_count_table , reward_value_table \n",
    "\n",
    "# Takes in counts and builds an MDP using the RMAX approach (unseen rewards set\n",
    "# to rmax, use the empirical counts for the transition frequencies)\n",
    "def build_MDP_RMAX( transition_count_table , reward_value_table , rmax , gamma ):\n",
    "    state_count = np.shape( transition_count_table )[0]\n",
    "    action_count = np.shape( transition_count_table )[1]\n",
    "    state_action_observations = np.sum( transition_count_table, axis = 2 )\n",
    "    state_action_observations = np.reshape( state_action_observations, \n",
    "        ( state_count, action_count, 1) )\n",
    "    transition_matrix = transition_count_table / np.tile(\n",
    "            state_action_observations, [ 1, 1, state_count ])\n",
    "    indices_for_unobserved_transition_probabilities = np.tile(\n",
    "            state_action_observations == 0, [ 1, 1, state_count ])\n",
    "    transition_matrix[ indices_for_unobserved_transition_probabilities ] = \\\n",
    "        1/state_count \n",
    "    rewards_matrix = np.copy(reward_value_table)\n",
    "    sas_not_observed = np.sum( transition_count_table, axis = (0,1) ) == 0\n",
    "    rewards_matrix[ sas_not_observed ] = rmax\n",
    "    MDP = {\n",
    "        'T' : transition_matrix,\n",
    "        'R' : rewards_matrix,\n",
    "        'gamma' : gamma,\n",
    "        'state_count' : state_count,\n",
    "        'action_count' : action_count}\n",
    "    return MDP\n",
    "\n",
    "# Takes in counts and samples and MDP \n",
    "#def sample_MDP( transition_count_table , reward_value_table , Dirichlet_alpha , default_reward ):\n",
    "#    state_count = np.shape( transition_count_table )[0]\n",
    "#    action_count = np.shape( transition_count_table )[1]\n",
    "#    state_action_observations = np.sum( transition_count_table, axis = 2 )\n",
    "#    state_action_observations = np.reshape( state_action_observations, \n",
    "#        ( state_count, action_count, 1) )\n",
    "#    transition_matrix = np.zeros( np.shape( transition_count_table ) )\n",
    "#    for state_ind in range( state_count ):\n",
    "#        for action_ind in range( action_count ):\n",
    "#            transition_matrix[ state_ind, action_ind, : ] = \\\n",
    "#                np.random.dirichlet( transition_count_table[ state_ind, action_ind, : ] + \\\n",
    "#                Dirichlet_alpha )\n",
    "#    rewards_matrix = np.copy(reward_value_table)\n",
    "#    sas_not_observed = np.sum( transition_count_table, axis = (0,1) ) == 0\n",
    "#    rewards_matrix[ sas_not_observed ] = default_reward\n",
    "#    MDP = {\n",
    "#        'T' : transition_matrix,\n",
    "#        'R' : rewards_matrix,\n",
    "#        'gamma' : gamma,\n",
    "#        'state_count' : state_count,\n",
    "#        'action_count' : action_count}\n",
    "#    return MDP\n",
    "\n",
    "# Solve MDP\n",
    "def solve_MDP( MDP ):\n",
    "    state_count = MDP['state_count']\n",
    "    action_count = MDP['action_count']\n",
    "    T = MDP['T']\n",
    "    R = MDP['R']\n",
    "    gamma = MDP['gamma']\n",
    "    Q_table = np.zeros( ( state_count, action_count ) )\n",
    "    V = np.zeros( state_count )\n",
    "    for iter_number in range(200):\n",
    "        for state_ind in range( state_count ):\n",
    "            for action_ind in range( action_count ):\n",
    "                expected_reward = np.sum(T[ state_ind, action_ind, : ] * \\\n",
    "                    R[ state_ind, action_ind, : ] )\n",
    "                expected_value_of_next_state = np.sum( T[ state_ind, action_ind, : ] * V )\n",
    "                Q_table[ state_ind, action_ind ] = expected_reward + \\\n",
    "                    gamma * expected_value_of_next_state\n",
    "            V[ state_ind ] = np.max( Q_table[ state_ind, :] )\n",
    "    return Q_table\n",
    "\n",
    "# -------------------- #\n",
    "#   Create the Task    #\n",
    "# -------------------- #\n",
    "# Task Parameters for gridworld \n",
    "task_name = cliffworld\n",
    "action_error_prob = 0.2\n",
    "pit_reward = -50\n",
    "task = gridworld.GridWorld( task_name ,\n",
    "                            action_error_prob=action_error_prob, \n",
    "                            rewards={'*': 50, 'moved': -1, 'hit-wall': -1,'X':pit_reward} ,\n",
    "                            terminal_markers='*' )        \n",
    "\n",
    "gamma1 = 0.95\n",
    "gamma2 = 0.25\n",
    "state_count = task.num_states  \n",
    "action_count = task.num_actions \n",
    "true_MDP1 = gridworld_true_MDP( task_name, action_error_prob, pit_reward, gamma1 )\n",
    "Q_table1 = solve_MDP( true_MDP1 )\n",
    "true_MDP2 = gridworld_true_MDP( task_name, action_error_prob, pit_reward, gamma2 )\n",
    "Q_table2 = solve_MDP( true_MDP2 )\n",
    "\n",
    "# -------------- #\n",
    "#   Make Plots   #\n",
    "# -------------- #\n",
    "# Note, these are plots that are useful for visualizing the policies\n",
    "# and the value functions, which can help you identify bugs.  You can\n",
    "# also use them as a starting point to create the plots that you will\n",
    "# need for your homework assignment.\n",
    "\n",
    "# Util to make an arrow \n",
    "# The directions are [ 'north' , 'south' , 'east' , 'west' ] \n",
    "def plot_arrow( location , direction , plot ):\n",
    "\n",
    "    arrow = plt.arrow( location[0] , location[1] , dx , dy , fc=\"k\", ec=\"k\", head_width=0.05, head_length=0.1 )\n",
    "    plot.add_patch(arrow) \n",
    "\n",
    "# Useful stats for the plot\n",
    "row_count = len( task_name )\n",
    "col_count = len( task_name[0] ) \n",
    "value_function1 = np.reshape( np.max( Q_table1 , 1 ) , ( row_count , col_count ) )\n",
    "policy_function1 = np.reshape( np.argmax( Q_table1 , 1 ) , ( row_count , col_count ) )\n",
    "value_function2 = np.reshape( np.max( Q_table2 , 1 ) , ( row_count , col_count ) )\n",
    "policy_function2 = np.reshape( np.argmax( Q_table2 , 1 ) , ( row_count , col_count ) )\n",
    "\n",
    "wall_info = .5 + np.zeros( ( row_count , col_count ) )\n",
    "wall_mask = np.zeros( ( row_count , col_count ) )\n",
    "for row in range( row_count ):\n",
    "    for col in range( col_count ):\n",
    "        if task_name[row][col] == '#':\n",
    "            wall_mask[row,col] = 1     \n",
    "wall_info = ma.masked_where( wall_mask==0 , wall_info )\n",
    "value_function1 *= (1-wall_mask)**2\n",
    "value_function2 *= (1-wall_mask)**2\n",
    "\n",
    "# value function plot \n",
    "#plt.subplot( 1 , 2 , 2 ) \n",
    "plt.imshow( value_function1 , interpolation='none' , cmap=matplotlib.cm.jet )\n",
    "plt.colorbar()\n",
    "plt.imshow( wall_info , interpolation='none' , cmap=matplotlib.cm.gray )\n",
    "plt.title( 'Value Function1, gamma = {0:.2f}'.format(gamma1) )\n",
    "plt.show()\n",
    "plt.imshow( value_function2 , interpolation='none' , cmap=matplotlib.cm.jet )\n",
    "plt.colorbar()\n",
    "plt.imshow( wall_info , interpolation='none' , cmap=matplotlib.cm.gray )\n",
    "plt.title( 'Value Function2, gamma = {0:.2f}'.format(gamma2) )\n",
    "\n",
    "\n",
    "plt.show()\n",
    "# policy plot \n",
    "# plt.imshow( 1 - wall_mask , interpolation='none' , cmap=matplotlib.cm.gray )    \n",
    "# for row in range( row_count ):\n",
    "#     for col in range( col_count ):\n",
    "#         if wall_mask[row][col] == 1:\n",
    "#             continue \n",
    "#         if policy_function1[row,col] == 0:\n",
    "#             dx = 0; dy = -.5\n",
    "#         if policy_function1[row,col] == 1:\n",
    "#             dx = 0; dy = .5\n",
    "#         if policy_function1[row,col] == 2:\n",
    "#             dx = .5; dy = 0\n",
    "#         if policy_function1[row,col] == 3:\n",
    "#             dx = -.5; dy = 0\n",
    "#         plt.arrow( col , row , dx , dy , shape='full', fc='w' , ec='w' , lw=3, length_includes_head=True, head_width=.2 )\n",
    "# plt.title( 'Policy' )        \n",
    "# plt.show( block=False ) \n",
    "\n",
    "# -------------------------- #\n",
    "# Off-policy evaluation part #    \n",
    "# -------------------------- #\n",
    "\n",
    "episode_count__list = [ 5, 10, 20, 40, 80, 160]#, 360, 640, 1280, 2560 ]\n",
    "num_of_tests = 20\n",
    "epsilon = 0.2\n",
    "pi_optimal1 = np.argmax( Q_table1, axis = 1 )\n",
    "pi_optimal1 = rlfun.turn_policy_to_stochastic_policy(\n",
    "    pi_optimal1, num_of_states = state_count, num_of_actions = action_count )\n",
    "pi_optimal2 = np.argmax( Q_table2, axis = 1 )\n",
    "pi_optimal2 = rlfun.turn_policy_to_stochastic_policy(\n",
    "    pi_optimal2, num_of_states = state_count, num_of_actions = action_count )\n",
    "pi_random  = np.ones( (state_count, action_count) ) / action_count\n",
    "pi_eps_greedy1 = pi_optimal1 * ( 1 - epsilon ) + epsilon / 4\n",
    "pi_behavior1 = pi_eps_greedy1\n",
    "pi_eval1 = pi_optimal1\n",
    "pi_eps_greedy2 = pi_optimal2 * ( 1 - epsilon ) + epsilon / 4\n",
    "pi_behavior2 = pi_eps_greedy2\n",
    "pi_eval2 = pi_optimal2\n",
    "\n",
    "\n",
    "\n",
    "#pi_behavior = pi_random\n",
    "#pi_eval = pi_random\n",
    "\n",
    "\n",
    "# IS__list__list = []\n",
    "# PDIS__list__list = []\n",
    "# PDDR__list__list = []\n",
    "# WIS__list__list = []\n",
    "# PDWIS__list__list = []\n",
    "PDWDR__list__list = []\n",
    "\n",
    "max_task_iter = 100\n",
    "rmax = task.get_max_reward()\n",
    "\n",
    "# XXX\n",
    "# training_gradient_fun = grad(training_loss)\n",
    "\n",
    "for episode_count in episode_count__list:\n",
    "#     IS__list = []\n",
    "#     PDIS__list = []\n",
    "#     PDDR__list = []\n",
    "#     WIS__list = []\n",
    "#     PDWIS__list = []\n",
    "    PDWDR__list = []\n",
    "    ACTION_CHOSEN = []\n",
    "    for test_count in range(num_of_tests):\n",
    "        global_task_iter = 0\n",
    "        states_sequence = []\n",
    "        actions_sequence = []\n",
    "        rewards_sequence = []\n",
    "        fence_posts = []\n",
    "        transition_count_table = np.zeros( ( state_count , action_count , state_count ) )\n",
    "        reward_value_table = np.zeros( ( state_count , action_count , state_count ) )\n",
    "        print(episode_count, test_count)\n",
    "        # Loop until the episode is done \n",
    "        for episode_iter in range( episode_count ):\n",
    "            fence_posts += [ global_task_iter ]\n",
    "            # Start the task \n",
    "            task.reset()\n",
    "            state = task.observe() \n",
    "            action1 = np.random.choice( 4, 1, p = pi_behavior1[ state, : ] )[0] \n",
    "            action2 = np.random.choice( 4, 1, p = pi_behavior2[ state, : ] )[0] \n",
    "            episode_reward_list = []\n",
    "            task_iter = 0 \n",
    "        \n",
    "            # Loop until done\n",
    "            while task_iter < max_task_iter:\n",
    "                global_task_iter += 1\n",
    "                task_iter = task_iter + 1 \n",
    "                # choose action between action1 and action2\n",
    "                if True: #(logistic_predictions(weights,inputs) > 0.5):\n",
    "                    #print (\"action 1\")\n",
    "                    action = new_action1\n",
    "                else:\n",
    "                    #print (\"action 2\")\n",
    "                    action = new_action2\n",
    "                new_state, reward = task.perform_action( action ) # TODO\n",
    "                new_action1 = np.random.choice( 4, 1, p = pi_behavior1[ new_state, : ] )[0] \n",
    "                new_action2 = np.random.choice( 4, 1, p = pi_behavior2[ new_state, : ] )[0] \n",
    "                #weights -= training_gradient_fun(weights) * 0.01\n",
    "\n",
    "                \n",
    "                # Cases for the different algorithms \n",
    "                transition_count_table , reward_value_table = update_count_table( transition_count_table , reward_value_table , state , action , new_state , reward )\n",
    "        \n",
    "                # store the data\n",
    "                episode_reward_list.append( reward ) \n",
    "                \n",
    "                states_sequence += [ state ]\n",
    "                actions_sequence += [ action ]\n",
    "                rewards_sequence += [ reward ]\n",
    "\n",
    "                # stop if at goal/else update for the next iteration \n",
    "                if task.is_terminal( state ):\n",
    "                    break\n",
    "                else:\n",
    "                    state = new_state\n",
    "                    action = new_action1 # TODO\n",
    "            \n",
    "                    \n",
    "        MDP = build_MDP_RMAX( transition_count_table , reward_value_table , rmax , gamma1 )\n",
    "        V, Q = rlfun.policy_evaluation(\n",
    "                MDP['T'] , MDP['R'] , pi_eval1 , gamma1 , theta = 0.01 ) # TODO\n",
    "        \n",
    "#         IS, _ = rlfun.off_policy_importance_sampling(\n",
    "#             states_sequence, actions_sequence, rewards_sequence,\n",
    "#             fence_posts, gamma, pi_eval, pi_behavior, state_count,\n",
    "#             action_count)\n",
    "#         PDIS, _ = rlfun.off_policy_per_decision_importance_sampling(\n",
    "#             states_sequence, actions_sequence, rewards_sequence,\n",
    "#             fence_posts, gamma, pi_eval, pi_behavior, state_count,\n",
    "#             action_count)\n",
    "#         PDDR, _ = rlfun.off_policy_per_decision_doubly_robust(\n",
    "#             states_sequence, actions_sequence, rewards_sequence,\n",
    "#             fence_posts, gamma, pi_eval, pi_behavior, V, Q, state_count,\n",
    "#             action_count)\n",
    "#         WIS, ite = rlfun.off_policy_weighted_importance_sampling(\n",
    "#             states_sequence, actions_sequence, rewards_sequence,\n",
    "#             fence_posts, gamma, pi_eval, pi_behavior, state_count,\n",
    "#             action_count)\n",
    "#         PDWIS, ite = rlfun.off_policy_per_decision_weighted_importance_sampling(\n",
    "#             states_sequence, actions_sequence, rewards_sequence,\n",
    "#             fence_posts, gamma, pi_eval, pi_behavior, state_count,\n",
    "#             action_count)\n",
    "        PDWDR, ite = rlfun.off_policy_per_decision_weighted_doubly_robust(\n",
    "            states_sequence, actions_sequence, rewards_sequence,\n",
    "            fence_posts, gamma1, pi_eval1, pi_behavior1, V, Q, state_count,\n",
    "            action_count)\n",
    "        # XXX\n",
    "# def training_loss(weights):\n",
    "#     # Training loss is the negative log-likelihood of the training labels.\n",
    "#     preds = logistic_predictions(weights, inputs)\n",
    "#     label_probabilities = preds * targets + (1 - preds) * (1 - targets)\n",
    "#     return -np.sum(np.log(label_probabilities))\n",
    "\n",
    "#         training_gradient_fun = grad(training_loss)\n",
    "\n",
    "#         weights -= training_gradient_fun(weights) * 0.01\n",
    "        \n",
    "#         IS__list += [ IS ]\n",
    "#         PDIS__list += [ PDIS ]\n",
    "#         PDDR__list += [ PDDR ]\n",
    "#         WIS__list += [ WIS ]\n",
    "#         PDWIS__list += [ PDWIS ]\n",
    "        PDWDR__list += [ PDWDR ]\n",
    "#     IS__list__list += [ IS__list ]\n",
    "#     PDIS__list__list += [ PDIS__list ]\n",
    "#     PDDR__list__list += [ PDDR__list ]\n",
    "#     WIS__list__list += [ WIS__list ]\n",
    "#     PDWIS__list__list += [ PDWIS__list ]\n",
    "    PDWDR__list__list += [ PDWDR__list ]\n",
    "    \n",
    "# IS__list__list = np.asarray(IS__list__list)\n",
    "# PDIS__list__list = np.asarray(PDIS__list__list)\n",
    "# PDDR__list__list = np.asarray(PDDR__list__list)\n",
    "# WIS__list__list = np.asarray(WIS__list__list)\n",
    "# PDWIS__list__list = np.asarray(PDWIS__list__list)\n",
    "PDWDR__list__list = np.asarray(PDWDR__list__list)\n",
    "\n",
    "V__true, Q__true = rlfun.policy_evaluation(\n",
    "                true_MDP1['T'] , true_MDP1['R'] , pi_eval1 , gamma1 , theta = 0.01 )\n",
    "actual_policy_value = V__true[ task.maze.flat_positions_containing('o')[0] ]\n",
    "plt.figure()\n",
    "# plt.errorbar( episode_count__list, np.mean(IS__list__list, axis = 1 ),\n",
    "#              yerr = np.std(IS__list__list, axis = 1 ) )\n",
    "# plt.errorbar( episode_count__list, np.mean(PDIS__list__list, axis = 1 ),\n",
    "#              yerr = np.std(PDIS__list__list, axis = 1 ) )\n",
    "# plt.errorbar( episode_count__list, np.mean(PDDR__list__list, axis = 1 ),\n",
    "#              yerr = np.std(PDDR__list__list, axis = 1 ) )\n",
    "# plt.errorbar( episode_count__list, np.mean(WIS__list__list, axis = 1 ),\n",
    "#              yerr = np.std(WIS__list__list, axis = 1 ) )\n",
    "# plt.errorbar( episode_count__list, np.mean(PDWIS__list__list, axis = 1 ),\n",
    "#              yerr = np.std(PDWIS__list__list, axis = 1 ) )\n",
    "plt.errorbar( episode_count__list, np.mean(PDWDR__list__list, axis = 1 ),\n",
    "             yerr = np.std(PDWDR__list__list, axis = 1 ) )\n",
    "plt.plot(episode_count__list, actual_policy_value*np.ones(\n",
    "        len(episode_count__list)))\n",
    "plt.xscale('log')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('estimator value')\n",
    "\n",
    "# IS__squared_error = (IS__list__list - actual_policy_value)**2\n",
    "# PDIS__squared_error = (PDIS__list__list - actual_policy_value)**2\n",
    "# PDDR__squared_error = (PDDR__list__list - actual_policy_value)**2\n",
    "# WIS__squared_error = (WIS__list__list - actual_policy_value)**2\n",
    "# PDWIS__squared_error = (PDWIS__list__list - actual_policy_value)**2\n",
    "PDWDR__squared_error = (PDWDR__list__list - actual_policy_value)**2\n",
    "plt.figure()\n",
    "# plt.plot( episode_count__list, np.mean(IS__squared_error, axis = 1 ), label = 'IS' )\n",
    "# plt.plot( episode_count__list, np.mean(PDIS__squared_error, axis = 1 ), label = 'PDIS' )\n",
    "# plt.plot( episode_count__list, np.mean(PDDR__squared_error, axis = 1 ), label = 'PDDR' )\n",
    "# plt.plot( episode_count__list, np.mean(WIS__squared_error, axis = 1 ), label = 'WIS' )\n",
    "# plt.plot( episode_count__list, np.mean(PDWIS__squared_error, axis = 1 ), label = 'PDWIS' )\n",
    "plt.plot( episode_count__list, np.mean(PDWDR__squared_error, axis = 1 ), label = 'PDWDR' )\n",
    "plt.plot( episode_count__list, 50*(np.array(episode_count__list)+0.0)**-1, 'm' )\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend( loc = 3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  3.76e+01   1.46e+01        nan        nan   5.64e+00        nan\n",
      "    1.32e+01        nan   4.91e+02        nan        nan   7.51e+01\n",
      "    2.48e+00   3.08e+01   6.10e-02   6.16e+00   5.71e+01        nan\n",
      "    1.69e+01   7.82e+00]\n",
      " [  2.22e+02   7.09e+00   4.50e-01   3.35e-01   2.91e+01   5.72e-01\n",
      "    1.06e+01   2.70e+01   8.45e+00   4.64e+01   5.64e-02   2.35e+01\n",
      "    6.16e+00   5.05e+01   8.82e+00   5.27e-01   1.57e-01   4.55e+00\n",
      "    6.41e+00   6.53e-01]\n",
      " [  2.08e+00   1.87e+02   5.14e+00   3.26e+00   1.49e+01   7.49e+00\n",
      "    4.94e+00   2.60e+00   2.07e+01   9.67e+00   1.03e+00   1.93e+01\n",
      "    3.67e+00   1.26e+00   1.77e+01   1.57e+00   6.52e+00   2.29e+01\n",
      "    2.47e+01   6.01e+00]\n",
      " [  7.24e+00   1.33e+01   8.15e+01   3.33e+00   3.84e+00   1.51e+00\n",
      "    7.07e+00   5.56e-03   3.77e-01   1.24e+01   1.53e+00   5.15e+00\n",
      "    3.60e+01   7.29e-02   4.54e+00   1.60e+00   1.01e+01   1.13e+01\n",
      "    7.34e+00   9.26e+00]]\n"
     ]
    }
   ],
   "source": [
    "print ((PDWDR__squared_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_gradient_fun = grad(rlfun.off_policy_per_decision_weighted_doubly_robust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.4597314205\n"
     ]
    }
   ],
   "source": [
    "PDWDR, _ = rlfun.off_policy_per_decision_weighted_doubly_robust(states_sequence, actions_sequence, rewards_sequence,\n",
    "            fence_posts, gamma1, pi_eval1, pi_behavior1, V, Q, state_count,\n",
    "            action_count)\n",
    "print (PDWDR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_gradient_fun(states_sequence, actions_sequence, rewards_sequence,\n",
    "            fence_posts, gamma1, pi_eval1, pi_behavior1, V, Q, state_count,\n",
    "            action_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'float'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "for i in [states_sequence, actions_sequence, rewards_sequence,\n",
    "            fence_posts, gamma1, pi_eval1, pi_behavior1, V, Q, state_count,\n",
    "            action_count]:\n",
    "    print (type(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi_behavior1.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
